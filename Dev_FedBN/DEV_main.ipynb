{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-j8mMdKY-sRm"
      },
      "source": [
        "##Process dataset 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wqu19srJxU4",
        "outputId": "dedb300f-05d1-4075-c5fe-e7aabf126093"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opacus\n",
            "  Downloading opacus-1.4.0-py3-none-any.whl (224 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/224.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/224.8 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.8/224.8 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.10/dist-packages (from opacus) (1.23.5)\n",
            "Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.10/dist-packages (from opacus) (2.0.1+cu118)\n",
            "Requirement already satisfied: scipy>=1.2 in /usr/local/lib/python3.10/dist-packages (from opacus) (1.10.1)\n",
            "Requirement already satisfied: opt-einsum>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from opacus) (3.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->opacus) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->opacus) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->opacus) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->opacus) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->opacus) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->opacus) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.13->opacus) (3.27.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.13->opacus) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13->opacus) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13->opacus) (1.3.0)\n",
            "Installing collected packages: opacus\n",
            "Successfully installed opacus-1.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install opacus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DlLhmIm4VxLq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f75c4a2b-53a8-4b85-8a74-4716e17a0db2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.2/157.2 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.4/201.4 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m73.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.1/98.1 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m58.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.9/468.9 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for gpustat (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q flwr[simulation] torch torchvision matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzHefadMBsZv",
        "outputId": "c8dda198-90ad-4a4f-fa06-7851cec272f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on cpu using PyTorch 2.0.1+cu118 and Flower 1.4.0\n"
          ]
        }
      ],
      "source": [
        "from collections import OrderedDict\n",
        "from typing import List, Tuple\n",
        "# from torchsummary import summary\n",
        "# from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import datasets, models\n",
        "from torchsummary import summary\n",
        "from torch.optim import lr_scheduler\n",
        "from typing import Callable, Dict, List, Optional, Tuple\n",
        "from flwr.server.history import History\n",
        "from pathlib import Path\n",
        "import flwr as fl\n",
        "from flwr.common import Metrics\n",
        "from flwr.common.typing import NDArrays, Scalar\n",
        "import json\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "DEVICE = torch.device(\"cpu\")  # Try \"cuda\" to train on GPU\n",
        "print(\n",
        "    f\"Training on {DEVICE} using PyTorch {torch.__version__} and Flower {fl.__version__}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ajDYCbXbACSx",
        "outputId": "acbdd7c2-f8b4-4d3e-ebb6-656a2bbf060d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Sg1QhTnlkFNRy6p_5t2rQN9ljD6OdRm0\n",
            "To: /content/b_cancer_data2.zip\n",
            "100% 4.28G/4.28G [00:58<00:00, 73.0MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown https://drive.google.com/uc?id=1Sg1QhTnlkFNRy6p_5t2rQN9ljD6OdRm0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8GUKkDMoBucm",
        "outputId": "907228b3-5d18-4e38-92e9-72f4a43b3de5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (9.4.0)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (4.6.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.12.2)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.31.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.11.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2023.7.22)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install Pillow\n",
        "!pip install gdown\n",
        "# !pip install tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ouxwS6qCBwam"
      },
      "outputs": [],
      "source": [
        "!rm -rf b_cancer_data2 b_cancer_data || true\n",
        "!unzip -qq b_cancer_data2.zip\n",
        "!mv b_cancer_data2 b_cancer_data\n",
        "!rm b_cancer_data2.zip || true"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0oN_xft-zgs"
      },
      "source": [
        "##Process dataset 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UVUJSvj-45m",
        "outputId": "59c18e7e-023e-4b46-faea-8975f3a6e641"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/u/2/uc?id=1LsjeL1CDJATns4PH6C7PnJVDHKmTVX-M\n",
            "To: /content/MISA_Dataset.zip\n",
            "100% 327M/327M [00:08<00:00, 36.6MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/u/2/uc?id=1y5rGQw2gnWjW2rWm94pKAssVxs1rZv6l\n",
            "To: /content/MISA_Crop_Dataset.zip\n",
            "100% 62.4M/62.4M [00:01<00:00, 55.1MB/s]\n",
            "rm: cannot remove 'MISA_Crop_Dataset.zipp': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!gdown https://drive.google.com/u/2/uc?id=1LsjeL1CDJATns4PH6C7PnJVDHKmTVX-M&export=download\n",
        "!gdown https://drive.google.com/u/2/uc?id=1y5rGQw2gnWjW2rWm94pKAssVxs1rZv6l&export=download\n",
        "!unzip -qq MISA_Crop_Dataset.zip -d mias-crop-mammography\n",
        "!unzip -qq MISA_Dataset.zip -d mias-mammography\n",
        "!rm MISA_Dataset.zip || true\n",
        "!rm MISA_Crop_Dataset.zipp || true"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AXBrq7xC--19"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy\n",
        "import seaborn as sns\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchsummary import summary\n",
        "from torchvision import datasets\n",
        "# import pytorch_lightning as pl\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.io import read_image\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.utils.data import DataLoader, ConcatDataset, random_split\n",
        "import os\n",
        "import cv2\n",
        "import glob\n",
        "from skimage import io\n",
        "\n",
        "from skimage import data\n",
        "from skimage import filters\n",
        "from skimage.color import rgb2gray\n",
        "from skimage.io import imread"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4uYBTyaa_AWM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "4b53db22-dbcc-4ed3-b54f-bc03eb918f0a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   REFNUM BG CLASS SEVERITY      X      Y  RADIUS\n",
              "0  mdb001  G  CIRC        B  535.0  425.0   197.0\n",
              "1  mdb002  G  CIRC        B  522.0  280.0    69.0\n",
              "2  mdb003  D  NORM      NaN    NaN    NaN     NaN\n",
              "3  mdb004  D  NORM      NaN    NaN    NaN     NaN\n",
              "4  mdb005  F  CIRC        B  477.0  133.0    30.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d5ccc443-b172-4497-8140-2bb3b471f234\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>REFNUM</th>\n",
              "      <th>BG</th>\n",
              "      <th>CLASS</th>\n",
              "      <th>SEVERITY</th>\n",
              "      <th>X</th>\n",
              "      <th>Y</th>\n",
              "      <th>RADIUS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>mdb001</td>\n",
              "      <td>G</td>\n",
              "      <td>CIRC</td>\n",
              "      <td>B</td>\n",
              "      <td>535.0</td>\n",
              "      <td>425.0</td>\n",
              "      <td>197.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>mdb002</td>\n",
              "      <td>G</td>\n",
              "      <td>CIRC</td>\n",
              "      <td>B</td>\n",
              "      <td>522.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>69.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>mdb003</td>\n",
              "      <td>D</td>\n",
              "      <td>NORM</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>mdb004</td>\n",
              "      <td>D</td>\n",
              "      <td>NORM</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>mdb005</td>\n",
              "      <td>F</td>\n",
              "      <td>CIRC</td>\n",
              "      <td>B</td>\n",
              "      <td>477.0</td>\n",
              "      <td>133.0</td>\n",
              "      <td>30.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d5ccc443-b172-4497-8140-2bb3b471f234')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d5ccc443-b172-4497-8140-2bb3b471f234 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d5ccc443-b172-4497-8140-2bb3b471f234');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-39dba0aa-6bfd-4a04-ad28-26440491840b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-39dba0aa-6bfd-4a04-ad28-26440491840b')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-39dba0aa-6bfd-4a04-ad28-26440491840b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "df = pd.read_csv('/content/mias-mammography/Info.txt', sep=\" \").drop('Unnamed: 7',axis=1)\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Y7G_3zk_BcV"
      },
      "outputs": [],
      "source": [
        "df['CLASS'] = [\"BENIGN\" if x == 'NORM' else \"MALIGNANT\" for x in df['CLASS']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R9WPk0Jm_DsN"
      },
      "outputs": [],
      "source": [
        "# make sure there are not duplicates in rows\n",
        "labels = df.drop_duplicates(subset=['REFNUM'])['CLASS']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N66qIdQD_FCW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 518
        },
        "outputId": "105bc74e-c1a7-46b9-fbdf-ac128b2df65a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BENIGN       207\n",
            "MALIGNANT    123\n",
            "Name: CLASS, dtype: int64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Count')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "class_counts = df['CLASS'].value_counts()\n",
        "print(class_counts)\n",
        "\n",
        "sns.barplot(x=class_counts.index, y=class_counts.values)\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Count')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sr9-jKXE_GDt"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import glob\n",
        "\n",
        "# Đường dẫn đến thư mục chứa các tệp tin ảnh PGM\n",
        "folder_path = '/content/mias-mammography/all-mias/'\n",
        "\n",
        "# Lấy danh sách tệp tin PGM trong thư mục\n",
        "pgm_files = glob.glob(folder_path + '*.pgm')\n",
        "\n",
        "# Duyệt qua từng tệp tin PGM và chuyển đổi sang PNG\n",
        "for pgm_file in pgm_files:\n",
        "    # Đọc ảnh PGM\n",
        "    image = cv2.imread(pgm_file, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    # Tạo đường dẫn mới cho ảnh PNG\n",
        "    png_file = pgm_file.replace('.pgm', '.png')\n",
        "\n",
        "    # Ghi ảnh PNG\n",
        "    cv2.imwrite(png_file, image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_SrzVsT_H1E"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('/content/mias-crop-mammography/description.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nVCCHNLY_8ZE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 518
        },
        "outputId": "ff7bfcb7-e259-4c40-d562-f64d2f3901fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BENIGN       207\n",
            "MALIGNANT    115\n",
            "Name: Classes, dtype: int64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Count')"
            ]
          },
          "metadata": {},
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "data['Classes'] = [\"BENIGN\" if x == 'NORM' else \"MALIGNANT\" for x in data['Class']]\n",
        "labels = data.drop_duplicates(subset=['Refnum'])['Class']\n",
        "class_counts = data['Classes'].value_counts()\n",
        "print(class_counts)\n",
        "\n",
        "sns.barplot(x=class_counts.index, y=class_counts.values)\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Count')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GaDQpziv_KP1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f72b3652-ddaa-40aa-9f18-dc689f5c23f9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      /content/mias-crop-mammography/MALIGNANT/mdb00...\n",
              "1      /content/mias-crop-mammography/MALIGNANT/mdb00...\n",
              "2       /content/mias-crop-mammography/BENIGN/mdb003.png\n",
              "3       /content/mias-crop-mammography/BENIGN/mdb004.png\n",
              "4      /content/mias-crop-mammography/MALIGNANT/mdb00...\n",
              "                             ...                        \n",
              "317     /content/mias-crop-mammography/BENIGN/mdb318.png\n",
              "318     /content/mias-crop-mammography/BENIGN/mdb319.png\n",
              "319     /content/mias-crop-mammography/BENIGN/mdb320.png\n",
              "320     /content/mias-crop-mammography/BENIGN/mdb321.png\n",
              "321     /content/mias-crop-mammography/BENIGN/mdb322.png\n",
              "Length: 322, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# Đường dẫn đến thư mục chứa ảnh\n",
        "image_folder = '/content/mias-crop-mammography/images/'\n",
        "\n",
        "\n",
        "\n",
        "# Đường dẫn đến thư mục BENIGN\n",
        "benign_folder = '/content/mias-crop-mammography/BENIGN/'\n",
        "\n",
        "# Đường dẫn đến thư mục MALIGNANT\n",
        "malignant_folder = '/content/mias-crop-mammography/MALIGNANT/'\n",
        "\n",
        "\n",
        "# Tạo thư mục BENIGN nếu chưa tồn tại\n",
        "os.makedirs(benign_folder, exist_ok=True)\n",
        "\n",
        "# Tạo thư mục MALIGNANT nếu chưa tồn tại\n",
        "os.makedirs(malignant_folder, exist_ok=True)\n",
        "\n",
        "# Áp dụng hàm lambda cho từng hàng trong dataframe\n",
        "data.apply(lambda x: shutil.move(\n",
        "    os.path.join(image_folder, x['Refnum']+'.png'),\n",
        "    benign_folder if x['Classes'] == 'BENIGN' else malignant_folder\n",
        "), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mHUPS6iT_Lc1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Đường dẫn đến thư mục BENIGN\n",
        "benign_folder = '/content/mias-crop-mammography/BENIGN/'\n",
        "\n",
        "# Đường dẫn đến thư mục MALIGNANT\n",
        "malignant_folder = '/content/mias-crop-mammography/MALIGNANT/'\n",
        "\n",
        "# Tạo cột mới \"Path\" và lưu đường dẫn vào đó\n",
        "data['Path'] = data.apply(lambda row: os.path.join(benign_folder if row['Classes'] == 'BENIGN' else malignant_folder, row['Refnum'] + '.png'), axis=1)\n",
        "data['Labels'] = data['Classes'].apply(lambda x: 1 if x == 'MALIGNANT' else 0)\n",
        "# Lưu lại tệp CSV đã cập nhật\n",
        "data.to_csv('/content/mias-crop-mammography/description_new.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y9VX2Ro3BhN-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "outputId": "bf16f3ca-fade-4c9b-9507-cf00d630bd01"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Refnum Bg Class Severity      X      Y  Radius  \\\n",
              "0  mdb001  G  CIRC        B  535.0  425.0   197.0   \n",
              "1  mdb002  G  CIRC        B  522.0  280.0    69.0   \n",
              "2  mdb003  D  NORM      NaN    NaN    NaN     NaN   \n",
              "3  mdb004  D  NORM      NaN    NaN    NaN     NaN   \n",
              "4  mdb005  F  CIRC        B  477.0  133.0    30.0   \n",
              "\n",
              "                                                Path  Cancer  \\\n",
              "0  /content/mias-crop-mammography/MALIGNANT/mdb00...       0   \n",
              "1  /content/mias-crop-mammography/MALIGNANT/mdb00...       0   \n",
              "2   /content/mias-crop-mammography/BENIGN/mdb003.png       0   \n",
              "3   /content/mias-crop-mammography/BENIGN/mdb004.png       0   \n",
              "4  /content/mias-crop-mammography/MALIGNANT/mdb00...       0   \n",
              "\n",
              "           Path_save    Classes  Labels  \n",
              "0  images/mdb001.png  MALIGNANT       1  \n",
              "1  images/mdb002.png  MALIGNANT       1  \n",
              "2  images/mdb003.png     BENIGN       0  \n",
              "3  images/mdb004.png     BENIGN       0  \n",
              "4  images/mdb005.png  MALIGNANT       1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-79b71065-1ac6-46e4-bed5-08cd24efece7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Refnum</th>\n",
              "      <th>Bg</th>\n",
              "      <th>Class</th>\n",
              "      <th>Severity</th>\n",
              "      <th>X</th>\n",
              "      <th>Y</th>\n",
              "      <th>Radius</th>\n",
              "      <th>Path</th>\n",
              "      <th>Cancer</th>\n",
              "      <th>Path_save</th>\n",
              "      <th>Classes</th>\n",
              "      <th>Labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>mdb001</td>\n",
              "      <td>G</td>\n",
              "      <td>CIRC</td>\n",
              "      <td>B</td>\n",
              "      <td>535.0</td>\n",
              "      <td>425.0</td>\n",
              "      <td>197.0</td>\n",
              "      <td>/content/mias-crop-mammography/MALIGNANT/mdb00...</td>\n",
              "      <td>0</td>\n",
              "      <td>images/mdb001.png</td>\n",
              "      <td>MALIGNANT</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>mdb002</td>\n",
              "      <td>G</td>\n",
              "      <td>CIRC</td>\n",
              "      <td>B</td>\n",
              "      <td>522.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>/content/mias-crop-mammography/MALIGNANT/mdb00...</td>\n",
              "      <td>0</td>\n",
              "      <td>images/mdb002.png</td>\n",
              "      <td>MALIGNANT</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>mdb003</td>\n",
              "      <td>D</td>\n",
              "      <td>NORM</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>/content/mias-crop-mammography/BENIGN/mdb003.png</td>\n",
              "      <td>0</td>\n",
              "      <td>images/mdb003.png</td>\n",
              "      <td>BENIGN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>mdb004</td>\n",
              "      <td>D</td>\n",
              "      <td>NORM</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>/content/mias-crop-mammography/BENIGN/mdb004.png</td>\n",
              "      <td>0</td>\n",
              "      <td>images/mdb004.png</td>\n",
              "      <td>BENIGN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>mdb005</td>\n",
              "      <td>F</td>\n",
              "      <td>CIRC</td>\n",
              "      <td>B</td>\n",
              "      <td>477.0</td>\n",
              "      <td>133.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>/content/mias-crop-mammography/MALIGNANT/mdb00...</td>\n",
              "      <td>0</td>\n",
              "      <td>images/mdb005.png</td>\n",
              "      <td>MALIGNANT</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-79b71065-1ac6-46e4-bed5-08cd24efece7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-79b71065-1ac6-46e4-bed5-08cd24efece7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-79b71065-1ac6-46e4-bed5-08cd24efece7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8ea97484-8aca-4a10-b3ae-0f488bc5a1c5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8ea97484-8aca-4a10-b3ae-0f488bc5a1c5')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8ea97484-8aca-4a10-b3ae-0f488bc5a1c5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7OksfoqzCjiH"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "data_dir = \"/content/mias-crop-mammography\"\n",
        "train_dir = \"final_mias-crop-mammography/train\"\n",
        "test_dir = \"final_mias-crop-mammography/valid\"\n",
        "train_ratio = 0.9\n",
        "\n",
        "\n",
        "os.makedirs(os.path.join(train_dir, \"BENIGN\"), exist_ok=True)\n",
        "os.makedirs(os.path.join(train_dir, \"MALIGNANT\"), exist_ok=True)\n",
        "os.makedirs(os.path.join(test_dir, \"BENIGN\"), exist_ok=True)\n",
        "os.makedirs(os.path.join(test_dir, \"MALIGNANT\"), exist_ok=True)\n",
        "\n",
        "benign_files = os.listdir(os.path.join(data_dir, \"BENIGN\"))\n",
        "malignant_files = os.listdir(os.path.join(data_dir, \"MALIGNANT\"))\n",
        "\n",
        "random.shuffle(benign_files)\n",
        "random.shuffle(malignant_files)\n",
        "\n",
        "train_benign_count = int(len(benign_files) * train_ratio)\n",
        "train_malignant_count = int(len(malignant_files) * train_ratio)\n",
        "\n",
        "for file in benign_files[:train_benign_count]:\n",
        "    src = os.path.join(data_dir, \"BENIGN\", file)\n",
        "    dst = os.path.join(train_dir, \"BENIGN\", file)\n",
        "    shutil.copyfile(src, dst)\n",
        "\n",
        "for file in benign_files[train_benign_count:]:\n",
        "    src = os.path.join(data_dir, \"BENIGN\", file)\n",
        "    dst = os.path.join(test_dir, \"BENIGN\", file)\n",
        "    shutil.copyfile(src, dst)\n",
        "\n",
        "for file in malignant_files[:train_malignant_count]:\n",
        "    src = os.path.join(data_dir, \"MALIGNANT\", file)\n",
        "    dst = os.path.join(train_dir, \"MALIGNANT\", file)\n",
        "    shutil.copyfile(src, dst)\n",
        "\n",
        "for file in malignant_files[train_malignant_count:]:\n",
        "    src = os.path.join(data_dir, \"MALIGNANT\", file)\n",
        "    dst = os.path.join(test_dir, \"MALIGNANT\", file)\n",
        "    shutil.copyfile(src, dst)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQKIkkd8NdfM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7cc7a0b-c583-469b-9ba5-2a6eb1f3d84c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/pytorch/vision/zipball/v0.10.0\" to /root/.cache/torch/hub/v0.10.0.zip\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v2-b0353104.pth\n",
            "100%|██████████| 13.6M/13.6M [00:00<00:00, 63.5MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 32, 112, 112]             864\n",
            "       BatchNorm2d-2         [-1, 32, 112, 112]              64\n",
            "             ReLU6-3         [-1, 32, 112, 112]               0\n",
            "            Conv2d-4         [-1, 32, 112, 112]             288\n",
            "       BatchNorm2d-5         [-1, 32, 112, 112]              64\n",
            "             ReLU6-6         [-1, 32, 112, 112]               0\n",
            "            Conv2d-7         [-1, 16, 112, 112]             512\n",
            "       BatchNorm2d-8         [-1, 16, 112, 112]              32\n",
            "  InvertedResidual-9         [-1, 16, 112, 112]               0\n",
            "           Conv2d-10         [-1, 96, 112, 112]           1,536\n",
            "      BatchNorm2d-11         [-1, 96, 112, 112]             192\n",
            "            ReLU6-12         [-1, 96, 112, 112]               0\n",
            "           Conv2d-13           [-1, 96, 56, 56]             864\n",
            "      BatchNorm2d-14           [-1, 96, 56, 56]             192\n",
            "            ReLU6-15           [-1, 96, 56, 56]               0\n",
            "           Conv2d-16           [-1, 24, 56, 56]           2,304\n",
            "      BatchNorm2d-17           [-1, 24, 56, 56]              48\n",
            " InvertedResidual-18           [-1, 24, 56, 56]               0\n",
            "           Conv2d-19          [-1, 144, 56, 56]           3,456\n",
            "      BatchNorm2d-20          [-1, 144, 56, 56]             288\n",
            "            ReLU6-21          [-1, 144, 56, 56]               0\n",
            "           Conv2d-22          [-1, 144, 56, 56]           1,296\n",
            "      BatchNorm2d-23          [-1, 144, 56, 56]             288\n",
            "            ReLU6-24          [-1, 144, 56, 56]               0\n",
            "           Conv2d-25           [-1, 24, 56, 56]           3,456\n",
            "      BatchNorm2d-26           [-1, 24, 56, 56]              48\n",
            " InvertedResidual-27           [-1, 24, 56, 56]               0\n",
            "           Conv2d-28          [-1, 144, 56, 56]           3,456\n",
            "      BatchNorm2d-29          [-1, 144, 56, 56]             288\n",
            "            ReLU6-30          [-1, 144, 56, 56]               0\n",
            "           Conv2d-31          [-1, 144, 28, 28]           1,296\n",
            "      BatchNorm2d-32          [-1, 144, 28, 28]             288\n",
            "            ReLU6-33          [-1, 144, 28, 28]               0\n",
            "           Conv2d-34           [-1, 32, 28, 28]           4,608\n",
            "      BatchNorm2d-35           [-1, 32, 28, 28]              64\n",
            " InvertedResidual-36           [-1, 32, 28, 28]               0\n",
            "           Conv2d-37          [-1, 192, 28, 28]           6,144\n",
            "      BatchNorm2d-38          [-1, 192, 28, 28]             384\n",
            "            ReLU6-39          [-1, 192, 28, 28]               0\n",
            "           Conv2d-40          [-1, 192, 28, 28]           1,728\n",
            "      BatchNorm2d-41          [-1, 192, 28, 28]             384\n",
            "            ReLU6-42          [-1, 192, 28, 28]               0\n",
            "           Conv2d-43           [-1, 32, 28, 28]           6,144\n",
            "      BatchNorm2d-44           [-1, 32, 28, 28]              64\n",
            " InvertedResidual-45           [-1, 32, 28, 28]               0\n",
            "           Conv2d-46          [-1, 192, 28, 28]           6,144\n",
            "      BatchNorm2d-47          [-1, 192, 28, 28]             384\n",
            "            ReLU6-48          [-1, 192, 28, 28]               0\n",
            "           Conv2d-49          [-1, 192, 28, 28]           1,728\n",
            "      BatchNorm2d-50          [-1, 192, 28, 28]             384\n",
            "            ReLU6-51          [-1, 192, 28, 28]               0\n",
            "           Conv2d-52           [-1, 32, 28, 28]           6,144\n",
            "      BatchNorm2d-53           [-1, 32, 28, 28]              64\n",
            " InvertedResidual-54           [-1, 32, 28, 28]               0\n",
            "           Conv2d-55          [-1, 192, 28, 28]           6,144\n",
            "      BatchNorm2d-56          [-1, 192, 28, 28]             384\n",
            "            ReLU6-57          [-1, 192, 28, 28]               0\n",
            "           Conv2d-58          [-1, 192, 14, 14]           1,728\n",
            "      BatchNorm2d-59          [-1, 192, 14, 14]             384\n",
            "            ReLU6-60          [-1, 192, 14, 14]               0\n",
            "           Conv2d-61           [-1, 64, 14, 14]          12,288\n",
            "      BatchNorm2d-62           [-1, 64, 14, 14]             128\n",
            " InvertedResidual-63           [-1, 64, 14, 14]               0\n",
            "           Conv2d-64          [-1, 384, 14, 14]          24,576\n",
            "      BatchNorm2d-65          [-1, 384, 14, 14]             768\n",
            "            ReLU6-66          [-1, 384, 14, 14]               0\n",
            "           Conv2d-67          [-1, 384, 14, 14]           3,456\n",
            "      BatchNorm2d-68          [-1, 384, 14, 14]             768\n",
            "            ReLU6-69          [-1, 384, 14, 14]               0\n",
            "           Conv2d-70           [-1, 64, 14, 14]          24,576\n",
            "      BatchNorm2d-71           [-1, 64, 14, 14]             128\n",
            " InvertedResidual-72           [-1, 64, 14, 14]               0\n",
            "           Conv2d-73          [-1, 384, 14, 14]          24,576\n",
            "      BatchNorm2d-74          [-1, 384, 14, 14]             768\n",
            "            ReLU6-75          [-1, 384, 14, 14]               0\n",
            "           Conv2d-76          [-1, 384, 14, 14]           3,456\n",
            "      BatchNorm2d-77          [-1, 384, 14, 14]             768\n",
            "            ReLU6-78          [-1, 384, 14, 14]               0\n",
            "           Conv2d-79           [-1, 64, 14, 14]          24,576\n",
            "      BatchNorm2d-80           [-1, 64, 14, 14]             128\n",
            " InvertedResidual-81           [-1, 64, 14, 14]               0\n",
            "           Conv2d-82          [-1, 384, 14, 14]          24,576\n",
            "      BatchNorm2d-83          [-1, 384, 14, 14]             768\n",
            "            ReLU6-84          [-1, 384, 14, 14]               0\n",
            "           Conv2d-85          [-1, 384, 14, 14]           3,456\n",
            "      BatchNorm2d-86          [-1, 384, 14, 14]             768\n",
            "            ReLU6-87          [-1, 384, 14, 14]               0\n",
            "           Conv2d-88           [-1, 64, 14, 14]          24,576\n",
            "      BatchNorm2d-89           [-1, 64, 14, 14]             128\n",
            " InvertedResidual-90           [-1, 64, 14, 14]               0\n",
            "           Conv2d-91          [-1, 384, 14, 14]          24,576\n",
            "      BatchNorm2d-92          [-1, 384, 14, 14]             768\n",
            "            ReLU6-93          [-1, 384, 14, 14]               0\n",
            "           Conv2d-94          [-1, 384, 14, 14]           3,456\n",
            "      BatchNorm2d-95          [-1, 384, 14, 14]             768\n",
            "            ReLU6-96          [-1, 384, 14, 14]               0\n",
            "           Conv2d-97           [-1, 96, 14, 14]          36,864\n",
            "      BatchNorm2d-98           [-1, 96, 14, 14]             192\n",
            " InvertedResidual-99           [-1, 96, 14, 14]               0\n",
            "          Conv2d-100          [-1, 576, 14, 14]          55,296\n",
            "     BatchNorm2d-101          [-1, 576, 14, 14]           1,152\n",
            "           ReLU6-102          [-1, 576, 14, 14]               0\n",
            "          Conv2d-103          [-1, 576, 14, 14]           5,184\n",
            "     BatchNorm2d-104          [-1, 576, 14, 14]           1,152\n",
            "           ReLU6-105          [-1, 576, 14, 14]               0\n",
            "          Conv2d-106           [-1, 96, 14, 14]          55,296\n",
            "     BatchNorm2d-107           [-1, 96, 14, 14]             192\n",
            "InvertedResidual-108           [-1, 96, 14, 14]               0\n",
            "          Conv2d-109          [-1, 576, 14, 14]          55,296\n",
            "     BatchNorm2d-110          [-1, 576, 14, 14]           1,152\n",
            "           ReLU6-111          [-1, 576, 14, 14]               0\n",
            "          Conv2d-112          [-1, 576, 14, 14]           5,184\n",
            "     BatchNorm2d-113          [-1, 576, 14, 14]           1,152\n",
            "           ReLU6-114          [-1, 576, 14, 14]               0\n",
            "          Conv2d-115           [-1, 96, 14, 14]          55,296\n",
            "     BatchNorm2d-116           [-1, 96, 14, 14]             192\n",
            "InvertedResidual-117           [-1, 96, 14, 14]               0\n",
            "          Conv2d-118          [-1, 576, 14, 14]          55,296\n",
            "     BatchNorm2d-119          [-1, 576, 14, 14]           1,152\n",
            "           ReLU6-120          [-1, 576, 14, 14]               0\n",
            "          Conv2d-121            [-1, 576, 7, 7]           5,184\n",
            "     BatchNorm2d-122            [-1, 576, 7, 7]           1,152\n",
            "           ReLU6-123            [-1, 576, 7, 7]               0\n",
            "          Conv2d-124            [-1, 160, 7, 7]          92,160\n",
            "     BatchNorm2d-125            [-1, 160, 7, 7]             320\n",
            "InvertedResidual-126            [-1, 160, 7, 7]               0\n",
            "          Conv2d-127            [-1, 960, 7, 7]         153,600\n",
            "     BatchNorm2d-128            [-1, 960, 7, 7]           1,920\n",
            "           ReLU6-129            [-1, 960, 7, 7]               0\n",
            "          Conv2d-130            [-1, 960, 7, 7]           8,640\n",
            "     BatchNorm2d-131            [-1, 960, 7, 7]           1,920\n",
            "           ReLU6-132            [-1, 960, 7, 7]               0\n",
            "          Conv2d-133            [-1, 160, 7, 7]         153,600\n",
            "     BatchNorm2d-134            [-1, 160, 7, 7]             320\n",
            "InvertedResidual-135            [-1, 160, 7, 7]               0\n",
            "          Conv2d-136            [-1, 960, 7, 7]         153,600\n",
            "     BatchNorm2d-137            [-1, 960, 7, 7]           1,920\n",
            "           ReLU6-138            [-1, 960, 7, 7]               0\n",
            "          Conv2d-139            [-1, 960, 7, 7]           8,640\n",
            "     BatchNorm2d-140            [-1, 960, 7, 7]           1,920\n",
            "           ReLU6-141            [-1, 960, 7, 7]               0\n",
            "          Conv2d-142            [-1, 160, 7, 7]         153,600\n",
            "     BatchNorm2d-143            [-1, 160, 7, 7]             320\n",
            "InvertedResidual-144            [-1, 160, 7, 7]               0\n",
            "          Conv2d-145            [-1, 960, 7, 7]         153,600\n",
            "     BatchNorm2d-146            [-1, 960, 7, 7]           1,920\n",
            "           ReLU6-147            [-1, 960, 7, 7]               0\n",
            "          Conv2d-148            [-1, 960, 7, 7]           8,640\n",
            "     BatchNorm2d-149            [-1, 960, 7, 7]           1,920\n",
            "           ReLU6-150            [-1, 960, 7, 7]               0\n",
            "          Conv2d-151            [-1, 320, 7, 7]         307,200\n",
            "     BatchNorm2d-152            [-1, 320, 7, 7]             640\n",
            "InvertedResidual-153            [-1, 320, 7, 7]               0\n",
            "          Conv2d-154           [-1, 1280, 7, 7]         409,600\n",
            "     BatchNorm2d-155           [-1, 1280, 7, 7]           2,560\n",
            "           ReLU6-156           [-1, 1280, 7, 7]               0\n",
            "          Linear-157                    [-1, 2]           2,562\n",
            "================================================================\n",
            "Total params: 2,226,434\n",
            "Trainable params: 2,226,434\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 152.85\n",
            "Params size (MB): 8.49\n",
            "Estimated Total Size (MB): 161.92\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torchsummary import summary\n",
        "model = torch.hub.load('pytorch/vision:v0.10.0', 'mobilenet_v2', pretrained=True)\n",
        "for param in model.parameters():\n",
        "  param.requires_grad = True\n",
        "model.classifier = nn.Linear(1280, 2)\n",
        "net = model.to(DEVICE)\n",
        "summary(model, (3, 224, 224))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fb1h3AY5VQOK"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 32\n",
        "NUM_CLIENTS = 100\n",
        "ORDER_of_CLIENTS = [80, 20]\n",
        "\n",
        "def load_datasets(data_dirs):\n",
        "    data_transforms = {\n",
        "        'train': transforms.Compose([\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.RandomRotation(10),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ]),\n",
        "        'valid': transforms.Compose([\n",
        "            transforms.Resize(256),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ]),\n",
        "    }\n",
        "\n",
        "    trainloaders = []\n",
        "    valloaders = []\n",
        "\n",
        "    for i,data_dir in enumerate(data_dirs):\n",
        "\n",
        "        trainset = datasets.ImageFolder(os.path.join(data_dir, 'train'), data_transforms['train'])\n",
        "        testset = datasets.ImageFolder(os.path.join(data_dir, 'valid'), data_transforms['valid'])\n",
        "\n",
        "        total_length = len(trainset)\n",
        "        partition_size = total_length // ORDER_of_CLIENTS[i]\n",
        "        lengths = [partition_size] * ORDER_of_CLIENTS[i]\n",
        "        lengths[-1] = total_length - sum(lengths[:-1])\n",
        "\n",
        "        clients_data = random_split(trainset, lengths, torch.Generator().manual_seed(42))\n",
        "\n",
        "        client_trainloaders = []\n",
        "        client_valloaders = []\n",
        "\n",
        "        for client_data in clients_data:\n",
        "            len_val = len(client_data) // 10\n",
        "            len_train = len(client_data) - len_val\n",
        "            lengths = [len_train, len_val]\n",
        "            ds_train, ds_val = random_split(client_data, lengths, torch.Generator().manual_seed(42))\n",
        "            trainloader = DataLoader(ds_train, batch_size=BATCH_SIZE, shuffle=True)\n",
        "            client_trainloaders.append(trainloader)\n",
        "            valloader = DataLoader(ds_val, batch_size=BATCH_SIZE)\n",
        "            client_valloaders.append(valloader)\n",
        "\n",
        "        trainloaders.extend(client_trainloaders)\n",
        "        valloaders.extend(client_valloaders)\n",
        "\n",
        "    testloader = DataLoader(testset, batch_size=BATCH_SIZE)\n",
        "    return trainloaders, valloaders, testloader\n",
        "\n",
        "data_dirs = ['/content/b_cancer_data', '/content/final_mias-crop-mammography']  # Thay đổi đường dẫn theo thư mục của bạn\n",
        "trainloaders, valloaders, testloader = load_datasets(data_dirs)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(trainloaders))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_VQ_GRDfHVe",
        "outputId": "efa942ee-8a47-44a8-c7c3-52c80b2753d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AbPXDGgdTHYj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a979d2b6-a29b-44d6-c66d-2801823cfe62"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U6r-MVLaTikM"
      },
      "outputs": [],
      "source": [
        "\n",
        "import csv\n",
        "\n",
        "# Đường dẫn đến file CSV\n",
        "csv_file_train = 'results_train.csv'\n",
        "csv_file_test = 'results_test.csv'\n",
        "\n",
        "class BNClient(fl.client.NumPyClient):\n",
        "    # client_count = 0\n",
        "    \"\"\"Flower client implementing image classification using PyTorch.\"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        cid: str,\n",
        "        model: net,\n",
        "        trainloader: torch.utils.data.DataLoader,\n",
        "        testloader: torch.utils.data.DataLoader,\n",
        "        num_examples: Dict,\n",
        "        mode: str,\n",
        "    ) -> None:\n",
        "        self.cid = cid\n",
        "        self.model = model\n",
        "        self.trainloader = trainloader\n",
        "        self.testloader = testloader\n",
        "        self.num_examples = num_examples\n",
        "        self.mode = mode\n",
        "        # BNClient.client_count += 1\n",
        "        # self.n_iter = BNClient.client_count\n",
        "\n",
        "\n",
        "    def get_parameters(self, config) -> NDArrays:\n",
        "        \"\"\"Return model parameters as a list of NumPy ndarrays w or w/o using\n",
        "        BN layers.\"\"\"\n",
        "        print(f\"[Client {self.cid}] get_parameters\")\n",
        "        self.model.train()\n",
        "        # pylint: disable = no-else-return\n",
        "        if self.mode == \"fedbn\":\n",
        "            # Excluding parameters of BN layers when using FedBN\n",
        "            return [\n",
        "                val.cpu().numpy()\n",
        "                for name, val in self.model.state_dict().items()\n",
        "                if \"bn\" not in name\n",
        "            ]\n",
        "        else:\n",
        "            # Return all model parameters as a list of NumPy ndarrays\n",
        "            return [val.cpu().numpy() for _, val in self.model.state_dict().items()]\n",
        "\n",
        "    def set_parameters(self, parameters: NDArrays) -> None:\n",
        "        \"\"\"Set model parameters from a list of NumPy ndarrays Exclude the bn\n",
        "        layer if available.\"\"\"\n",
        "        self.model.train()\n",
        "        # pylint: disable=not-callable\n",
        "        if self.mode == \"fedbn\":\n",
        "            keys = [k for k in self.model.state_dict().keys() if \"bn\" not in k]\n",
        "            params_dict = zip(keys, parameters)\n",
        "            state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n",
        "            self.model.load_state_dict(state_dict, strict=False)\n",
        "        else:\n",
        "            params_dict = zip(self.model.state_dict().keys(), parameters)\n",
        "            state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n",
        "            self.model.load_state_dict(state_dict, strict=True)\n",
        "        # pylint: enable=not-callable\n",
        "\n",
        "    def fit(\n",
        "        self, parameters: NDArrays, config: Dict[str, Scalar]\n",
        "    ) -> Tuple[NDArrays, int, Dict]:\n",
        "        \"\"\"Set model parameters, train model, return updated model\n",
        "        parameters.\"\"\"\n",
        "        print(f\"[Client {self.cid}] fit, config: {config}\")\n",
        "        self.set_parameters(parameters)\n",
        "        test_loss, test_accuracy = test(\n",
        "            self.model, self.num_examples[\"dataset\"], self.trainloader, device=DEVICE\n",
        "        )\n",
        "        test_dict = {\n",
        "            \"dataset\": self.num_examples[\"dataset\"],\n",
        "            \"fl_round\": FL_ROUND,\n",
        "            \"strategy\": self.mode,\n",
        "            \"train_loss\": test_loss,\n",
        "            \"train_accuracy\": test_accuracy,\n",
        "        }\n",
        "        loss, accuracy = train(\n",
        "            self.model,\n",
        "            self.trainloader,\n",
        "            self.num_examples[\"dataset\"],\n",
        "            epochs=5,\n",
        "            device=DEVICE,\n",
        "        )\n",
        "        eval_list.append(test_dict)\n",
        "\n",
        "        # writer = SummaryWriter()\n",
        "\n",
        "\n",
        "        eval_dict = eval_list[0]\n",
        "\n",
        "        train_loss = eval_dict['train_loss']\n",
        "        train_accuracy = eval_dict['train_accuracy']\n",
        "\n",
        "\n",
        "        header_written = False\n",
        "\n",
        "        with open(csv_file_train, 'a', newline='') as file:\n",
        "          writer = csv.writer(file)\n",
        "\n",
        "          if not header_written:\n",
        "            writer.writerow(['train_loss', 'train_accuracy'])\n",
        "            header_written = True\n",
        "\n",
        "          writer.writerow([test_loss, test_accuracy])\n",
        "        # # Ghi các giá trị vào TensorBoard\n",
        "        # writer.add_scalar(\"loss/train\", test_loss, self.n_iter)\n",
        "        # writer.add_scalar(\"accuracy/train\", test_accuracy, self.n_iter)\n",
        "        # # n_iter += 1\n",
        "\n",
        "        print(\"EVAL_LIST_FIT\",eval_list)\n",
        "        return (\n",
        "            self.get_parameters({}),\n",
        "            self.num_examples[\"trainset\"],\n",
        "            {\"loss\": loss, \"accuracy\": accuracy},\n",
        "        )\n",
        "\n",
        "    def evaluate(\n",
        "        self, parameters: NDArrays, config: Dict[str, Scalar]\n",
        "    ) -> Tuple[float, int, Dict]:\n",
        "        \"\"\"Set model parameters, evaluate model on local test dataset, return\n",
        "        result.\"\"\"\n",
        "        print(f\"[Client {self.cid}] evaluate, config: {config}\")\n",
        "        self.set_parameters(parameters)\n",
        "        global FL_ROUND\n",
        "\n",
        "        loss, accuracy = test(\n",
        "            self.model, self.num_examples[\"dataset\"], self.testloader, device=DEVICE\n",
        "        )\n",
        "        test_dict = {\n",
        "            \"dataset\": self.num_examples[\"dataset\"],\n",
        "            \"fl_round\": FL_ROUND,\n",
        "            \"strategy\": self.mode,\n",
        "            \"test_loss\": loss,\n",
        "            \"test_accuracy\": accuracy,\n",
        "        }\n",
        "        eval_list.append(test_dict)\n",
        "                # Truy cập vào từ điển trong danh sách eval_list\n",
        "        eval_dict = eval_list[0]\n",
        "\n",
        "        # Truy cập các giá trị 'test_loss' và 'test_accuracy' trong từ điển\n",
        "        test_loss = eval_dict['test_loss']\n",
        "        test_accuracy = eval_dict['test_accuracy']\n",
        "\n",
        "        # Kiểm tra xem đã ghi tiêu đề cột hay chưa\n",
        "        header_written = False\n",
        "\n",
        "        with open(csv_file_test, 'a', newline='') as file:\n",
        "          writer = csv.writer(file)\n",
        "\n",
        "          if not header_written:\n",
        "            writer.writerow(['test_loss', 'test_accuracy'])\n",
        "            header_written = True\n",
        "\n",
        "          # Ghi giá trị vào từng dòng\n",
        "          writer.writerow([test_loss, test_accuracy])\n",
        "        print(\"EVAL_LIST\",eval_list)\n",
        "        FL_ROUND += 1\n",
        "        return (\n",
        "            float(loss),\n",
        "            self.num_examples[\"testset\"],\n",
        "            {\"loss\": loss, \"accuracy\": accuracy},\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lNnPAgmTTkFZ"
      },
      "outputs": [],
      "source": [
        "def train(model, traindata, dataset, epochs, device) -> Tuple[float, float]:\n",
        "    \"\"\"Train the network.\"\"\"\n",
        "    # Define loss and optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.SGD(model.parameters(),lr = 0.006, momentum = 0.9)\n",
        "    exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
        "    # writer = SummaryWriter()\n",
        "    print(\n",
        "        f\"Training {dataset} dataset with {epochs} local epoch(s) w/ {len(traindata)} batches each\"\n",
        "    )\n",
        "    # n_iter = 1\n",
        "    # Train the network\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "    for epoch in range(epochs):  # loop over the dataset multiple times\n",
        "        running_loss = 0.0\n",
        "        total = 0.0\n",
        "        correct = 0\n",
        "        for i, data in enumerate(traindata, 0):\n",
        "            images, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # print statistics\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)  # pylint: disable=no-member\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            loss = running_loss\n",
        "            accuracy = correct / total\n",
        "            if i == len(traindata) - 1:  # print every 100 mini-batches\n",
        "                accuracy = correct / total\n",
        "                loss_batch = running_loss / len(traindata) # loss for mini batches\n",
        "                # writer.add_scalar(\"loss/train\",running_loss,n_iter)\n",
        "                # writer.add_scalar(\"accuracy/train\",accuracy,n_iter)\n",
        "                print(\n",
        "                    f\"Train Dataset {dataset} with [{epoch+1}, {i+1}] \\\n",
        "                    loss: {loss_batch} accuracy: {accuracy}\"\n",
        "                )\n",
        "                running_loss = 0.0\n",
        "            # n_iter +=1\n",
        "        loss = loss / len(traindata)\n",
        "        exp_lr_scheduler.step()\n",
        "    return loss, accuracy\n",
        "\n",
        "\n",
        "def test(model, dataset, testdata, device) -> Tuple[float, float]:\n",
        "    \"\"\"Validate the network on the entire test set.\"\"\"\n",
        "    # Define loss and metrics\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    loss = 0.0\n",
        "\n",
        "    # Evaluate the network\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for data in testdata:\n",
        "            images, labels = data[0].to(device), data[1].to(device)\n",
        "            outputs = model(images)\n",
        "            loss += criterion(outputs, labels).item()\n",
        "            _, predicted = torch.max(outputs.data, 1)  # pylint: disable=no-member\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    accuracy = correct / total\n",
        "    loss = loss / len(testdata)\n",
        "    print(f\"Dataset {dataset} with evaluation loss: {loss}\")\n",
        "    return loss, accuracy\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3CJv1jmyTm5S"
      },
      "outputs": [],
      "source": [
        "FL_ROUND = 0\n",
        "eval_list = []\n",
        "# num_round = 0\n",
        "\n",
        "def client_fn(cid: str) -> BNClient:\n",
        "    \"\"\"Create a Flower client representing a single organization.\"\"\"\n",
        "    # Load model\n",
        "    net = model.to(DEVICE)\n",
        "\n",
        "    num_round = 0\n",
        "    print(f\"ROUND BACK OTHER CLIENT {num_round}\")\n",
        "    num_round += 1  # Sử dụng toán tử += để tăng giá trị của biến num_round\n",
        "    # Load data\n",
        "    # Note: each client gets a different trainloader/valloader, so each client\n",
        "    # will train and evaluate on their own unique data\n",
        "    trainloader = trainloaders[int(cid)]\n",
        "    valloader = valloaders[int(cid)]\n",
        "    num_examples = {\n",
        "    \"dataset\": \"HBCDs\",\n",
        "    \"trainset\": len(trainloader),\n",
        "    \"testset\": len(valloader),\n",
        "}\n",
        "    # Create a  single Flower client representing a single organization\n",
        "    return BNClient(cid,net, trainloader, valloader,num_examples,\"fedbn\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u7jTivjLTpmB"
      },
      "outputs": [],
      "source": [
        "def weighted_average(metrics: List[Tuple[int, Metrics]]) -> Metrics:\n",
        "    # Multiply accuracy of each client by number of examples used\n",
        "    accuracies = [num_examples * m[\"accuracy\"] for num_examples, m in metrics]\n",
        "    examples = [num_examples for num_examples, _ in metrics]\n",
        "\n",
        "    # Aggregate and return custom metric (weighted average)\n",
        "    return {\"accuracy\": sum(accuracies) / sum(examples)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jcw7_kT8TqoJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cba1fe12-7b71-4718-9c60-e3e5451f335c"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO flwr 2023-08-24 09:07:59,754 | app.py:146 | Starting Flower simulation, config: ServerConfig(num_rounds=50, round_timeout=None)\n",
            "INFO:flwr:Starting Flower simulation, config: ServerConfig(num_rounds=50, round_timeout=None)\n",
            "2023-08-24 09:08:05,389\tINFO worker.py:1621 -- Started a local Ray instance.\n",
            "INFO flwr 2023-08-24 09:08:07,229 | app.py:180 | Flower VCE: Ray initialized with resources: {'object_store_memory': 3915573657.0, 'memory': 7831147316.0, 'CPU': 2.0, 'node:__internal_head__': 1.0, 'node:172.28.0.12': 1.0}\n",
            "INFO:flwr:Flower VCE: Ray initialized with resources: {'object_store_memory': 3915573657.0, 'memory': 7831147316.0, 'CPU': 2.0, 'node:__internal_head__': 1.0, 'node:172.28.0.12': 1.0}\n",
            "INFO flwr 2023-08-24 09:08:07,233 | server.py:86 | Initializing global parameters\n",
            "INFO:flwr:Initializing global parameters\n",
            "INFO flwr 2023-08-24 09:08:07,236 | server.py:273 | Requesting initial parameters from one random client\n",
            "INFO:flwr:Requesting initial parameters from one random client\n",
            "\u001b[2m\u001b[36m(pid=2951)\u001b[0m 2023-08-24 09:08:09.767313: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "INFO flwr 2023-08-24 09:08:16,743 | server.py:277 | Received initial parameters from one random client\n",
            "INFO:flwr:Received initial parameters from one random client\n",
            "INFO flwr 2023-08-24 09:08:16,751 | server.py:88 | Evaluating initial parameters\n",
            "INFO:flwr:Evaluating initial parameters\n",
            "INFO flwr 2023-08-24 09:08:16,757 | server.py:101 | FL starting\n",
            "INFO:flwr:FL starting\n",
            "DEBUG flwr 2023-08-24 09:08:16,761 | server.py:218 | fit_round 1: strategy sampled 100 clients (out of 100)\n",
            "DEBUG:flwr:fit_round 1: strategy sampled 100 clients (out of 100)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_get_parameters pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_get_parameters pid=2951)\u001b[0m [Client 58] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 24] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6593833367029825\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.595499575138092 accuracy: 0.7222222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.5342869162559509 accuracy: 0.75\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.5252782007058462 accuracy: 0.8055555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.37545205156008404 accuracy: 0.875\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.6798313756783804 accuracy: 0.8472222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6593833367029825, 'train_accuracy': 0.6805555555555556}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 24] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 68] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6473227739334106\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.6504329840342203 accuracy: 0.6666666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.4250384072462718 accuracy: 0.7777777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.2729295988877614 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.19840320448080698 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.18335044384002686 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6473227739334106, 'train_accuracy': 0.6527777777777778}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 68] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 82] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6829786896705627\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 1 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 1]                     loss: 0.7247508764266968 accuracy: 0.6153846153846154\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 1]                     loss: 0.565244734287262 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 1]                     loss: 0.6038399934768677 accuracy: 0.6153846153846154\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 1]                     loss: 0.5052316188812256 accuracy: 0.7692307692307693\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 1]                     loss: 0.5541378259658813 accuracy: 0.7692307692307693\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6829786896705627, 'train_accuracy': 0.5384615384615384}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 82] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 50] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6506237387657166\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.5553131500879923 accuracy: 0.6805555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.5817281206448873 accuracy: 0.75\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.4017815788586934 accuracy: 0.8055555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.3042966624101003 accuracy: 0.8472222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.15223496655623117 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6506237387657166, 'train_accuracy': 0.5972222222222222}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 50] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 8] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6570637822151184\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.8418184717496237 accuracy: 0.6944444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.5239689946174622 accuracy: 0.7916666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.31195569535096485 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.19807995359102884 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.2444352606932322 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6570637822151184, 'train_accuracy': 0.6805555555555556}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 8] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 20] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6680917342503866\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.6913944681485494 accuracy: 0.5416666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.4684527317682902 accuracy: 0.75\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.3928532401720683 accuracy: 0.8194444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.3071040560801824 accuracy: 0.875\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.18975335856278738 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6680917342503866, 'train_accuracy': 0.625}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 20] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 80] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6902047395706177\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 1 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 1]                     loss: 0.6606312394142151 accuracy: 0.5384615384615384\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 1]                     loss: 0.6566018462181091 accuracy: 0.6153846153846154\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 1]                     loss: 0.540910005569458 accuracy: 0.6153846153846154\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 1]                     loss: 0.5587639212608337 accuracy: 0.6153846153846154\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 1]                     loss: 0.5398640632629395 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6902047395706177, 'train_accuracy': 0.5384615384615384}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 80] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 7] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.649956742922465\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.6328961849212646 accuracy: 0.6388888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.4729984402656555 accuracy: 0.75\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.34643375873565674 accuracy: 0.875\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.26874010264873505 accuracy: 0.8611111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.15740492939949036 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.649956742922465, 'train_accuracy': 0.6527777777777778}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 7] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 32] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6715556383132935\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.676565408706665 accuracy: 0.6527777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.391695241133372 accuracy: 0.8333333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.7057949304580688 accuracy: 0.7916666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.24661006033420563 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.24166992555061975 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6715556383132935, 'train_accuracy': 0.5972222222222222}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 32] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 56] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6450842618942261\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.6035473148028055 accuracy: 0.6666666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.38204529881477356 accuracy: 0.7916666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.250649760166804 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.28668046991030377 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.1498832404613495 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6450842618942261, 'train_accuracy': 0.6388888888888888}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 56] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 42] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6631250580151876\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.5761693120002747 accuracy: 0.6388888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.5386736293633779 accuracy: 0.7638888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.5453016757965088 accuracy: 0.7361111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.311548188328743 accuracy: 0.875\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.5566265434026718 accuracy: 0.8888888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6631250580151876, 'train_accuracy': 0.5833333333333334}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 42] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 12] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6685061852137247\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.5377670923868815 accuracy: 0.5972222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.4694742759068807 accuracy: 0.7638888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.34888334075609845 accuracy: 0.8611111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.14050572365522385 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.11091389258702596 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6685061852137247, 'train_accuracy': 0.5972222222222222}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 12] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 69] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6960227886835734\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.7655641635258993 accuracy: 0.4861111111111111\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.48197465141614276 accuracy: 0.7638888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.41789404551188153 accuracy: 0.8333333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.2926955620447795 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.21219818790753683 accuracy: 0.8888888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6960227886835734, 'train_accuracy': 0.5555555555555556}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 69] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6938130855560303\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.6388564705848694 accuracy: 0.5972222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.6330826381842295 accuracy: 0.6388888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.7193809250990549 accuracy: 0.5972222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.19896345088879266 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.22308644155661264 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6938130855560303, 'train_accuracy': 0.5138888888888888}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 1] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 66] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6671008268992106\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.6182800730069479 accuracy: 0.5833333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.4414210418860118 accuracy: 0.7083333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.4674898535013199 accuracy: 0.8888888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.2207069198290507 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.22474933664004007 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6671008268992106, 'train_accuracy': 0.6111111111111112}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 66] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 72] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6362838546435038\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.7125027775764465 accuracy: 0.6944444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.4618208607037862 accuracy: 0.75\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.35133107503255206 accuracy: 0.8888888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.31200558443864185 accuracy: 0.875\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.2742805828650792 accuracy: 0.875\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6362838546435038, 'train_accuracy': 0.6944444444444444}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 72] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 9] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6389737327893575\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.5371352632840475 accuracy: 0.5972222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.43131468693415326 accuracy: 0.7638888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.19752516349156699 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.16177778939406076 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.13072665284077326 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6389737327893575, 'train_accuracy': 0.6805555555555556}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 9] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 14] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6953269640604655\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.6322113076845804 accuracy: 0.5972222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.5344422459602356 accuracy: 0.7361111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.38240963220596313 accuracy: 0.8611111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.27824674050013226 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.22284047802289328 accuracy: 0.875\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6953269640604655, 'train_accuracy': 0.5833333333333334}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 14] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 44] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6451316475868225\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.5914883414904276 accuracy: 0.6805555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.5980708102385203 accuracy: 0.7222222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.6657671630382538 accuracy: 0.625\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.20436507960160574 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.30630507816871005 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6451316475868225, 'train_accuracy': 0.6388888888888888}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 44] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 52] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6554151376088461\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.7171634038289388 accuracy: 0.625\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.49904253085454303 accuracy: 0.75\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.4107009669144948 accuracy: 0.875\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.24048568805058798 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.19598259031772614 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6554151376088461, 'train_accuracy': 0.6527777777777778}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 52] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 39] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6496890584627787\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.5779240727424622 accuracy: 0.7083333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.5237852334976196 accuracy: 0.75\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.3864487111568451 accuracy: 0.8472222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.34048646688461304 accuracy: 0.875\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.28196728229522705 accuracy: 0.8888888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6496890584627787, 'train_accuracy': 0.6111111111111112}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 39] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 76] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6588780681292216\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.654947837193807 accuracy: 0.6805555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.5218313336372375 accuracy: 0.7777777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.6968532651662827 accuracy: 0.8333333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.16709586729605994 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.1501181274652481 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6588780681292216, 'train_accuracy': 0.6388888888888888}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 76] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 35] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6896145145098368\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.4799925585587819 accuracy: 0.6805555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.7475648323694865 accuracy: 0.75\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.5198071797688802 accuracy: 0.8333333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.2663791974385579 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.19993330538272858 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6896145145098368, 'train_accuracy': 0.6111111111111112}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 35] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 43] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6790390213330587\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.698712170124054 accuracy: 0.6388888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.4498356382052104 accuracy: 0.7777777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.3133150637149811 accuracy: 0.875\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.22857541839281717 accuracy: 0.8888888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.1764621138572693 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6790390213330587, 'train_accuracy': 0.625}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 43] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 63] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.661076287428538\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 1.0760860244433086 accuracy: 0.5972222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.7506664792696635 accuracy: 0.5416666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.29743930076559383 accuracy: 0.8055555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.824745645125707 accuracy: 0.7638888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.33009890994677943 accuracy: 0.7916666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.661076287428538, 'train_accuracy': 0.6666666666666666}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 63] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 78] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6378312110900879\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.5889652967453003 accuracy: 0.6527777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.5291934510072073 accuracy: 0.8055555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.3630705078442891 accuracy: 0.8888888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.2890207568804423 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.2290661782026291 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6378312110900879, 'train_accuracy': 0.7361111111111112}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 78] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 81] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6373119950294495\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 1 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 1]                     loss: 0.703593909740448 accuracy: 0.38461538461538464\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 1]                     loss: 0.49934250116348267 accuracy: 0.7692307692307693\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 1]                     loss: 0.5178005695343018 accuracy: 0.7692307692307693\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 1]                     loss: 0.6312044858932495 accuracy: 0.7692307692307693\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 1]                     loss: 0.5919906497001648 accuracy: 0.7692307692307693\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6373119950294495, 'train_accuracy': 0.6923076923076923}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 81] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 49] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6516820589701334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.718489944934845 accuracy: 0.625\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.47351641456286114 accuracy: 0.7777777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.3874027927716573 accuracy: 0.875\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.344972367088 accuracy: 0.8333333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.17252793659766516 accuracy: 0.875\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6516820589701334, 'train_accuracy': 0.6805555555555556}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 49] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 98] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.7126728296279907\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 1 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 1]                     loss: 0.7635379433631897 accuracy: 0.38461538461538464\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 1]                     loss: 0.7020277380943298 accuracy: 0.6153846153846154\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 1]                     loss: 0.6471165418624878 accuracy: 0.6153846153846154\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 1]                     loss: 0.5529340505599976 accuracy: 0.6153846153846154\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 1]                     loss: 0.5380219221115112 accuracy: 0.6153846153846154\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.7126728296279907, 'train_accuracy': 0.46153846153846156}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 98] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 88] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6669334173202515\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 1 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 1]                     loss: 0.6710093021392822 accuracy: 0.5384615384615384\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 1]                     loss: 0.6914171576499939 accuracy: 0.46153846153846156\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 1]                     loss: 0.6445137858390808 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 1]                     loss: 0.5646849870681763 accuracy: 0.8461538461538461\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 1]                     loss: 0.5253806114196777 accuracy: 0.8461538461538461\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6669334173202515, 'train_accuracy': 0.6153846153846154}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 88] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 22] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6714503566424052\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.6580551266670227 accuracy: 0.6527777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.4381044904390971 accuracy: 0.8194444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.3444524059693019 accuracy: 0.8194444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.29170988500118256 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.27425842980543774 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6714503566424052, 'train_accuracy': 0.5694444444444444}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 22] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 85] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6397899389266968\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 1 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 1]                     loss: 0.663705587387085 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 1]                     loss: 0.6151819825172424 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 1]                     loss: 0.5745460987091064 accuracy: 0.8461538461538461\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 1]                     loss: 0.5302285552024841 accuracy: 0.7692307692307693\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 1]                     loss: 0.4337885081768036 accuracy: 0.9230769230769231\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6397899389266968, 'train_accuracy': 0.5384615384615384}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 85] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 96] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6323546171188354\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 1 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 1]                     loss: 0.6985930800437927 accuracy: 0.38461538461538464\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 1]                     loss: 0.6033496260643005 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 1]                     loss: 0.5383806824684143 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 1]                     loss: 0.5351167321205139 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 1]                     loss: 0.4859852194786072 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6323546171188354, 'train_accuracy': 0.6923076923076923}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 96] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 3] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6434776981671652\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.5203846096992493 accuracy: 0.6944444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.5882695019245148 accuracy: 0.7638888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.45306100447972614 accuracy: 0.8333333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.15582385659217834 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.2003492017587026 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6434776981671652, 'train_accuracy': 0.7083333333333334}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 3] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 99] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6751705408096313\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 1 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 1]                     loss: 0.6734967231750488 accuracy: 0.5238095238095238\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 1]                     loss: 0.6261857151985168 accuracy: 0.6666666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 1]                     loss: 0.6741584539413452 accuracy: 0.5238095238095238\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 1]                     loss: 0.603561282157898 accuracy: 0.7142857142857143\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 1]                     loss: 0.569428026676178 accuracy: 0.7619047619047619\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6751705408096313, 'train_accuracy': 0.5238095238095238}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 99] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 4] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6714672843615214\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.6041609843571981 accuracy: 0.6805555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.5491133828957876 accuracy: 0.7083333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.3732243130604426 accuracy: 0.8333333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.23914272586504617 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.20984703054030737 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6714672843615214, 'train_accuracy': 0.6388888888888888}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 4] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 38] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6943349838256836\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.5838648776213328 accuracy: 0.6527777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.5423140525817871 accuracy: 0.7083333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.4091019928455353 accuracy: 0.8333333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.26097965737183887 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.2427187810341517 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6943349838256836, 'train_accuracy': 0.5555555555555556}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 38] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 13] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6531022588411967\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.6852609117825826 accuracy: 0.625\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.4711565574010213 accuracy: 0.7638888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.6255896886189779 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.1871751000483831 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.23057718575000763 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6531022588411967, 'train_accuracy': 0.6527777777777778}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 13] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 61] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6608935991923014\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.5009390314420065 accuracy: 0.625\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.7263861497243246 accuracy: 0.75\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.35276973247528076 accuracy: 0.8333333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.6047881245613098 accuracy: 0.8055555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.2794564664363861 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6608935991923014, 'train_accuracy': 0.6666666666666666}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 61] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 91] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6595749258995056\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 1 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 1]                     loss: 0.6624892950057983 accuracy: 0.46153846153846156\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 1]                     loss: 0.5861375331878662 accuracy: 0.7692307692307693\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 1]                     loss: 0.4995594620704651 accuracy: 0.7692307692307693\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 1]                     loss: 0.5526608824729919 accuracy: 0.7692307692307693\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 1]                     loss: 0.4586327373981476 accuracy: 0.7692307692307693\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6595749258995056, 'train_accuracy': 0.5384615384615384}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 91] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 48] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6427662173906962\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.6805333693822225 accuracy: 0.6388888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.5192924539248148 accuracy: 0.7638888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.40783971548080444 accuracy: 0.7638888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.2603067805369695 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.2592376818259557 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6427662173906962, 'train_accuracy': 0.75}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 48] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 10] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6865638693173727\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.6245531837145487 accuracy: 0.6527777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.5567493935426077 accuracy: 0.7222222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.27471689383188885 accuracy: 0.8333333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.17866097390651703 accuracy: 0.875\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.2455917646487554 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6865638693173727, 'train_accuracy': 0.6111111111111112}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 10] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 71] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.674678365389506\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.6498158176740011 accuracy: 0.6527777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.4764251112937927 accuracy: 0.7361111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.3072524170080821 accuracy: 0.8888888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.2738916054368019 accuracy: 0.875\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.20258734623591104 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.674678365389506, 'train_accuracy': 0.6111111111111112}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 71] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 28] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6514749924341837\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.6206591327985128 accuracy: 0.5416666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.6777477264404297 accuracy: 0.6666666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.5060387551784515 accuracy: 0.7083333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.2576325287421544 accuracy: 0.8888888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.2345193773508072 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6514749924341837, 'train_accuracy': 0.6805555555555556}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 28] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 87] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6551179885864258\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 1 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 1]                     loss: 0.7186350226402283 accuracy: 0.38461538461538464\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 1]                     loss: 0.47695910930633545 accuracy: 0.7692307692307693\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 1]                     loss: 0.5230035185813904 accuracy: 0.7692307692307693\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 1]                     loss: 0.5081928372383118 accuracy: 0.7692307692307693\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 1]                     loss: 0.5684166550636292 accuracy: 0.7692307692307693\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6551179885864258, 'train_accuracy': 0.6923076923076923}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 87] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 6] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6711940765380859\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.6328818996747335 accuracy: 0.6388888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.411148468653361 accuracy: 0.7777777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.28719379504521686 accuracy: 0.875\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.18427003423372904 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.2359114040931066 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6711940765380859, 'train_accuracy': 0.6944444444444444}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 6] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 33] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6632194916407267\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.5625094274679819 accuracy: 0.6388888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.544720858335495 accuracy: 0.7361111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.3469328284263611 accuracy: 0.8888888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.1643944854537646 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.32408773402373 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6632194916407267, 'train_accuracy': 0.6527777777777778}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 33] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 37] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6770751078923544\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.7185975313186646 accuracy: 0.5833333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.5574151277542114 accuracy: 0.7222222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.4442400634288788 accuracy: 0.7916666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.232847198843956 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.3118026753266652 accuracy: 0.8611111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6770751078923544, 'train_accuracy': 0.6111111111111112}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 37] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 73] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6531462470690409\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.7198629180590311 accuracy: 0.6388888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.5024272898832957 accuracy: 0.7638888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.27408599853515625 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.1861529548962911 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.16636578738689423 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6531462470690409, 'train_accuracy': 0.6944444444444444}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 73] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 58] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6812585989634196\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.7017181118329366 accuracy: 0.5555555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.5509773890177408 accuracy: 0.6944444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.429073969523112 accuracy: 0.8055555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.2674826631943385 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.25751934945583344 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6812585989634196, 'train_accuracy': 0.5}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 58] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 67] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6811206340789795\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.9651007850964864 accuracy: 0.5555555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.726729174455007 accuracy: 0.5277777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.7246993184089661 accuracy: 0.7361111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.39540305733680725 accuracy: 0.7916666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.5376147379477819 accuracy: 0.7777777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6811206340789795, 'train_accuracy': 0.6388888888888888}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 67] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 75] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.7065094312032064\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.6135477622350057 accuracy: 0.5416666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.532128781080246 accuracy: 0.6805555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.4688165485858917 accuracy: 0.7916666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.23538434008757272 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.19285563627878824 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.7065094312032064, 'train_accuracy': 0.5138888888888888}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 75] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 31] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6534164547920227\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.5885101954142252 accuracy: 0.6944444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.4616774519284566 accuracy: 0.7777777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.23043008148670197 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.12393846362829208 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.15660018722216287 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6534164547920227, 'train_accuracy': 0.6388888888888888}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 31] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 17] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6443825364112854\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.8579276700814565 accuracy: 0.6666666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.46747686465581256 accuracy: 0.8194444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.3159721593062083 accuracy: 0.8333333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.3097114811340968 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.19936306277910867 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6443825364112854, 'train_accuracy': 0.6388888888888888}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 17] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 5] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6767489711443583\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.6630174914995829 accuracy: 0.5555555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.4747934937477112 accuracy: 0.7222222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.2653575638930003 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.17730935414632162 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.19534046947956085 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6767489711443583, 'train_accuracy': 0.6388888888888888}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 5] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 41] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.637028972307841\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.5190275808175405 accuracy: 0.7083333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.5694409807523092 accuracy: 0.7222222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.36636317769686383 accuracy: 0.875\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.297881414492925 accuracy: 0.8888888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.24262140691280365 accuracy: 0.8888888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.637028972307841, 'train_accuracy': 0.625}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 41] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 65] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6949768463770548\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.65851362546285 accuracy: 0.6805555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.5248494148254395 accuracy: 0.7361111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.2793443550666173 accuracy: 0.875\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.2873031447331111 accuracy: 0.8472222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.20546172062555948 accuracy: 0.875\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6949768463770548, 'train_accuracy': 0.625}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 65] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 86] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.7710065841674805\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 1 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 1]                     loss: 0.7224730849266052 accuracy: 0.38461538461538464\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 1]                     loss: 0.6129145622253418 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 1]                     loss: 0.5617815852165222 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 1]                     loss: 0.4521484971046448 accuracy: 0.7692307692307693\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 1]                     loss: 0.49977973103523254 accuracy: 0.6153846153846154\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.7710065841674805, 'train_accuracy': 0.07692307692307693}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 86] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 57] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6501356164614359\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.7271396517753601 accuracy: 0.6111111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.32406210402647656 accuracy: 0.8194444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.2827855149904887 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.16136547674735388 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.12192154675722122 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6501356164614359, 'train_accuracy': 0.625}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 57] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 21] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6715909242630005\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.5865969856580099 accuracy: 0.625\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.49283450841903687 accuracy: 0.6944444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.42103976011276245 accuracy: 0.7361111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.21971112986405691 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.18397417664527893 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6715909242630005, 'train_accuracy': 0.625}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 21] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 55] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6591531038284302\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.6721739967664083 accuracy: 0.6111111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.5520410140355428 accuracy: 0.7222222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.4776185353597005 accuracy: 0.75\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.6336250305175781 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.21522900462150574 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6591531038284302, 'train_accuracy': 0.6111111111111112}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 55] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 40] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6982602079709371\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.7169459263483683 accuracy: 0.5694444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.5033391813437144 accuracy: 0.8194444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.4922543466091156 accuracy: 0.8472222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.24909891684850058 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.23048182328542074 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6982602079709371, 'train_accuracy': 0.5694444444444444}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 40] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 54] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6733450889587402\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.7129111886024475 accuracy: 0.5972222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.45432653029759723 accuracy: 0.8472222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.38272730509440106 accuracy: 0.8333333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.24661369621753693 accuracy: 0.8611111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.16410942375659943 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6733450889587402, 'train_accuracy': 0.7083333333333334}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 54] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 18] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6502452294031779\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.6341437300046285 accuracy: 0.5972222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.5006286005179087 accuracy: 0.7361111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.26788226266702014 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.2265643129746119 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.24931747714678446 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6502452294031779, 'train_accuracy': 0.5833333333333334}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 18] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 79] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6662138303120931\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.6096054712931315 accuracy: 0.6595744680851063\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.413150817155838 accuracy: 0.8085106382978723\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.28476810455322266 accuracy: 0.9042553191489362\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.1517399623990059 accuracy: 0.9680851063829787\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.13464810202519098 accuracy: 0.9468085106382979\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6662138303120931, 'train_accuracy': 0.6276595744680851}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 79] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6633348067601522\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.6083949108918508 accuracy: 0.6388888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.5118606388568878 accuracy: 0.7361111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.26160963376363117 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.21950087447961172 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.23249744872252145 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6633348067601522, 'train_accuracy': 0.6111111111111112}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 0] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 89] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6931008100509644\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 1 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 1]                     loss: 0.7389081120491028 accuracy: 0.38461538461538464\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 1]                     loss: 0.6291294097900391 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 1]                     loss: 0.615547239780426 accuracy: 0.6153846153846154\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 1]                     loss: 0.6233106255531311 accuracy: 0.6153846153846154\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 1]                     loss: 0.6163439154624939 accuracy: 0.6153846153846154\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6931008100509644, 'train_accuracy': 0.46153846153846156}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 89] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 84] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6579068899154663\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 1 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 1]                     loss: 0.7581759691238403 accuracy: 0.23076923076923078\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 1]                     loss: 0.641455888748169 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 1]                     loss: 0.6634150743484497 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 1]                     loss: 0.575721025466919 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 1]                     loss: 0.4895152449607849 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6579068899154663, 'train_accuracy': 0.6923076923076923}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 84] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 16] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6651771068572998\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.6304887930552164 accuracy: 0.6388888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.5745194951693217 accuracy: 0.6944444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.32397663593292236 accuracy: 0.8333333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.41592495640118915 accuracy: 0.875\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.2930339549978574 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6651771068572998, 'train_accuracy': 0.6666666666666666}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 16] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 97] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.5959697961807251\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 1 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 1]                     loss: 0.6524823904037476 accuracy: 0.5384615384615384\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 1]                     loss: 0.4988543391227722 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 1]                     loss: 0.44012123346328735 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 1]                     loss: 0.49146175384521484 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 1]                     loss: 0.5262858867645264 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.5959697961807251, 'train_accuracy': 0.6923076923076923}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 97] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 74] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6337655981381735\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.7067944407463074 accuracy: 0.6388888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.48619671662648517 accuracy: 0.7777777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.21185938517252603 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.13116095215082169 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.16283285866181055 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6337655981381735, 'train_accuracy': 0.625}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 74] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 94] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6417880654335022\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 1 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 1]                     loss: 0.7339833378791809 accuracy: 0.38461538461538464\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 1]                     loss: 0.5740829706192017 accuracy: 0.7692307692307693\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 1]                     loss: 0.5681433081626892 accuracy: 0.7692307692307693\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 1]                     loss: 0.528058648109436 accuracy: 0.7692307692307693\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 1]                     loss: 0.46377676725387573 accuracy: 0.7692307692307693\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6417880654335022, 'train_accuracy': 0.6923076923076923}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 94] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 34] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6824544866879781\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.48113298416137695 accuracy: 0.6527777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.5853837430477142 accuracy: 0.75\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.38131485382715863 accuracy: 0.8333333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.2759116192658742 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.2363286018371582 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6824544866879781, 'train_accuracy': 0.5694444444444444}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 34] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 83] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.62943434715271\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 1 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 1]                     loss: 0.6745153069496155 accuracy: 0.5384615384615384\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 1]                     loss: 0.47397011518478394 accuracy: 0.8461538461538461\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 1]                     loss: 0.4614993929862976 accuracy: 0.8461538461538461\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 1]                     loss: 0.4811033010482788 accuracy: 0.8461538461538461\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 1]                     loss: 0.4321179687976837 accuracy: 0.8461538461538461\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.62943434715271, 'train_accuracy': 0.7692307692307693}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 83] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 26] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6649986902872721\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.6429674426714579 accuracy: 0.6111111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.7862998942534128 accuracy: 0.6944444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 1.0025046666463215 accuracy: 0.3333333333333333\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.1936727116505305 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.23793972531954447 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6649986902872721, 'train_accuracy': 0.5694444444444444}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 26] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 92] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6552045345306396\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 1 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 1]                     loss: 0.718877375125885 accuracy: 0.3076923076923077\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 1]                     loss: 0.6025108098983765 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 1]                     loss: 0.5415859818458557 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 1]                     loss: 0.5326207876205444 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 1]                     loss: 0.4720320701599121 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6552045345306396, 'train_accuracy': 0.7692307692307693}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 92] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 2] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6734608014424642\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.7583633661270142 accuracy: 0.5416666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.4599196215470632 accuracy: 0.7777777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.43294743696848553 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.1596005062262217 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.23014363646507263 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6734608014424642, 'train_accuracy': 0.6111111111111112}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 2] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 30] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6547624270121256\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.6473244229952494 accuracy: 0.6944444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.48936503132184345 accuracy: 0.7083333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.2902139127254486 accuracy: 0.875\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.19428126017252603 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.26413971185684204 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6547624270121256, 'train_accuracy': 0.6527777777777778}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 30] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 62] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6537982622782389\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.7168600161870321 accuracy: 0.6388888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.4648810823758443 accuracy: 0.8194444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.407551387945811 accuracy: 0.8611111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.1936626434326172 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.19238982101281485 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6537982622782389, 'train_accuracy': 0.6527777777777778}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 62] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 95] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.7306921482086182\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 1 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 1]                     loss: 0.7052494287490845 accuracy: 0.46153846153846156\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 1]                     loss: 0.6448312401771545 accuracy: 0.6153846153846154\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 1]                     loss: 0.6412887573242188 accuracy: 0.6153846153846154\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 1]                     loss: 0.43809178471565247 accuracy: 0.9230769230769231\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 1]                     loss: 0.45246759057044983 accuracy: 0.9230769230769231\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.7306921482086182, 'train_accuracy': 0.46153846153846156}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 95] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 29] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6339235504468282\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.5260793069998423 accuracy: 0.5972222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.4258171220620473 accuracy: 0.7916666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.2753695795933406 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.17204754054546356 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.1550270070632299 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6339235504468282, 'train_accuracy': 0.7777777777777778}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 29] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 11] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6412256956100464\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.5301340818405151 accuracy: 0.625\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.6018702586491903 accuracy: 0.7638888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.5473430852095286 accuracy: 0.8333333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.15460023283958435 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.1411442905664444 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6412256956100464, 'train_accuracy': 0.6388888888888888}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 11] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 77] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6539984742800394\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.5691065589586893 accuracy: 0.7083333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.45483383536338806 accuracy: 0.7777777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.39909671743710834 accuracy: 0.7916666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.22161844869454703 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.18971270322799683 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6539984742800394, 'train_accuracy': 0.6527777777777778}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 77] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 47] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6731428702672323\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.853324810663859 accuracy: 0.625\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.4235843022664388 accuracy: 0.8333333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.5091222127278646 accuracy: 0.7361111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.3267764498790105 accuracy: 0.8055555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.33465192715326947 accuracy: 0.8472222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6731428702672323, 'train_accuracy': 0.6805555555555556}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 47] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 51] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6726340254147848\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.7435004512468973 accuracy: 0.5277777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.4409235715866089 accuracy: 0.8055555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.2274304380019506 accuracy: 0.8888888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.3713220035036405 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.13869668543338776 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6726340254147848, 'train_accuracy': 0.6111111111111112}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 51] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 60] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6692541639010111\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.6586703658103943 accuracy: 0.5694444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.5175874431927999 accuracy: 0.7222222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.3408272663752238 accuracy: 0.875\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.21493500471115112 accuracy: 0.8888888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.15759088595708212 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6692541639010111, 'train_accuracy': 0.6111111111111112}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 60] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 27] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6296921769777933\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.5992057124773661 accuracy: 0.6111111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.48265334963798523 accuracy: 0.7777777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.3220413376887639 accuracy: 0.8888888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.3048795908689499 accuracy: 0.8611111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.26494639615217846 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6296921769777933, 'train_accuracy': 0.7777777777777778}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 27] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 46] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6705004970232645\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.44941427807013196 accuracy: 0.7083333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.6513311862945557 accuracy: 0.8055555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.49859167138735455 accuracy: 0.8194444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.28581543266773224 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.3330262154340744 accuracy: 0.8888888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6705004970232645, 'train_accuracy': 0.7083333333333334}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 46] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 15] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6842531164487203\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.7635951638221741 accuracy: 0.5972222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.4984864294528961 accuracy: 0.7777777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.3100780149300893 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.44373315076033276 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.17213933169841766 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6842531164487203, 'train_accuracy': 0.5555555555555556}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 15] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 90] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6529171466827393\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 1 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 1]                     loss: 0.685758650302887 accuracy: 0.5384615384615384\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 1]                     loss: 0.49647125601768494 accuracy: 0.7692307692307693\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 1]                     loss: 0.5119557976722717 accuracy: 0.7692307692307693\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 1]                     loss: 0.5130363702774048 accuracy: 0.7692307692307693\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 1]                     loss: 0.5198602080345154 accuracy: 0.7692307692307693\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6529171466827393, 'train_accuracy': 0.6153846153846154}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 90] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 64] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6594919164975485\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.6660118699073792 accuracy: 0.6111111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.4859218696753184 accuracy: 0.7638888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.356320599714915 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.21488197147846222 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.40335480868816376 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6594919164975485, 'train_accuracy': 0.6666666666666666}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 64] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 23] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6277732849121094\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.574965904156367 accuracy: 0.6527777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.4478996197382609 accuracy: 0.7638888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.3043170968691508 accuracy: 0.875\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.1451853091518084 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.20787176489830017 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6277732849121094, 'train_accuracy': 0.7083333333333334}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 23] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 93] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6735340356826782\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 1 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 1]                     loss: 0.7714557647705078 accuracy: 0.23076923076923078\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 1]                     loss: 0.6375575661659241 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 1]                     loss: 0.6292240619659424 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 1]                     loss: 0.5650333762168884 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 1]                     loss: 0.5453003644943237 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6735340356826782, 'train_accuracy': 0.6153846153846154}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 93] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 59] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6469877362251282\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.9332903027534485 accuracy: 0.5416666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.6938043634096781 accuracy: 0.5833333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.750853955745697 accuracy: 0.6944444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.2759015162785848 accuracy: 0.8472222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.2993144392967224 accuracy: 0.8888888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6469877362251282, 'train_accuracy': 0.6944444444444444}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 59] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 19] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6676001151402792\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.5213170846303304 accuracy: 0.6527777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.5563482294480006 accuracy: 0.7916666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.33783289790153503 accuracy: 0.8611111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.2319002499183019 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.17741726835568747 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6676001151402792, 'train_accuracy': 0.6388888888888888}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 19] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 45] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6681710680325826\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.5087761282920837 accuracy: 0.6666666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.5700781444708506 accuracy: 0.7222222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.2753371000289917 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.307122344772021 accuracy: 0.875\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.3689303547143936 accuracy: 0.875\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6681710680325826, 'train_accuracy': 0.625}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 45] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 53] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6638529499371847\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.6377341349919637 accuracy: 0.5694444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.48837772011756897 accuracy: 0.7361111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.4615514079729716 accuracy: 0.8472222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.18150239189465842 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.3790964260697365 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6638529499371847, 'train_accuracy': 0.6111111111111112}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 53] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 70] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6448667645454407\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.5849503477414449 accuracy: 0.6111111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.6265316704909006 accuracy: 0.7638888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.6076790591080984 accuracy: 0.7222222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.2246692180633545 accuracy: 0.8888888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.19091405719518661 accuracy: 0.8888888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6448667645454407, 'train_accuracy': 0.6527777777777778}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 70] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 25] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6486931840578715\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.6495218276977539 accuracy: 0.5277777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.4809532364209493 accuracy: 0.7638888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.2784670790036519 accuracy: 0.8611111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.22715653479099274 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.17484849443038306 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6486931840578715, 'train_accuracy': 0.6666666666666666}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 25] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 36] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6587111353874207\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.5409928858280182 accuracy: 0.6527777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.5376461644967397 accuracy: 0.7222222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.34494489928086597 accuracy: 0.7916666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.18166806548833847 accuracy: 0.9305555555555556\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-08-24 10:45:52,930 | server.py:232 | fit_round 1 received 100 results and 0 failures\n",
            "DEBUG:flwr:fit_round 1 received 100 results and 0 failures\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.24231798450152078 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6587111353874207, 'train_accuracy': 0.6111111111111112}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 36] get_parameters\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING flwr 2023-08-24 10:46:00,494 | fedavg.py:243 | No fit_metrics_aggregation_fn provided\n",
            "WARNING:flwr:No fit_metrics_aggregation_fn provided\n",
            "DEBUG flwr 2023-08-24 10:46:00,512 | server.py:168 | evaluate_round 1: strategy sampled 100 clients (out of 100)\n",
            "DEBUG:flwr:evaluate_round 1: strategy sampled 100 clients (out of 100)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 34] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.029656633734703064\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.029656633734703064, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 12] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.7813881039619446\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.7813881039619446, 'test_accuracy': 0.7142857142857143}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 28] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 1.2250934839248657\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 1.2250934839248657, 'test_accuracy': 0.5714285714285714}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 95] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.3932033181190491\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.3932033181190491, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 45] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.4846607744693756\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.4846607744693756, 'test_accuracy': 0.7142857142857143}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 61] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.5685240030288696\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.5685240030288696, 'test_accuracy': 0.7142857142857143}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 76] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.7712317705154419\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.7712317705154419, 'test_accuracy': 0.5714285714285714}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 85] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 1.4413628578186035\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 1.4413628578186035, 'test_accuracy': 0.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 47] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.22862212359905243\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.22862212359905243, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 64] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6431770920753479\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.6431770920753479, 'test_accuracy': 0.7142857142857143}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 26] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.9781996607780457\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.9781996607780457, 'test_accuracy': 0.5714285714285714}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 32] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.39967575669288635\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.39967575669288635, 'test_accuracy': 0.8571428571428571}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 29] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.7023859620094299\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.7023859620094299, 'test_accuracy': 0.5714285714285714}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 35] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.34624606370925903\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.34624606370925903, 'test_accuracy': 0.8571428571428571}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 90] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 1.2914822101593018\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 1.2914822101593018, 'test_accuracy': 0.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 56] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.1437751203775406\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.1437751203775406, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 13] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.5957866311073303\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.5957866311073303, 'test_accuracy': 0.8571428571428571}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 75] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.4606856405735016\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.4606856405735016, 'test_accuracy': 0.7142857142857143}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 43] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.3743290305137634\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.3743290305137634, 'test_accuracy': 0.7142857142857143}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 67] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.27894240617752075\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.27894240617752075, 'test_accuracy': 0.8571428571428571}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 24] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.38953086733818054\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.38953086733818054, 'test_accuracy': 0.7142857142857143}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 5] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 1.049198865890503\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 1.049198865890503, 'test_accuracy': 0.42857142857142855}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 58] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.3451083302497864\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.3451083302497864, 'test_accuracy': 0.8571428571428571}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 98] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 1.0310931205749512\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 1.0310931205749512, 'test_accuracy': 0.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 91] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 1.3180004358291626\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 1.3180004358291626, 'test_accuracy': 0.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 16] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.14055228233337402\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.14055228233337402, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 23] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.5056499242782593\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.5056499242782593, 'test_accuracy': 0.7142857142857143}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 80] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 1.3229527473449707\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 1.3229527473449707, 'test_accuracy': 0.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 11] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.41545507311820984\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.41545507311820984, 'test_accuracy': 0.7142857142857143}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 2] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.9689134359359741\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.9689134359359741, 'test_accuracy': 0.5714285714285714}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 18] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6182120442390442\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.6182120442390442, 'test_accuracy': 0.7142857142857143}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 92] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 1.086785078048706\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 1.086785078048706, 'test_accuracy': 0.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 74] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.3871771991252899\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.3871771991252899, 'test_accuracy': 0.7142857142857143}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 6] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.3249507546424866\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.3249507546424866, 'test_accuracy': 0.8571428571428571}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 42] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.510883629322052\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.510883629322052, 'test_accuracy': 0.5714285714285714}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 71] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.15276500582695007\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.15276500582695007, 'test_accuracy': 0.8571428571428571}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 46] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6687554717063904\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.6687554717063904, 'test_accuracy': 0.5714285714285714}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 31] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.32505226135253906\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.32505226135253906, 'test_accuracy': 0.8571428571428571}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 8] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.49488019943237305\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.49488019943237305, 'test_accuracy': 0.7142857142857143}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 60] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.3904438614845276\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.3904438614845276, 'test_accuracy': 0.8571428571428571}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 14] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6187044382095337\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.6187044382095337, 'test_accuracy': 0.7142857142857143}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 1] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 1.0719056129455566\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 1.0719056129455566, 'test_accuracy': 0.5714285714285714}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 30] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.1457587480545044\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.1457587480545044, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 17] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.46316882967948914\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.46316882967948914, 'test_accuracy': 0.7142857142857143}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 0] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.2106093168258667\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.2106093168258667, 'test_accuracy': 0.8571428571428571}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 49] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.674562931060791\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.674562931060791, 'test_accuracy': 0.5714285714285714}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 9] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.791910707950592\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.791910707950592, 'test_accuracy': 0.42857142857142855}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 86] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 1.0682404041290283\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 1.0682404041290283, 'test_accuracy': 0.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 40] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.49573928117752075\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.49573928117752075, 'test_accuracy': 0.7142857142857143}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 89] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 1.501734972000122\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 1.501734972000122, 'test_accuracy': 0.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 33] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.17202888429164886\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.17202888429164886, 'test_accuracy': 0.8571428571428571}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 66] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.2440945953130722\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.2440945953130722, 'test_accuracy': 0.8571428571428571}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 99] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 1.3718135356903076\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 1.3718135356903076, 'test_accuracy': 0.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 3] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 1.0653244256973267\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 1.0653244256973267, 'test_accuracy': 0.42857142857142855}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 70] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.4181470274925232\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.4181470274925232, 'test_accuracy': 0.7142857142857143}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 82] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.49526020884513855\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.49526020884513855, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 15] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.251883864402771\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.251883864402771, 'test_accuracy': 0.8571428571428571}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 50] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6423107385635376\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.6423107385635376, 'test_accuracy': 0.5714285714285714}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 93] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 1.0339038372039795\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 1.0339038372039795, 'test_accuracy': 0.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 73] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.931468665599823\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.931468665599823, 'test_accuracy': 0.5714285714285714}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 54] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.554196298122406\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.554196298122406, 'test_accuracy': 0.7142857142857143}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 44] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.9316145181655884\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.9316145181655884, 'test_accuracy': 0.5714285714285714}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 59] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.9390419721603394\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.9390419721603394, 'test_accuracy': 0.42857142857142855}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 65] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.7413216829299927\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.7413216829299927, 'test_accuracy': 0.5714285714285714}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 20] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.2985888421535492\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.2985888421535492, 'test_accuracy': 0.8571428571428571}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 68] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.48450449109077454\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.48450449109077454, 'test_accuracy': 0.5714285714285714}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 38] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.29289084672927856\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.29289084672927856, 'test_accuracy': 0.8571428571428571}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 53] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.3884628117084503\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.3884628117084503, 'test_accuracy': 0.8571428571428571}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 83] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 1.072551965713501\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 1.072551965713501, 'test_accuracy': 0.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 52] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 1.0038779973983765\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 1.0038779973983765, 'test_accuracy': 0.5714285714285714}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 27] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.08411593735218048\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.08411593735218048, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 57] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.5217083096504211\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.5217083096504211, 'test_accuracy': 0.8571428571428571}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 63] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6460700035095215\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.6460700035095215, 'test_accuracy': 0.5714285714285714}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 81] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.8995465040206909\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.8995465040206909, 'test_accuracy': 0.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 69] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.38748428225517273\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.38748428225517273, 'test_accuracy': 0.8571428571428571}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 51] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 1.1081467866897583\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 1.1081467866897583, 'test_accuracy': 0.5714285714285714}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 72] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6835775375366211\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.6835775375366211, 'test_accuracy': 0.5714285714285714}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 4] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 1.1126072406768799\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 1.1126072406768799, 'test_accuracy': 0.5714285714285714}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 10] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.26510703563690186\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.26510703563690186, 'test_accuracy': 0.8571428571428571}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 19] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.8677539825439453\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.8677539825439453, 'test_accuracy': 0.42857142857142855}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 41] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.09204216301441193\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.09204216301441193, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 36] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.37069541215896606\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.37069541215896606, 'test_accuracy': 0.8571428571428571}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 96] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 1.2340830564498901\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 1.2340830564498901, 'test_accuracy': 0.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 77] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.5086984634399414\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.5086984634399414, 'test_accuracy': 0.7142857142857143}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 94] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.5870639681816101\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.5870639681816101, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 55] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.43059220910072327\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.43059220910072327, 'test_accuracy': 0.8571428571428571}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 21] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.5515959858894348\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.5515959858894348, 'test_accuracy': 0.5714285714285714}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 7] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.4078080654144287\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.4078080654144287, 'test_accuracy': 0.8571428571428571}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 78] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 1.3144687414169312\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 1.3144687414169312, 'test_accuracy': 0.2857142857142857}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 37] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 1.2418323755264282\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 1.2418323755264282, 'test_accuracy': 0.2857142857142857}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 87] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.3260478973388672\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.3260478973388672, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 97] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 1.0591685771942139\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 1.0591685771942139, 'test_accuracy': 0.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 39] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.341492623090744\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.341492623090744, 'test_accuracy': 0.8571428571428571}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 84] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 1.0245157480239868\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 1.0245157480239868, 'test_accuracy': 0.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 79] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.9033214449882507\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.9033214449882507, 'test_accuracy': 0.6}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 48] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.17650581896305084\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.17650581896305084, 'test_accuracy': 0.8571428571428571}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 22] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.1562025099992752\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.1562025099992752, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 25] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.9147524833679199\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.9147524833679199, 'test_accuracy': 0.5714285714285714}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 88] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.44026705622673035\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.44026705622673035, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 62] evaluate, config: {}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-08-24 10:47:00,570 | server.py:182 | evaluate_round 1 received 100 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 1 received 100 results and 0 failures\n",
            "DEBUG flwr 2023-08-24 10:47:00,574 | server.py:218 | fit_round 2: strategy sampled 100 clients (out of 100)\n",
            "DEBUG:flwr:fit_round 2: strategy sampled 100 clients (out of 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.2574920654296875\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.2574920654296875, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 14] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.5495376686255137\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.534538189570109 accuracy: 0.7638888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.4497026205062866 accuracy: 0.7916666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.3108542412519455 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.26376229027907055 accuracy: 0.875\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.2199884702761968 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.5495376686255137, 'train_accuracy': 0.7638888888888888}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 14] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 34] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.458957960208257\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.4987148841222127 accuracy: 0.8333333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.31524565319220227 accuracy: 0.8611111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.18409660955270132 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.1418329837421576 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.15750427544116974 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.458957960208257, 'train_accuracy': 0.8055555555555556}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 34] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 3] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.43418235580126446\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.3302788933118184 accuracy: 0.8472222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.24127340813477835 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.13652325669924417 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.10369646052519481 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.06738862891991933 accuracy: 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.43418235580126446, 'train_accuracy': 0.75}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 3] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 27] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.345452422897021\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.3829126755396525 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.25099176665147144 accuracy: 0.8888888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.23100184897581735 accuracy: 0.8888888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.13023159901301065 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.10421009734272957 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.345452422897021, 'train_accuracy': 0.8055555555555556}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 27] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 5] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.4817838867505391\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.4773630698521932 accuracy: 0.8055555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.2443200796842575 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.2512999027967453 accuracy: 0.8888888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.09206971650322278 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.08077327286203702 accuracy: 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.4817838867505391, 'train_accuracy': 0.75}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 5] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 86] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.719436764717102\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 1 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 1]                     loss: 0.8954382538795471 accuracy: 0.6153846153846154\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 1]                     loss: 0.6845503449440002 accuracy: 0.5384615384615384\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 1]                     loss: 0.5537275075912476 accuracy: 0.7692307692307693\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 1]                     loss: 0.5320950150489807 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 1]                     loss: 0.4487941861152649 accuracy: 0.7692307692307693\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.719436764717102, 'train_accuracy': 0.6153846153846154}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 86] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 74] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.38390765090783435\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.3335921068986257 accuracy: 0.8611111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.3040781219800313 accuracy: 0.8888888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.1299903839826584 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.08735918998718262 accuracy: 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.1020253524184227 accuracy: 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.38390765090783435, 'train_accuracy': 0.8194444444444444}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 74] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 66] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.4996995727221171\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.36650054653485614 accuracy: 0.8194444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.405062993367513 accuracy: 0.8194444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.11956181873877843 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.1866146003206571 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.10044094175100327 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.4996995727221171, 'train_accuracy': 0.7916666666666666}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 66] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 56] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.3648196955521901\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.25138084093729657 accuracy: 0.8888888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.25761909782886505 accuracy: 0.875\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.16254563629627228 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.1011525218685468 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.09185764441887538 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.3648196955521901, 'train_accuracy': 0.8472222222222222}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 56] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 85] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.7255350351333618\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 1 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 1]                     loss: 1.1069998741149902 accuracy: 0.46153846153846156\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 1]                     loss: 0.6323919296264648 accuracy: 0.6153846153846154\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 1]                     loss: 0.7538242340087891 accuracy: 0.5384615384615384\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 1]                     loss: 0.6337063908576965 accuracy: 0.5384615384615384\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 1]                     loss: 0.5201248526573181 accuracy: 0.6153846153846154\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.7255350351333618, 'train_accuracy': 0.5384615384615384}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 85] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 7] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.47060953577359516\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.422145277261734 accuracy: 0.7916666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.2488562191526095 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.21613635619481406 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.07506748164693515 accuracy: 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.20163122564554214 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.47060953577359516, 'train_accuracy': 0.75}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 7] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 23] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.30226601163546246\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.2809292823076248 accuracy: 0.875\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.20653719206651053 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.26370800534884137 accuracy: 0.8888888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.08929003526767094 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.10062432537476222 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.30226601163546246, 'train_accuracy': 0.8611111111111112}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 23] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 11] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.29743961493174237\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.29598528146743774 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.22253515323003134 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.0897537258764108 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.23438547054926553 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.07899212961395581 accuracy: 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.29743961493174237, 'train_accuracy': 0.8333333333333334}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 11] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 18] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.539331724246343\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.4148743450641632 accuracy: 0.8333333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.3295583426952362 accuracy: 0.8611111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.1894120822350184 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.19607020169496536 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.1324380338191986 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.539331724246343, 'train_accuracy': 0.7916666666666666}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 18] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 88] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.7040107250213623\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 1 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 1]                     loss: 1.147135615348816 accuracy: 0.46153846153846156\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 1]                     loss: 0.641669511795044 accuracy: 0.6153846153846154\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 1]                     loss: 0.7933916449546814 accuracy: 0.5384615384615384\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 1]                     loss: 0.7999661564826965 accuracy: 0.5384615384615384\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 1]                     loss: 0.778557538986206 accuracy: 0.5384615384615384\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.7040107250213623, 'train_accuracy': 0.5384615384615384}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 88] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 35] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.4751151700814565\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.34943358103434247 accuracy: 0.8472222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.2992962747812271 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.137029101451238 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.1112108901143074 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.09696213528513908 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.4751151700814565, 'train_accuracy': 0.7638888888888888}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 35] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 98] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.9643443822860718\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 1 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 1]                     loss: 1.302020788192749 accuracy: 0.38461538461538464\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 1]                     loss: 0.7111194133758545 accuracy: 0.5384615384615384\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 1]                     loss: 0.8070700764656067 accuracy: 0.6153846153846154\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 1]                     loss: 0.9124988317489624 accuracy: 0.6153846153846154\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 1]                     loss: 0.7792470455169678 accuracy: 0.6153846153846154\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.9643443822860718, 'train_accuracy': 0.38461538461538464}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 98] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 55] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.5499510665734609\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.5429591536521912 accuracy: 0.7916666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.8072071075439453 accuracy: 0.5555555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.2538447404901187 accuracy: 0.8333333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.5263491272926331 accuracy: 0.8333333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.18121126790841421 accuracy: 0.8611111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.5499510665734609, 'train_accuracy': 0.7777777777777778}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 55] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 49] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.5724420646826426\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.430338313182195 accuracy: 0.7777777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.4745478431383769 accuracy: 0.8055555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.34660786390304565 accuracy: 0.8888888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.12800786395867667 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.31471237043539685 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.5724420646826426, 'train_accuracy': 0.8055555555555556}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 49] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 37] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.4657079329093297\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.4720401068528493 accuracy: 0.7777777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.4216235280036926 accuracy: 0.7916666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.24315645297368368 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.14072528729836145 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.1566157986720403 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.4657079329093297, 'train_accuracy': 0.7361111111111112}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 37] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 75] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6474534273147583\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.49694379170735675 accuracy: 0.7777777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.37180057168006897 accuracy: 0.8472222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.20147396375735602 accuracy: 0.8888888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.23147193839152655 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.14549035330613455 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6474534273147583, 'train_accuracy': 0.75}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 75] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 90] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 1.0075485706329346\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 1 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 1]                     loss: 1.4802969694137573 accuracy: 0.23076923076923078\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 1]                     loss: 0.4379311800003052 accuracy: 0.7692307692307693\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 1]                     loss: 0.7072229981422424 accuracy: 0.7692307692307693\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 1]                     loss: 0.7929786443710327 accuracy: 0.7692307692307693\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 1]                     loss: 0.7966179251670837 accuracy: 0.7692307692307693\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 1.0075485706329346, 'train_accuracy': 0.23076923076923078}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 90] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 22] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.5148405134677887\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.5541071196397146 accuracy: 0.7361111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.424982488155365 accuracy: 0.8611111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.2234447399775187 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.11036953081687291 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.10613414148489635 accuracy: 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.5148405134677887, 'train_accuracy': 0.7638888888888888}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 22] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 81] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 1.036708950996399\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 1 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 1]                     loss: 1.5130430459976196 accuracy: 0.23076923076923078\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 1]                     loss: 0.623753547668457 accuracy: 0.7692307692307693\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 1]                     loss: 0.7654410004615784 accuracy: 0.7692307692307693\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 1]                     loss: 0.9610188603401184 accuracy: 0.7692307692307693\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 1]                     loss: 0.9527978301048279 accuracy: 0.7692307692307693\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 1.036708950996399, 'train_accuracy': 0.23076923076923078}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 81] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 21] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.49950166543324787\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.47602443893750507 accuracy: 0.7361111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.2782331109046936 accuracy: 0.875\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.2465358724196752 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.12428140143553416 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.23820492376883826 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.49950166543324787, 'train_accuracy': 0.7222222222222222}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 21] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 20] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6163167556126913\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.48651760816574097 accuracy: 0.7638888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.28167929251988727 accuracy: 0.8888888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.1725036253531774 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.1775479018688202 accuracy: 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.11388640850782394 accuracy: 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6163167556126913, 'train_accuracy': 0.7222222222222222}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 20] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 64] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.33225325246651966\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.52015021443367 accuracy: 0.75\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.37821946293115616 accuracy: 0.7916666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.14505006621281305 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.14094696442286173 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.18967321515083313 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.33225325246651966, 'train_accuracy': 0.7777777777777778}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 64] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 94] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.9373140931129456\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 1 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 1]                     loss: 1.71678626537323 accuracy: 0.23076923076923078\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 1]                     loss: 0.5375955700874329 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 1]                     loss: 0.771569550037384 accuracy: 0.7692307692307693\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 1]                     loss: 0.8306298851966858 accuracy: 0.7692307692307693\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 1]                     loss: 0.8904593586921692 accuracy: 0.7692307692307693\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.9373140931129456, 'train_accuracy': 0.23076923076923078}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 94] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 45] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.3446699281533559\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.49481189747651416 accuracy: 0.8194444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.39172282814979553 accuracy: 0.7638888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.1348800684014956 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.15101053286343813 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.14753354713320732 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.3446699281533559, 'train_accuracy': 0.8055555555555556}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 45] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 61] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.48845064640045166\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.6254482964674631 accuracy: 0.7777777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.5499304632345835 accuracy: 0.6944444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.4311552991469701 accuracy: 0.8194444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.14145831515391669 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.09987712651491165 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.48845064640045166, 'train_accuracy': 0.8333333333333334}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 61] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 40] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.47725964585940045\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.603137731552124 accuracy: 0.75\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.3676268259684245 accuracy: 0.875\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.21718322485685349 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.13621621330579123 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.15231841057538986 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.47725964585940045, 'train_accuracy': 0.75}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 40] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 96] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.8196271061897278\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 1 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 1]                     loss: 1.4580446481704712 accuracy: 0.3076923076923077\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 1]                     loss: 0.6055901050567627 accuracy: 0.7692307692307693\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 1]                     loss: 0.720111608505249 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 1]                     loss: 1.0024933815002441 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 1]                     loss: 1.0322288274765015 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.8196271061897278, 'train_accuracy': 0.3076923076923077}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 96] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 68] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.40983134508132935\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.3883029321829478 accuracy: 0.8333333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.23488773902257284 accuracy: 0.8888888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.2152912567059199 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.13325561583042145 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.10991388807694118 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.40983134508132935, 'train_accuracy': 0.8333333333333334}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 68] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 28] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6619922518730164\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.4531732201576233 accuracy: 0.7916666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.33413171768188477 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.4010150581598282 accuracy: 0.875\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.0997654398282369 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.12401160101095836 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6619922518730164, 'train_accuracy': 0.7638888888888888}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 28] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 39] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.5472112397352854\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.5147423247496287 accuracy: 0.7916666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.4575139284133911 accuracy: 0.8055555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.4515380561351776 accuracy: 0.8194444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.22212478518486023 accuracy: 0.875\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.293754905462265 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.5472112397352854, 'train_accuracy': 0.7777777777777778}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 39] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 29] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.27683494985103607\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.28057073056697845 accuracy: 0.8333333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.2309552530447642 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.14570626119772592 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.10710170865058899 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.09443809961279233 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.27683494985103607, 'train_accuracy': 0.8333333333333334}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 29] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 77] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.3623112738132477\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.5109164913495382 accuracy: 0.7777777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.3036873737970988 accuracy: 0.875\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.18244391679763794 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.21115049719810486 accuracy: 0.8472222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.2992948417862256 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.3623112738132477, 'train_accuracy': 0.8472222222222222}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 77] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 24] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.3834332078695297\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.45504605770111084 accuracy: 0.7777777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.32229185104370117 accuracy: 0.8194444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.2701113373041153 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.1641722321510315 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.14541434744993845 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.3834332078695297, 'train_accuracy': 0.7916666666666666}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 24] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 84] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.815126359462738\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 1 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 1]                     loss: 1.5275547504425049 accuracy: 0.3076923076923077\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 1]                     loss: 0.698317289352417 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 1]                     loss: 0.8083251714706421 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 1]                     loss: 1.019374132156372 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 1]                     loss: 1.0099214315414429 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.815126359462738, 'train_accuracy': 0.38461538461538464}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 84] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 4] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.40058504541714984\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.38678161303202313 accuracy: 0.7916666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.4081584910551707 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.549985279639562 accuracy: 0.8194444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.11417156706253688 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.09854997942845027 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.40058504541714984, 'train_accuracy': 0.7916666666666666}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 4] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 50] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.35824023683865863\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.3698030809561412 accuracy: 0.875\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.41061992446581524 accuracy: 0.8194444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.3375285714864731 accuracy: 0.8888888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.1731108066936334 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.20890088627735773 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.35824023683865863, 'train_accuracy': 0.8055555555555556}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 50] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 58] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.5311235884825388\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.39950605233510333 accuracy: 0.7916666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.3030259261528651 accuracy: 0.875\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.19022729496161142 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.1277433161934217 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.1937736657758554 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.5311235884825388, 'train_accuracy': 0.7222222222222222}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 58] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 19] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.38836897412935895\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.40050292015075684 accuracy: 0.8611111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.2840343564748764 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.15778867900371552 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.11018318186203639 accuracy: 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.09276219457387924 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.38836897412935895, 'train_accuracy': 0.8333333333333334}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 19] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 6] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.3062341809272766\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.42366016904513043 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.2603016048669815 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.18698279559612274 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.35436076919237774 accuracy: 0.8888888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.10608687003453572 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.3062341809272766, 'train_accuracy': 0.8333333333333334}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 6] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 65] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.44688504934310913\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.5564715464909872 accuracy: 0.7916666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.3144191304842631 accuracy: 0.8472222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.3176349997520447 accuracy: 0.8333333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.20099756121635437 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.22574985027313232 accuracy: 0.875\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.44688504934310913, 'train_accuracy': 0.7916666666666666}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 65] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 52] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.46085646748542786\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.41445929805437726 accuracy: 0.8055555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.2633548080921173 accuracy: 0.8888888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.1910312275091807 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.19259831806023917 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.16478625933329263 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.46085646748542786, 'train_accuracy': 0.8194444444444444}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 52] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 32] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.317998210589091\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.3083138664563497 accuracy: 0.8611111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.3042645951112111 accuracy: 0.8888888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.21825130780537924 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.10170921683311462 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.125624381005764 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.317998210589091, 'train_accuracy': 0.8333333333333334}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 32] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 93] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.8666887879371643\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 1 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 1]                     loss: 1.3911375999450684 accuracy: 0.3076923076923077\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 1]                     loss: 0.6060500144958496 accuracy: 0.7692307692307693\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 1]                     loss: 0.8177636861801147 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 1]                     loss: 0.9399927854537964 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 1]                     loss: 0.864911675453186 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.8666887879371643, 'train_accuracy': 0.38461538461538464}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 93] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 91] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.9658609628677368\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 1 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 1]                     loss: 1.4725728034973145 accuracy: 0.23076923076923078\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 1]                     loss: 0.4492447078227997 accuracy: 0.8461538461538461\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 1]                     loss: 0.6463965177536011 accuracy: 0.7692307692307693\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 1]                     loss: 0.7880558371543884 accuracy: 0.7692307692307693\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 1]                     loss: 1.0432394742965698 accuracy: 0.7692307692307693\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.9658609628677368, 'train_accuracy': 0.15384615384615385}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 91] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 57] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.3206447859605153\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.2908954272667567 accuracy: 0.8333333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.16592543323834738 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.15259132534265518 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.08039352049430211 accuracy: 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.05517792205015818 accuracy: 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.3206447859605153, 'train_accuracy': 0.8611111111111112}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 57] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 44] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.39512468377749127\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.4238655964533488 accuracy: 0.8055555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.2845921715100606 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.16145471235116324 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.1179577683409055 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.13212128480275473 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.39512468377749127, 'train_accuracy': 0.8055555555555556}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 44] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 71] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.46974819898605347\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.49377941091855365 accuracy: 0.7361111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.30657318731149036 accuracy: 0.8055555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.17420660456021628 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.12130086123943329 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.16812811543544134 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.46974819898605347, 'train_accuracy': 0.7222222222222222}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 71] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 46] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.28752416869004566\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.2874928017457326 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.19116854667663574 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.18899750461181006 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.17417338117957115 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.06659886240959167 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.28752416869004566, 'train_accuracy': 0.875}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 46] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 41] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.46387770275274914\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.3431549270947774 accuracy: 0.8055555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.3833857576052348 accuracy: 0.8194444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.2948523511489232 accuracy: 0.8194444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.13973447183767954 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.23541760196288428 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.46387770275274914, 'train_accuracy': 0.7916666666666666}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 41] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 82] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.8531798720359802\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 1 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 1]                     loss: 1.3946268558502197 accuracy: 0.38461538461538464\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 1]                     loss: 0.6712364554405212 accuracy: 0.5384615384615384\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 1]                     loss: 0.7506250143051147 accuracy: 0.6153846153846154\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 1]                     loss: 0.8039302825927734 accuracy: 0.6153846153846154\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 1]                     loss: 0.7469584345817566 accuracy: 0.6153846153846154\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.8531798720359802, 'train_accuracy': 0.46153846153846156}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 82] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 99] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.783968448638916\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 1 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 1]                     loss: 1.106257438659668 accuracy: 0.47619047619047616\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 1]                     loss: 0.6648917198181152 accuracy: 0.6190476190476191\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 1]                     loss: 0.8112432360649109 accuracy: 0.5238095238095238\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 1]                     loss: 0.7764937281608582 accuracy: 0.5238095238095238\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 1]                     loss: 0.6591883897781372 accuracy: 0.5238095238095238\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.783968448638916, 'train_accuracy': 0.5238095238095238}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 99] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 87] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.9416107535362244\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 1 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 1]                     loss: 1.554942011833191 accuracy: 0.23076923076923078\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 1]                     loss: 0.4731949269771576 accuracy: 0.8461538461538461\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 1]                     loss: 0.6812938451766968 accuracy: 0.7692307692307693\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 1]                     loss: 0.8508897423744202 accuracy: 0.7692307692307693\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 1]                     loss: 0.8631802797317505 accuracy: 0.7692307692307693\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.9416107535362244, 'train_accuracy': 0.23076923076923078}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 87] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 25] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.48984764019648236\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.5015302697817484 accuracy: 0.8333333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.3491398294766744 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.21996129055817923 accuracy: 0.8888888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.24855888883272806 accuracy: 0.8472222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.2162901113430659 accuracy: 0.8888888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.48984764019648236, 'train_accuracy': 0.7777777777777778}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 25] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 33] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.4387343227863312\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.4751170575618744 accuracy: 0.7361111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.2563462257385254 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.16073850790659586 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.16227204849322638 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.10653392225503922 accuracy: 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.4387343227863312, 'train_accuracy': 0.7361111111111112}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 33] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 72] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.43815656503041583\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.5298182169596354 accuracy: 0.8055555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.2951479305823644 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.3492376059293747 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.12602028250694275 accuracy: 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.1538818751772245 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.43815656503041583, 'train_accuracy': 0.7777777777777778}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 72] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 38] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.5183022419611613\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.6258946359157562 accuracy: 0.7083333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.3505158523718516 accuracy: 0.8194444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.250569944580396 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.20206577827533087 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.16886893411477408 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.5183022419611613, 'train_accuracy': 0.7777777777777778}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 38] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 60] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.509838471810023\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.4552096873521805 accuracy: 0.8055555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.3956456383069356 accuracy: 0.875\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.33432518939177197 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.11955264459053676 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.13498186320066452 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.509838471810023, 'train_accuracy': 0.7638888888888888}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 60] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 67] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.5060901045799255\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.40674250324567157 accuracy: 0.8333333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.2631187041600545 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.23620987931887308 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.14756208658218384 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.10142943387230237 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.5060901045799255, 'train_accuracy': 0.7638888888888888}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 67] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 51] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.48212747772534686\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.41485560933748883 accuracy: 0.7777777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.2729145089785258 accuracy: 0.8888888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.27540065348148346 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.12796887258688608 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.14058622469504675 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.48212747772534686, 'train_accuracy': 0.7777777777777778}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 51] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 69] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.48079340656598407\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.5343616604804993 accuracy: 0.7638888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.3973356286684672 accuracy: 0.7638888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.29531510670979816 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.3080267409483592 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.1796247959136963 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.48079340656598407, 'train_accuracy': 0.7222222222222222}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 69] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 42] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.46689023574193317\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.4583672285079956 accuracy: 0.8194444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.3211046059926351 accuracy: 0.8888888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.2063541462024053 accuracy: 0.875\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.1355214317639669 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.16332080960273743 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.46689023574193317, 'train_accuracy': 0.8055555555555556}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 42] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 16] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.3854537258545558\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.4553062717119853 accuracy: 0.8333333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.3821110725402832 accuracy: 0.7777777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.20031403005123138 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.15198969344298044 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.1581170087059339 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.3854537258545558, 'train_accuracy': 0.7638888888888888}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 16] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 17] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.47700836261113483\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.5211726824442545 accuracy: 0.8472222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.4176650643348694 accuracy: 0.7638888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.23236821095148721 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.18935233354568481 accuracy: 0.8888888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.15112480769554773 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.47700836261113483, 'train_accuracy': 0.8472222222222222}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 17] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 9] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.33422862490018207\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.2903672953446706 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.32423896590868634 accuracy: 0.8611111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.25436286131540936 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.13587417701880136 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.10042236000299454 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.33422862490018207, 'train_accuracy': 0.8611111111111112}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 9] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 54] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.4530799488226573\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.37245691816012066 accuracy: 0.875\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.2667747189601262 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.18894181152184805 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.10480364660422008 accuracy: 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.12122890849908192 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.4530799488226573, 'train_accuracy': 0.7916666666666666}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 54] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 2] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.37436090409755707\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.5237709581851959 accuracy: 0.8472222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.41646163662274677 accuracy: 0.7916666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.17319276928901672 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.17195008198420206 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.15280318756898245 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.37436090409755707, 'train_accuracy': 0.7777777777777778}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 2] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 95] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.8027657270431519\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 1 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 1]                     loss: 1.1603267192840576 accuracy: 0.5384615384615384\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 1]                     loss: 0.774132490158081 accuracy: 0.5384615384615384\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 1]                     loss: 0.6405131816864014 accuracy: 0.5384615384615384\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 1]                     loss: 0.7230428457260132 accuracy: 0.6153846153846154\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 1]                     loss: 0.6342515349388123 accuracy: 0.46153846153846156\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.8027657270431519, 'train_accuracy': 0.5384615384615384}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 95] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 15] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.5712083180745443\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.39593496918678284 accuracy: 0.8472222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.31567610303560895 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.2912691831588745 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.17488914728164673 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.15566477676232657 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.5712083180745443, 'train_accuracy': 0.75}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 15] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 31] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.36272109548250836\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.3139980932076772 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.28480570514996845 accuracy: 0.8888888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.2356159637371699 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.09481538583834966 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.10485842575629552 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.36272109548250836, 'train_accuracy': 0.875}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 31] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 78] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.4168379207452138\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.4739098648230235 accuracy: 0.7777777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.510820468266805 accuracy: 0.8611111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.38042476773262024 accuracy: 0.8055555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.2086326703429222 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.13988337417443594 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.4168379207452138, 'train_accuracy': 0.8333333333333334}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 78] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 89] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.7973598837852478\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 1 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 1]                     loss: 1.109392762184143 accuracy: 0.46153846153846156\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 1]                     loss: 0.680637776851654 accuracy: 0.5384615384615384\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 1]                     loss: 0.7295178174972534 accuracy: 0.5384615384615384\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 1]                     loss: 0.7386888265609741 accuracy: 0.5384615384615384\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 1]                     loss: 0.6844533085823059 accuracy: 0.5384615384615384\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.7973598837852478, 'train_accuracy': 0.46153846153846156}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 89] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 48] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.4635358353455861\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.4924943447113037 accuracy: 0.8055555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.43822598457336426 accuracy: 0.8194444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.27618669470151264 accuracy: 0.8194444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.18496058136224747 accuracy: 0.8888888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.13212633629639944 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.4635358353455861, 'train_accuracy': 0.75}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 48] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 63] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.31364164253075916\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.415974756081899 accuracy: 0.875\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.265873447060585 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.19631739457448324 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.11126403013865153 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.1069840391476949 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.31364164253075916, 'train_accuracy': 0.8472222222222222}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 63] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 43] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.5038896103700002\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.4193834165732066 accuracy: 0.8611111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.33605729540189105 accuracy: 0.8472222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.338905726869901 accuracy: 0.8888888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.14346661418676376 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.1627860739827156 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.5038896103700002, 'train_accuracy': 0.7361111111111112}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 43] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 36] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6644425193468729\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.4135014017422994 accuracy: 0.8194444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.31465577085812885 accuracy: 0.8472222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.30689021448294324 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.2345995455980301 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.16978651781876883 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6644425193468729, 'train_accuracy': 0.8055555555555556}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 36] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 97] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.9494498372077942\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 1 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 1]                     loss: 1.3085147142410278 accuracy: 0.3076923076923077\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 1]                     loss: 0.5322108864784241 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 1]                     loss: 0.7093359231948853 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 1]                     loss: 0.7723512053489685 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 1]                     loss: 0.8037497997283936 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.9494498372077942, 'train_accuracy': 0.3076923076923077}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 97] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 70] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.40261654059092206\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.33356855312983197 accuracy: 0.8333333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.27100418508052826 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.2201921045780182 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.09883339703083038 accuracy: 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.13998426124453545 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.40261654059092206, 'train_accuracy': 0.8194444444444444}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 70] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 83] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 1.0305724143981934\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 1 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 1]                     loss: 1.5620520114898682 accuracy: 0.15384615384615385\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 1]                     loss: 0.38189733028411865 accuracy: 0.8461538461538461\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 1]                     loss: 0.6129913926124573 accuracy: 0.8461538461538461\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 1]                     loss: 0.6283597946166992 accuracy: 0.8461538461538461\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 1]                     loss: 0.6586160063743591 accuracy: 0.8461538461538461\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 1.0305724143981934, 'train_accuracy': 0.15384615384615385}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 83] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 30] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.4086488684018453\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.34907453258832294 accuracy: 0.8472222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.27177827060222626 accuracy: 0.875\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.2166158159573873 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.12938263763984045 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.08616974949836731 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.4086488684018453, 'train_accuracy': 0.8333333333333334}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 30] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 53] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.4772961636384328\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.3525504469871521 accuracy: 0.8333333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.3068888783454895 accuracy: 0.8888888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.17117805778980255 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.15406501293182373 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.09905098627010982 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.4772961636384328, 'train_accuracy': 0.8055555555555556}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 53] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 26] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.5403690040111542\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.4644423226515452 accuracy: 0.8333333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.3072088460127513 accuracy: 0.875\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.18793813387552896 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.18964097400506338 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.11282507081826527 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.5403690040111542, 'train_accuracy': 0.8194444444444444}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 26] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.59221883614858\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.3876473506291707 accuracy: 0.8333333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.31396035353342694 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.1787737955649694 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.3400173981984456 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.1177999551097552 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.59221883614858, 'train_accuracy': 0.7777777777777778}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 0] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 12] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.3124109407265981\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.3109527925650279 accuracy: 0.875\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.19960416853427887 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.13261375079552332 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.05145368228356043 accuracy: 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.08024322365721066 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.3124109407265981, 'train_accuracy': 0.8888888888888888}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 12] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 76] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.38133153319358826\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.3314765741427739 accuracy: 0.8194444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.24451657136281332 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.1636821230252584 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.13412082195281982 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.13486123705903688 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.38133153319358826, 'train_accuracy': 0.7777777777777778}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 76] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 80] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6990987062454224\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 1 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 1]                     loss: 0.6953122615814209 accuracy: 0.6153846153846154\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 1]                     loss: 0.5086801052093506 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 1]                     loss: 0.5308706760406494 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 1]                     loss: 0.4571205973625183 accuracy: 0.9230769230769231\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 1]                     loss: 0.5079137086868286 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6990987062454224, 'train_accuracy': 0.6153846153846154}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 80] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 47] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.3846862117449443\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.3062072644631068 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.20860653122266135 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.14237962166468301 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.08926908920208614 accuracy: 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.07365080465873082 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.3846862117449443, 'train_accuracy': 0.8194444444444444}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 47] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 92] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.8528897762298584\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 1 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 1]                     loss: 1.4851430654525757 accuracy: 0.3076923076923077\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 1]                     loss: 0.5111825466156006 accuracy: 0.7692307692307693\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 1]                     loss: 0.6900457143783569 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 1]                     loss: 0.8268893361091614 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 1]                     loss: 0.7554379105567932 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.8528897762298584, 'train_accuracy': 0.3076923076923077}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 92] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 62] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.40452660123507184\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.3945735494295756 accuracy: 0.8472222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.6341881354649862 accuracy: 0.8055555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.5176769644021988 accuracy: 0.8611111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.21271281441052756 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.1823517084121704 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.40452660123507184, 'train_accuracy': 0.7916666666666666}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 62] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6368482311566671\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.44754543900489807 accuracy: 0.7916666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.3237561086813609 accuracy: 0.875\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.22536749889453253 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.12270517895619075 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.17971902589003244 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6368482311566671, 'train_accuracy': 0.7361111111111112}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 1] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 73] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.4575972557067871\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.4585011601448059 accuracy: 0.8611111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.3501501480738322 accuracy: 0.875\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.2656937862435977 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.15087608496348062 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.06288326531648636 accuracy: 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.4575972557067871, 'train_accuracy': 0.7916666666666666}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 73] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 79] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.4093356529871623\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.3963058292865753 accuracy: 0.8297872340425532\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.2623129189014435 accuracy: 0.9042553191489362\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.13534904271364212 accuracy: 0.9680851063829787\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.08224815875291824 accuracy: 0.9787234042553191\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.09586163361867268 accuracy: 0.9787234042553191\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.4093356529871623, 'train_accuracy': 0.8191489361702128}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 79] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 13] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.43390316764513653\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.3268825213114421 accuracy: 0.8472222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.26964905858039856 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.16926718751589456 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.10135850061972936 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.051468184838692345 accuracy: 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.43390316764513653, 'train_accuracy': 0.7361111111111112}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 13] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 10] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.4050145447254181\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.48678627610206604 accuracy: 0.8194444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.296391025185585 accuracy: 0.8611111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.28729310135046643 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.1037197212378184 accuracy: 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.08304222921530406 accuracy: 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.4050145447254181, 'train_accuracy': 0.8194444444444444}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 10] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 59] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6988117694854736\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.5176460345586141 accuracy: 0.7777777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.5811121960481008 accuracy: 0.875\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.24900474150975546 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.32435988386472064 accuracy: 0.8194444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.24238971869150797 accuracy: 0.8888888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6988117694854736, 'train_accuracy': 0.7083333333333334}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 59] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 8] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.35733341177304584\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.3103068321943283 accuracy: 0.8472222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.22676004469394684 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.15076053639252981 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.10771959026654561 accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-08-24 12:36:30,487 | server.py:232 | fit_round 2 received 100 results and 0 failures\n",
            "DEBUG:flwr:fit_round 2 received 100 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.07987492034832637 accuracy: 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.35733341177304584, 'train_accuracy': 0.875}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 8] get_parameters\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-08-24 12:36:40,441 | server.py:168 | evaluate_round 2: strategy sampled 100 clients (out of 100)\n",
            "DEBUG:flwr:evaluate_round 2: strategy sampled 100 clients (out of 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 35] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.2604697644710541\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.2604697644710541, 'test_accuracy': 0.8571428571428571}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 88] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.5871587991714478\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.5871587991714478, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 12] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.5261067748069763\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.5261067748069763, 'test_accuracy': 0.7142857142857143}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 20] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.06147708743810654\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.06147708743810654, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 5] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.8783461451530457\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.8783461451530457, 'test_accuracy': 0.7142857142857143}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 57] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.36216455698013306\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.36216455698013306, 'test_accuracy': 0.8571428571428571}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 76] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.4627683460712433\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.4627683460712433, 'test_accuracy': 0.7142857142857143}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 19] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.7280630469322205\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.7280630469322205, 'test_accuracy': 0.7142857142857143}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 74] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.1787753850221634\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.1787753850221634, 'test_accuracy': 0.8571428571428571}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 9] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.48606523871421814\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.48606523871421814, 'test_accuracy': 0.8571428571428571}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 94] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 1.265376091003418\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 1.265376091003418, 'test_accuracy': 0.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 42] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.28597134351730347\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.28597134351730347, 'test_accuracy': 0.8571428571428571}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 90] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.9256817698478699\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.9256817698478699, 'test_accuracy': 0.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 79] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6389249563217163\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.6389249563217163, 'test_accuracy': 0.6}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 28] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 1.0192071199417114\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 1.0192071199417114, 'test_accuracy': 0.5714285714285714}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 62] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.17519310116767883\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.17519310116767883, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 51] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 1.2635620832443237\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 1.2635620832443237, 'test_accuracy': 0.5714285714285714}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 69] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.345899760723114\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.345899760723114, 'test_accuracy': 0.8571428571428571}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 78] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 1.1167160272598267\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 1.1167160272598267, 'test_accuracy': 0.42857142857142855}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 6] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.41250601410865784\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.41250601410865784, 'test_accuracy': 0.7142857142857143}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 66] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.12589028477668762\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.12589028477668762, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 15] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.13063623011112213\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.13063623011112213, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 87] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.5294579267501831\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.5294579267501831, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 55] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.20447255671024323\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.20447255671024323, 'test_accuracy': 0.8571428571428571}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 65] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6438756585121155\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.6438756585121155, 'test_accuracy': 0.7142857142857143}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 58] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.310791939496994\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.310791939496994, 'test_accuracy': 0.8571428571428571}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 85] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.738457202911377\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.738457202911377, 'test_accuracy': 0.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 2] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6399206519126892\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.6399206519126892, 'test_accuracy': 0.42857142857142855}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 64] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.42628902196884155\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.42628902196884155, 'test_accuracy': 0.7142857142857143}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 17] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.326124370098114\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.326124370098114, 'test_accuracy': 0.8571428571428571}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 93] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6031562685966492\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.6031562685966492, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 59] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.3989768624305725\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.3989768624305725, 'test_accuracy': 0.8571428571428571}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 29] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.698516845703125\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.698516845703125, 'test_accuracy': 0.42857142857142855}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 27] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.08696221560239792\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.08696221560239792, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 44] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.8156552314758301\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.8156552314758301, 'test_accuracy': 0.7142857142857143}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 26] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6408079862594604\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.6408079862594604, 'test_accuracy': 0.7142857142857143}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 18] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.37967658042907715\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.37967658042907715, 'test_accuracy': 0.7142857142857143}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 32] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.27327293157577515\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.27327293157577515, 'test_accuracy': 0.8571428571428571}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 63] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.3148190677165985\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.3148190677165985, 'test_accuracy': 0.8571428571428571}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 77] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.22748194634914398\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.22748194634914398, 'test_accuracy': 0.8571428571428571}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 25] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.7082606554031372\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.7082606554031372, 'test_accuracy': 0.5714285714285714}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 52] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.7091015577316284\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.7091015577316284, 'test_accuracy': 0.5714285714285714}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 4] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.8761458396911621\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.8761458396911621, 'test_accuracy': 0.5714285714285714}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 50] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.1406756043434143\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.1406756043434143, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 97] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.5958378314971924\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.5958378314971924, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 81] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.7833753824234009\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.7833753824234009, 'test_accuracy': 0.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 13] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.4375819265842438\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.4375819265842438, 'test_accuracy': 0.7142857142857143}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 61] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.40291064977645874\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.40291064977645874, 'test_accuracy': 0.7142857142857143}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 46] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6683057546615601\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.6683057546615601, 'test_accuracy': 0.8571428571428571}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 60] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.17135581374168396\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.17135581374168396, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 0] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.14204011857509613\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.14204011857509613, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 8] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.16173017024993896\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.16173017024993896, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 89] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 1.1237155199050903\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 1.1237155199050903, 'test_accuracy': 0.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 92] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.43731385469436646\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.43731385469436646, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 21] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.3491615951061249\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.3491615951061249, 'test_accuracy': 0.7142857142857143}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 75] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.2097998410463333\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.2097998410463333, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 45] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.1654943972826004\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.1654943972826004, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 22] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.16994443535804749\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.16994443535804749, 'test_accuracy': 0.8571428571428571}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 1] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.9565228819847107\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.9565228819847107, 'test_accuracy': 0.5714285714285714}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 99] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.606607973575592\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.606607973575592, 'test_accuracy': 0.5}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 38] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.31948593258857727\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.31948593258857727, 'test_accuracy': 0.8571428571428571}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 83] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.709916353225708\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.709916353225708, 'test_accuracy': 0.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 24] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.20619122684001923\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.20619122684001923, 'test_accuracy': 0.8571428571428571}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 86] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.3522302508354187\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.3522302508354187, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 34] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.029744284227490425\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.029744284227490425, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 7] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.19182656705379486\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.19182656705379486, 'test_accuracy': 0.8571428571428571}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 31] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.23401550948619843\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.23401550948619843, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 53] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.19820712506771088\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.19820712506771088, 'test_accuracy': 0.8571428571428571}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 3] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6936648488044739\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.6936648488044739, 'test_accuracy': 0.5714285714285714}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 95] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.695268452167511\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.695268452167511, 'test_accuracy': 0.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 37] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.8816292881965637\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.8816292881965637, 'test_accuracy': 0.42857142857142855}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 82] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.9683694839477539\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.9683694839477539, 'test_accuracy': 0.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 14] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.39741596579551697\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.39741596579551697, 'test_accuracy': 0.7142857142857143}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 48] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.13090580701828003\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.13090580701828003, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 98] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6573467254638672\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.6573467254638672, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 11] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.2191227823495865\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.2191227823495865, 'test_accuracy': 0.8571428571428571}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 68] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.2737669348716736\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.2737669348716736, 'test_accuracy': 0.8571428571428571}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 56] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.09185413271188736\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.09185413271188736, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 23] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.21766960620880127\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.21766960620880127, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 80] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 1.1053557395935059\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 1.1053557395935059, 'test_accuracy': 0.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 49] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.3849700093269348\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.3849700093269348, 'test_accuracy': 0.7142857142857143}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 36] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.23721902072429657\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.23721902072429657, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 91] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6017373204231262\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.6017373204231262, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 33] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.18809998035430908\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.18809998035430908, 'test_accuracy': 0.8571428571428571}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 41] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.05485881119966507\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.05485881119966507, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 30] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.0857052281498909\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.0857052281498909, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 67] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.20209655165672302\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.20209655165672302, 'test_accuracy': 0.8571428571428571}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 47] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.131860613822937\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.131860613822937, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 71] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.11750377714633942\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.11750377714633942, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 54] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.32325008511543274\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.32325008511543274, 'test_accuracy': 0.8571428571428571}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 72] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.40892502665519714\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.40892502665519714, 'test_accuracy': 0.8571428571428571}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 96] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.426868736743927\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.426868736743927, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 39] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.27344873547554016\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.27344873547554016, 'test_accuracy': 0.8571428571428571}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 70] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.13576845824718475\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.13576845824718475, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 84] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.9508935213088989\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.9508935213088989, 'test_accuracy': 0.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 10] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.2175181806087494\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.2175181806087494, 'test_accuracy': 0.8571428571428571}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 16] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.13153553009033203\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.13153553009033203, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 43] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.2862108647823334\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.2862108647823334, 'test_accuracy': 0.8571428571428571}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 40] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.1834128051996231\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.1834128051996231, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 73] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-08-24 12:37:41,337 | server.py:182 | evaluate_round 2 received 100 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 2 received 100 results and 0 failures\n",
            "DEBUG flwr 2023-08-24 12:37:41,342 | server.py:218 | fit_round 3: strategy sampled 100 clients (out of 100)\n",
            "DEBUG:flwr:fit_round 3: strategy sampled 100 clients (out of 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.4229704439640045\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.4229704439640045, 'test_accuracy': 0.8571428571428571}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 87] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6769170165061951\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 1 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 1]                     loss: 1.5925419330596924 accuracy: 0.23076923076923078\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 1]                     loss: 0.5290429592132568 accuracy: 0.8461538461538461\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 1]                     loss: 0.4509533643722534 accuracy: 0.7692307692307693\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 1]                     loss: 0.7303259968757629 accuracy: 0.7692307692307693\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 1]                     loss: 0.5652523040771484 accuracy: 0.7692307692307693\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6769170165061951, 'train_accuracy': 0.46153846153846156}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 87] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 53] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.3837309579054515\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.37053240338961285 accuracy: 0.8194444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.23495796819527945 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.1830251763264338 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.10914229353268941 accuracy: 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.06744235505660374 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.3837309579054515, 'train_accuracy': 0.875}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 53] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 10] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.21948143343130747\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.21016119420528412 accuracy: 0.8888888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.16480515400568643 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.09367363154888153 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.03471738534669081 accuracy: 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.06803352696200211 accuracy: 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.21948143343130747, 'train_accuracy': 0.875}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 10] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 76] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.32763869563738507\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.23484920461972555 accuracy: 0.8888888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.19320194919904074 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.13557256758213043 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.06878384078542392 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.09967248017589252 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.32763869563738507, 'train_accuracy': 0.875}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 76] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 34] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.30457064012686413\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.20151575903097788 accuracy: 0.8888888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.2555762529373169 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.1208658516407013 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.27681025117635727 accuracy: 0.8888888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.20549272000789642 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.30457064012686413, 'train_accuracy': 0.875}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 34] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 37] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.39235780636469525\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.39273879925409955 accuracy: 0.8333333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.46964994072914124 accuracy: 0.75\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.3058324654897054 accuracy: 0.8611111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.16814243296782175 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.09760766476392746 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.39235780636469525, 'train_accuracy': 0.8333333333333334}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 37] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 56] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.19001465539137521\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.22932478288809457 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.20870413382848105 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.11814343432585399 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.1481706996758779 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.07971648251016934 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.19001465539137521, 'train_accuracy': 0.9027777777777778}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 56] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 12] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.26863565544287366\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.2192531277736028 accuracy: 0.8611111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.12835895518461862 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.08745408058166504 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.05014212429523468 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.026401758193969727 accuracy: 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.26863565544287366, 'train_accuracy': 0.8888888888888888}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 12] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 5] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.48252445956071216\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.23507360617319742 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.20937801400820413 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.47199955955147743 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.08320464566349983 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.07889971882104874 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.48252445956071216, 'train_accuracy': 0.8611111111111112}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 5] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 70] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.29000989099343616\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.24953341980775198 accuracy: 0.8472222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.1581875408689181 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.09861698746681213 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.166659959902366 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.07105530674258868 accuracy: 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.29000989099343616, 'train_accuracy': 0.8611111111111112}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 70] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 74] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.3685598125060399\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.48122401038805646 accuracy: 0.8194444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.43140606085459393 accuracy: 0.8888888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.14914070069789886 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.3646326810121536 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.1785132015744845 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.3685598125060399, 'train_accuracy': 0.8888888888888888}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 74] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 28] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.42696109414100647\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.28551827867825824 accuracy: 0.8611111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.22982188562552133 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.14228038241465887 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.10356492052475612 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.08352017278472583 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.42696109414100647, 'train_accuracy': 0.8194444444444444}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 28] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 67] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.45981619755427044\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.40308450162410736 accuracy: 0.8888888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.3026857078075409 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.45849235107501346 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.1259243587652842 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.1381689508756002 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.45981619755427044, 'train_accuracy': 0.8472222222222222}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 67] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 41] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.26517629126707715\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.3094478001197179 accuracy: 0.8472222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.26006149252255756 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.12114585191011429 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.2082437127828598 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.1050463393330574 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.26517629126707715, 'train_accuracy': 0.875}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 41] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 35] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.27334308127562207\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.25597064197063446 accuracy: 0.8888888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.17683124293883642 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.30879271278778714 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.2281124989191691 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.11053106933832169 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.27334308127562207, 'train_accuracy': 0.8333333333333334}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 35] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 6] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.18294348816076914\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.2136101375023524 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.15058485170205435 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.10563202450672786 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.08932338034113248 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.04901644587516785 accuracy: 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.18294348816076914, 'train_accuracy': 0.9305555555555556}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 6] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 40] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.33958527942498523\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.3894401689370473 accuracy: 0.8194444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.23541011412938437 accuracy: 0.875\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.2144464130202929 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.15490272517005602 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.07918252299229304 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.33958527942498523, 'train_accuracy': 0.8333333333333334}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 40] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 32] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.2534041752417882\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.23113186657428741 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.16284558673699698 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.10468543569246928 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.0785566084086895 accuracy: 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.11967042461037636 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.2534041752417882, 'train_accuracy': 0.8888888888888888}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 32] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 26] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.29758096237977344\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.267979234457016 accuracy: 0.875\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.25705715517203015 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.09314703320463498 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.09584865594903628 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.19411442801356316 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.29758096237977344, 'train_accuracy': 0.8333333333333334}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 26] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 58] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.508731464544932\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.47108906010786694 accuracy: 0.8611111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.2978757321834564 accuracy: 0.8333333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.23426220814387003 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.23534902930259705 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.036584699526429176 accuracy: 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.508731464544932, 'train_accuracy': 0.8611111111111112}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 58] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 79] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.2628779262304306\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.3619181265433629 accuracy: 0.8297872340425532\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.16919292757908502 accuracy: 0.9148936170212766\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.1848276431361834 accuracy: 0.9361702127659575\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.057612391809622444 accuracy: 0.9893617021276596\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.05604789902766546 accuracy: 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.2628779262304306, 'train_accuracy': 0.8723404255319149}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 79] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 94] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.7756468057632446\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 1 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 1]                     loss: 1.6225528717041016 accuracy: 0.23076923076923078\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 1]                     loss: 0.5637959241867065 accuracy: 0.7692307692307693\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 1]                     loss: 0.6661742329597473 accuracy: 0.7692307692307693\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 1]                     loss: 0.8395435810089111 accuracy: 0.7692307692307693\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 1]                     loss: 0.9760398864746094 accuracy: 0.7692307692307693\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.7756468057632446, 'train_accuracy': 0.46153846153846156}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 94] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 43] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.3867793182531993\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.3135847548643748 accuracy: 0.8888888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.38225112358729046 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.18879473954439163 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.20200422406196594 accuracy: 0.8888888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.25815469523270923 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.3867793182531993, 'train_accuracy': 0.875}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 43] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 83] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6935752034187317\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 1 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 1]                     loss: 1.6042993068695068 accuracy: 0.15384615384615385\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 1]                     loss: 0.31114354729652405 accuracy: 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 1]                     loss: 0.4038989245891571 accuracy: 0.8461538461538461\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 1]                     loss: 0.8208698034286499 accuracy: 0.8461538461538461\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 1]                     loss: 0.6383016109466553 accuracy: 0.8461538461538461\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6935752034187317, 'train_accuracy': 0.5384615384615384}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 83] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 23] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.2830600142478943\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.19026639064153036 accuracy: 0.8888888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.21671059727668762 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.07063257570068042 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.2341198374827703 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.10725208620230357 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.2830600142478943, 'train_accuracy': 0.875}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 23] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 51] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.25770869354406994\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.2707817455132802 accuracy: 0.8611111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.12920043617486954 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.09212205310662587 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.10342544068892796 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.10479614014426868 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.25770869354406994, 'train_accuracy': 0.8611111111111112}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 51] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 20] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.450446218252182\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.38147303462028503 accuracy: 0.8333333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.40511006613572437 accuracy: 0.8472222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.3800664196411769 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.16291056076685587 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.11334660897652309 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.450446218252182, 'train_accuracy': 0.8055555555555556}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 20] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 81] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.77685546875\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 1 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 1]                     loss: 1.6603527069091797 accuracy: 0.23076923076923078\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 1]                     loss: 0.5899316072463989 accuracy: 0.6153846153846154\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 1]                     loss: 0.6341986060142517 accuracy: 0.7692307692307693\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 1]                     loss: 0.8957156538963318 accuracy: 0.7692307692307693\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 1]                     loss: 0.8157088160514832 accuracy: 0.7692307692307693\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.77685546875, 'train_accuracy': 0.38461538461538464}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 81] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 29] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.25310592850049335\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.2323789248863856 accuracy: 0.875\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.1536805381377538 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.06258905244370301 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.08359509085615476 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.10150384157896042 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.25310592850049335, 'train_accuracy': 0.9305555555555556}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 29] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 24] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.382467324535052\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.29608087738355 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.3410482456286748 accuracy: 0.8888888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.15702646225690842 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.12458632389704387 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.0937779148419698 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.382467324535052, 'train_accuracy': 0.875}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 24] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 48] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.29949550330638885\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.467842439810435 accuracy: 0.8472222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.29375145335992175 accuracy: 0.8472222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.19709527492523193 accuracy: 0.8888888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.13835802674293518 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.15171276777982712 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.29949550330638885, 'train_accuracy': 0.8888888888888888}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 48] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 90] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.7099370360374451\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 1 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 1]                     loss: 1.5100154876708984 accuracy: 0.23076923076923078\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 1]                     loss: 0.2725796401500702 accuracy: 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 1]                     loss: 0.46390044689178467 accuracy: 0.8461538461538461\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 1]                     loss: 0.5723004937171936 accuracy: 0.7692307692307693\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 1]                     loss: 0.5666900873184204 accuracy: 0.7692307692307693\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.7099370360374451, 'train_accuracy': 0.5384615384615384}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 90] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 14] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.4448538025220235\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.4082037905852 accuracy: 0.7777777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.21889346837997437 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.18191401908795038 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.13353637605905533 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.14203724016745886 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.4448538025220235, 'train_accuracy': 0.8055555555555556}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 14] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 18] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.3605162401994069\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.43252746264139813 accuracy: 0.8611111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.277500460545222 accuracy: 0.875\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.1622980758547783 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.21316363910833994 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.13520238548517227 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.3605162401994069, 'train_accuracy': 0.8611111111111112}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 18] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 39] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.4421865890423457\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.2944949269294739 accuracy: 0.875\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.22062761584917703 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.18954633176326752 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.14292273670434952 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.11111263185739517 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.4421865890423457, 'train_accuracy': 0.8333333333333334}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 39] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 52] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.29251978794733685\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.22843076785405478 accuracy: 0.8888888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.2123880386352539 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.11774961402018864 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.18151762088139853 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.06591977303226788 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.29251978794733685, 'train_accuracy': 0.8472222222222222}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 52] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 50] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.19776555399099985\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.1887641946474711 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.28556406994660694 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.19625316808621088 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.09826242551207542 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.05062208759287993 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.19776555399099985, 'train_accuracy': 0.8888888888888888}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 50] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 7] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.24701024840275446\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.3446728189786275 accuracy: 0.875\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.19900350272655487 accuracy: 0.8888888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.12775730093320212 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.13975075632333755 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.07924156077206135 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.24701024840275446, 'train_accuracy': 0.8611111111111112}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 7] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 93] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6540701985359192\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 1 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 1]                     loss: 1.5346713066101074 accuracy: 0.3076923076923077\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 1]                     loss: 0.4780840575695038 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 1]                     loss: 0.619314432144165 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 1]                     loss: 0.7280825972557068 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 1]                     loss: 0.757731020450592 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6540701985359192, 'train_accuracy': 0.5384615384615384}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 93] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 60] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.34614574909210205\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.4119083782037099 accuracy: 0.8888888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.25179608166217804 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.2964852799971898 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.1894012987613678 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.0880924512942632 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.34614574909210205, 'train_accuracy': 0.8888888888888888}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 60] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 84] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6616808772087097\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 1 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 1]                     loss: 1.3794034719467163 accuracy: 0.3076923076923077\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 1]                     loss: 0.8326541185379028 accuracy: 0.38461538461538464\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 1]                     loss: 0.8296912908554077 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 1]                     loss: 0.9088431596755981 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 1]                     loss: 0.9565809965133667 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6616808772087097, 'train_accuracy': 0.6153846153846154}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 84] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 31] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.18202486137549082\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.2192338158686956 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.18345890690883002 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.09958132108052571 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.12486562877893448 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.08504641304413478 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.18202486137549082, 'train_accuracy': 0.9166666666666666}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 31] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 73] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.21080681184927622\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.21568067371845245 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.29330795009930927 accuracy: 0.875\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.312079315384229 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.04968022803465525 accuracy: 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.04124243184924126 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.21080681184927622, 'train_accuracy': 0.8611111111111112}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 73] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 80] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.7560977935791016\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 1 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 1]                     loss: 0.5915133953094482 accuracy: 0.6153846153846154\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 1]                     loss: 0.4075416028499603 accuracy: 0.7692307692307693\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 1]                     loss: 0.3090966045856476 accuracy: 0.9230769230769231\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 1]                     loss: 0.2971765398979187 accuracy: 0.9230769230769231\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 1]                     loss: 0.28527262806892395 accuracy: 0.9230769230769231\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.7560977935791016, 'train_accuracy': 0.6153846153846154}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 80] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 88] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6762336492538452\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 1 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 1]                     loss: 1.0609670877456665 accuracy: 0.5384615384615384\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 1]                     loss: 0.5907870531082153 accuracy: 0.7692307692307693\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 1]                     loss: 0.6427426934242249 accuracy: 0.5384615384615384\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 1]                     loss: 0.6003097295761108 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 1]                     loss: 0.5433127284049988 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6762336492538452, 'train_accuracy': 0.5384615384615384}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 88] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 16] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.36181805034478504\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.39146921535332996 accuracy: 0.875\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.2535749673843384 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.32354668776194256 accuracy: 0.8472222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.18383226046959558 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.222260482609272 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.36181805034478504, 'train_accuracy': 0.875}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 16] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 47] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.22800555328528085\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.18474979201952615 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.18604822953542074 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.35013472661376 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.13709291070699692 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.06183247019847234 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.22800555328528085, 'train_accuracy': 0.9305555555555556}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 47] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 92] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6983422636985779\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 1 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 1]                     loss: 1.3166446685791016 accuracy: 0.3076923076923077\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 1]                     loss: 0.6545171737670898 accuracy: 0.6153846153846154\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 1]                     loss: 0.6272586584091187 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 1]                     loss: 0.7807406187057495 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 1]                     loss: 0.6960605978965759 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6983422636985779, 'train_accuracy': 0.38461538461538464}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 92] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 38] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.4167025585969289\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.43629390001296997 accuracy: 0.8611111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.26521192987759906 accuracy: 0.8472222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.16853074729442596 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.15413889040549597 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.09003324930866559 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.4167025585969289, 'train_accuracy': 0.7916666666666666}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 38] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 86] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.7608852982521057\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 1 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 1]                     loss: 1.0910205841064453 accuracy: 0.6153846153846154\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 1]                     loss: 0.8886096477508545 accuracy: 0.5384615384615384\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 1]                     loss: 0.47524893283843994 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 1]                     loss: 0.48224937915802 accuracy: 0.6153846153846154\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 1]                     loss: 0.5281655788421631 accuracy: 0.6153846153846154\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.7608852982521057, 'train_accuracy': 0.5384615384615384}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 86] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 49] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.3007533699274063\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.43491773804028827 accuracy: 0.8333333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.2514406045277913 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.2915821596980095 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.09402597198883693 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.11737211793661118 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.3007533699274063, 'train_accuracy': 0.8333333333333334}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 49] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 45] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.17521252110600471\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.23710746069749197 accuracy: 0.8611111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.18684563040733337 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.15339391926924387 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.043373349433143936 accuracy: 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.1917053461074829 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.17521252110600471, 'train_accuracy': 0.9027777777777778}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 45] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 63] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.2710913419723511\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.2078046997388204 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.24372510115305582 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.13700669755538306 accuracy: 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.1586750919620196 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.06297050292293231 accuracy: 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.2710913419723511, 'train_accuracy': 0.875}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 63] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 91] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.7741721272468567\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 1 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 1]                     loss: 1.6214630603790283 accuracy: 0.3076923076923077\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 1]                     loss: 0.5031007528305054 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 1]                     loss: 0.5876333713531494 accuracy: 0.7692307692307693\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 1]                     loss: 0.7100419402122498 accuracy: 0.7692307692307693\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 1]                     loss: 0.7454174757003784 accuracy: 0.7692307692307693\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.7741721272468567, 'train_accuracy': 0.46153846153846156}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 91] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.33396270871162415\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.34919416904449463 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.21189830203851065 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.2756575345993042 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.10817056645949681 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.07432039082050323 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.33396270871162415, 'train_accuracy': 0.875}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 0] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 59] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.3420730431874593\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.3214608281850815 accuracy: 0.8611111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.34089769423007965 accuracy: 0.8888888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.4318000028530757 accuracy: 0.8472222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.1523820956548055 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.1692875772714615 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.3420730431874593, 'train_accuracy': 0.8055555555555556}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 59] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 4] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.23386934647957483\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.3131129542986552 accuracy: 0.8333333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.2350715845823288 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.09937808165947597 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.10239047557115555 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.10352321714162827 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.23386934647957483, 'train_accuracy': 0.8611111111111112}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 4] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 33] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.4358120858669281\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.4004145512978236 accuracy: 0.8611111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.25239203373591107 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.3230196535587311 accuracy: 0.8888888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.16956807672977448 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.1914470543464025 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.4358120858669281, 'train_accuracy': 0.8333333333333334}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 33] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 21] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.2674146940310796\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.2636900196472804 accuracy: 0.8611111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.16741974403460821 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.09723109006881714 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.07053069894512494 accuracy: 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.08436670651038487 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.2674146940310796, 'train_accuracy': 0.875}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 21] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 15] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.39462771515051526\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.27918019394079846 accuracy: 0.875\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.14475431789954504 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.12051859001318614 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.052273971339066826 accuracy: 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.07443038374185562 accuracy: 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.39462771515051526, 'train_accuracy': 0.8472222222222222}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 15] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 9] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.2183105250199636\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.26257535566886264 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.15204489727814993 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.17381175607442856 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.07635583480199178 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.10892447332541148 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.2183105250199636, 'train_accuracy': 0.9444444444444444}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 9] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 46] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.20244269569714865\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.21187036236127219 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.117542731265227 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.09655789285898209 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.11042822152376175 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.07755610098441441 accuracy: 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.20244269569714865, 'train_accuracy': 0.9305555555555556}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 46] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 2] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.24702797333399454\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.22893263399600983 accuracy: 0.8888888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.2994935214519501 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.1851957912246386 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.10182403897245725 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.13850727304816246 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.24702797333399454, 'train_accuracy': 0.9027777777777778}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 2] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.36230461796124774\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.33419567346572876 accuracy: 0.8194444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.3174917052189509 accuracy: 0.8472222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.4270908683538437 accuracy: 0.875\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.08123472705483437 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.17497011522452036 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.36230461796124774, 'train_accuracy': 0.8333333333333334}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 1] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 19] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.38563495377699536\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.2679697225491206 accuracy: 0.875\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.13083583116531372 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.1667564238111178 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.05752855911850929 accuracy: 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.04876721277832985 accuracy: 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.38563495377699536, 'train_accuracy': 0.9027777777777778}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 19] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 77] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.27801985045274097\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.27041417360305786 accuracy: 0.8611111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.7505321055650711 accuracy: 0.8333333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 1.0403603290518124 accuracy: 0.7361111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.21108786016702652 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.14367460956176123 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.27801985045274097, 'train_accuracy': 0.8611111111111112}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 77] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 13] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.25370123485724133\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.3030361533164978 accuracy: 0.8888888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.3055794984102249 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.2706096023321152 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.1183058147629102 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.1646145631869634 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.25370123485724133, 'train_accuracy': 0.8611111111111112}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 13] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 69] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.3214167207479477\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.3898829569419225 accuracy: 0.8611111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.3085654377937317 accuracy: 0.875\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.28262994190057117 accuracy: 0.8611111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.3053444375594457 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.11185302337010701 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.3214167207479477, 'train_accuracy': 0.8194444444444444}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 69] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 99] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.7809481620788574\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 1 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 1]                     loss: 1.126618504524231 accuracy: 0.47619047619047616\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 1]                     loss: 0.7242938280105591 accuracy: 0.6190476190476191\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 1]                     loss: 0.8344502449035645 accuracy: 0.5238095238095238\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 1]                     loss: 0.9190880656242371 accuracy: 0.5238095238095238\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 1]                     loss: 0.6970393657684326 accuracy: 0.5714285714285714\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.7809481620788574, 'train_accuracy': 0.2857142857142857}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 99] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 36] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.4619434078534444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.33571423093477887 accuracy: 0.8333333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.2972886711359024 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.1324955771366755 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.24421570698420206 accuracy: 0.8472222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.15283960103988647 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.4619434078534444, 'train_accuracy': 0.8472222222222222}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 36] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 11] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.15255090842644373\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.19529643654823303 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.10259647915760677 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.09496231873830159 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.057499429831902184 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.046814870089292526 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.15255090842644373, 'train_accuracy': 0.9583333333333334}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 11] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 98] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.7826897501945496\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 1 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 1]                     loss: 1.4443423748016357 accuracy: 0.38461538461538464\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 1]                     loss: 0.6822907328605652 accuracy: 0.5384615384615384\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 1]                     loss: 0.783724844455719 accuracy: 0.6153846153846154\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 1]                     loss: 0.7289063930511475 accuracy: 0.6153846153846154\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 1]                     loss: 0.6445636749267578 accuracy: 0.6153846153846154\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.7826897501945496, 'train_accuracy': 0.3076923076923077}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 98] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 71] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.37960482637087506\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.3342719574769338 accuracy: 0.8472222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.5799636741479238 accuracy: 0.875\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.2227580522497495 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.5448312262694041 accuracy: 0.8194444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.17433119316895804 accuracy: 0.8888888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.37960482637087506, 'train_accuracy': 0.8333333333333334}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 71] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 22] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.4340868691603343\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.5119264324506124 accuracy: 0.8055555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.28799662987391156 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.16337389995654425 accuracy: 0.8888888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.1490227406223615 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.1208353266119957 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.4340868691603343, 'train_accuracy': 0.8333333333333334}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 22] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 68] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.22755691905816397\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.2860112686951955 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.5424321442842484 accuracy: 0.8888888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.28060423334439594 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.21405980487664542 accuracy: 0.8888888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.14990964035193124 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.22755691905816397, 'train_accuracy': 0.875}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 68] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 57] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.17567994197209677\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.2481591502825419 accuracy: 0.8888888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.13078205287456512 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.25262712438901264 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.183811624844869 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.19871676713228226 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.17567994197209677, 'train_accuracy': 0.9166666666666666}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 57] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 97] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.7282677292823792\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 1 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 1]                     loss: 1.3222960233688354 accuracy: 0.3076923076923077\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 1]                     loss: 0.47906309366226196 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 1]                     loss: 0.7035318613052368 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 1]                     loss: 0.653838574886322 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 1]                     loss: 0.685932457447052 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.7282677292823792, 'train_accuracy': 0.46153846153846156}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 97] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 72] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.2808896650870641\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.2850419630606969 accuracy: 0.875\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.15596033384402594 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.10447794447342555 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.13856874406337738 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.054611217230558395 accuracy: 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.2808896650870641, 'train_accuracy': 0.8611111111111112}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 72] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 44] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.3348342478275299\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.3333394179741542 accuracy: 0.875\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.16050921380519867 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.12183753152688344 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.08072418222824733 accuracy: 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.07319588835040729 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.3348342478275299, 'train_accuracy': 0.8611111111111112}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 44] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 95] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.650666356086731\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 1 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 1]                     loss: 1.3895601034164429 accuracy: 0.46153846153846156\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 1]                     loss: 1.0411427021026611 accuracy: 0.15384615384615385\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 1]                     loss: 0.6933733224868774 accuracy: 0.5384615384615384\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 1]                     loss: 0.6219087243080139 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 1]                     loss: 0.49145010113716125 accuracy: 0.6153846153846154\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.650666356086731, 'train_accuracy': 0.6153846153846154}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 95] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 25] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.3491522967815399\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.25868793825308484 accuracy: 0.875\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.1614438792069753 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.09184737627704938 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.0807662649701039 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.15657886117696762 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.3491522967815399, 'train_accuracy': 0.8611111111111112}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 25] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 85] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6688244342803955\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 1 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 1]                     loss: 1.2070964574813843 accuracy: 0.46153846153846156\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 1]                     loss: 0.6509252190589905 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 1]                     loss: 0.6051285266876221 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 1]                     loss: 0.7393820881843567 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 1]                     loss: 0.5765427350997925 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6688244342803955, 'train_accuracy': 0.5384615384615384}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 85] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 82] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.7909015417098999\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 1 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 1]                     loss: 1.3570091724395752 accuracy: 0.38461538461538464\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 1]                     loss: 0.7736443281173706 accuracy: 0.5384615384615384\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 1]                     loss: 0.7940199971199036 accuracy: 0.6153846153846154\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 1]                     loss: 0.7115115523338318 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 1]                     loss: 0.6434074640274048 accuracy: 0.6153846153846154\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.7909015417098999, 'train_accuracy': 0.46153846153846156}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 82] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 54] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.2867579360802968\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.40456337730089825 accuracy: 0.875\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.2895566125710805 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.12447523077329 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.2699373587965965 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.20812709629535675 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.2867579360802968, 'train_accuracy': 0.9027777777777778}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 54] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 30] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.31296610832214355\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.2645764996608098 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.21028538544972739 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.13827936351299286 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.10437046984831493 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.29640354961156845 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.31296610832214355, 'train_accuracy': 0.9027777777777778}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 30] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 27] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.2797546188036601\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.26958558956782025 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.14455835024515787 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.0987412507335345 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.10974908868471782 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.11872366319100063 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.2797546188036601, 'train_accuracy': 0.9027777777777778}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 27] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 65] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.4223983387152354\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.36470990379651386 accuracy: 0.8333333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.33962715168793994 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.23762359221776327 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.1802544742822647 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.14553606510162354 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.4223983387152354, 'train_accuracy': 0.8333333333333334}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 65] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 96] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.72186279296875\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 1 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 1]                     loss: 1.3131879568099976 accuracy: 0.38461538461538464\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 1]                     loss: 0.6144434213638306 accuracy: 0.6153846153846154\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 1]                     loss: 0.6670151948928833 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 1]                     loss: 0.6532639265060425 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 1]                     loss: 0.7432690858840942 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.72186279296875, 'train_accuracy': 0.38461538461538464}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 96] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 42] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.4290987352530162\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.4532374292612076 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.36755236983299255 accuracy: 0.8888888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.22447888056437174 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.12762199093898138 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.18816469858090082 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.4290987352530162, 'train_accuracy': 0.9027777777777778}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 42] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 3] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.2612243841091792\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.22938352326552072 accuracy: 0.875\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.1551411027709643 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.07450043906768163 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.0511384146908919 accuracy: 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.04576802377899488 accuracy: 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.2612243841091792, 'train_accuracy': 0.8333333333333334}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 3] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 75] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.38597246011098224\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.32976897060871124 accuracy: 0.8472222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.16197139273087183 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.11438910663127899 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.20903560519218445 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.06993435695767403 accuracy: 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.38597246011098224, 'train_accuracy': 0.8194444444444444}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 75] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 78] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.2829204648733139\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.28361297647158307 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.21158970395723978 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.1787488410870234 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.12753698229789734 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.0805771177013715 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.2829204648733139, 'train_accuracy': 0.8611111111111112}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 78] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 8] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.1941670427719752\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.26359830300013226 accuracy: 0.8888888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.13067111869653067 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.07534500459829967 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.07005174333850543 accuracy: 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.059073831886053085 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.1941670427719752, 'train_accuracy': 0.9305555555555556}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 8] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 62] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.32329537471135456\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.36021459599335987 accuracy: 0.8611111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.24484572311242422 accuracy: 0.875\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.19565975666046143 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.0681624561548233 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.09312012543280919 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.32329537471135456, 'train_accuracy': 0.8194444444444444}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 62] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 64] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.2638628880182902\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.21668681999047598 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.13358631109197935 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.09199364110827446 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.2047171083589395 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.04819934939344724 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.2638628880182902, 'train_accuracy': 0.9166666666666666}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 64] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 66] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.23472649852434793\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.27392009894053143 accuracy: 0.8888888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.5152140210072199 accuracy: 0.8333333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.11898019164800644 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.26965180536111194 accuracy: 0.8611111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.14357426762580872 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.23472649852434793, 'train_accuracy': 0.9166666666666666}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 66] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 17] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.2728412946065267\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.5245965868234634 accuracy: 0.875\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.22568093240261078 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.13021604468425116 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.1939620537062486 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.07323957172532876 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.2728412946065267, 'train_accuracy': 0.875}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 17] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 61] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.3077458788951238\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.3715936640898387 accuracy: 0.8194444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.2024014194806417 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.16623781869808832 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.16740608339508375 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.06777265295386314 accuracy: 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.3077458788951238, 'train_accuracy': 0.8472222222222222}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 61] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 55] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.3460935850938161\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.3050587475299835 accuracy: 0.8472222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.294404998421669 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.40520984927813214 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.11405746390422185 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.2059209644794464 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.3460935850938161, 'train_accuracy': 0.8333333333333334}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 55] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 89] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6412168741226196\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 1 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 1]                     loss: 0.9178013205528259 accuracy: 0.46153846153846156\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 1]                     loss: 0.5753225088119507 accuracy: 0.6153846153846154\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 1]                     loss: 0.6277469396591187 accuracy: 0.7692307692307693\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 1]                     loss: 0.644932210445404 accuracy: 0.5384615384615384\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-08-24 14:23:27,329 | server.py:232 | fit_round 3 received 100 results and 0 failures\n",
            "DEBUG:flwr:fit_round 3 received 100 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 1]                     loss: 0.5819547176361084 accuracy: 0.5384615384615384\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6412168741226196, 'train_accuracy': 0.5384615384615384}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 89] get_parameters\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-08-24 14:23:37,693 | server.py:168 | evaluate_round 3: strategy sampled 100 clients (out of 100)\n",
            "DEBUG:flwr:evaluate_round 3: strategy sampled 100 clients (out of 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 12] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.5416182279586792\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.5416182279586792, 'test_accuracy': 0.7142857142857143}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 21] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.2261204719543457\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.2261204719543457, 'test_accuracy': 0.8571428571428571}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 83] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.5177348852157593\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.5177348852157593, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 40] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.11124897748231888\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.11124897748231888, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 57] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.28812578320503235\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.28812578320503235, 'test_accuracy': 0.8571428571428571}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 64] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.35828113555908203\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.35828113555908203, 'test_accuracy': 0.8571428571428571}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 10] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.2941182255744934\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.2941182255744934, 'test_accuracy': 0.8571428571428571}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 5] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6479377746582031\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.6479377746582031, 'test_accuracy': 0.7142857142857143}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 24] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.1501702070236206\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.1501702070236206, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 48] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.05343199521303177\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.05343199521303177, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 23] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.08644972741603851\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.08644972741603851, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 45] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.07426948845386505\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.07426948845386505, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 84] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6107741594314575\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.6107741594314575, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 30] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.053610336035490036\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.053610336035490036, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 85] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.43745580315589905\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.43745580315589905, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 41] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.02429554983973503\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.02429554983973503, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 94] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 1.6899311542510986\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 1.6899311542510986, 'test_accuracy': 0.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 20] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.040213342756032944\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.040213342756032944, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 56] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.04129800200462341\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.04129800200462341, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 42] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.19074784219264984\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.19074784219264984, 'test_accuracy': 0.8571428571428571}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 97] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.4526531994342804\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.4526531994342804, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 4] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.7592535018920898\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.7592535018920898, 'test_accuracy': 0.7142857142857143}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 61] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.4310908317565918\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.4310908317565918, 'test_accuracy': 0.7142857142857143}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 82] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.7466546297073364\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.7466546297073364, 'test_accuracy': 0.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 62] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.12497802078723907\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.12497802078723907, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 70] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.0794481635093689\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.0794481635093689, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 6] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.27885714173316956\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.27885714173316956, 'test_accuracy': 0.8571428571428571}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 52] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.7531319260597229\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.7531319260597229, 'test_accuracy': 0.5714285714285714}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 29] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.4466986060142517\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.4466986060142517, 'test_accuracy': 0.7142857142857143}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 18] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.26651445031166077\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.26651445031166077, 'test_accuracy': 0.8571428571428571}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 9] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.3477390706539154\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.3477390706539154, 'test_accuracy': 0.8571428571428571}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 51] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.9149889349937439\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.9149889349937439, 'test_accuracy': 0.7142857142857143}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 0] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.05836184695363045\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.05836184695363045, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 55] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.1646168977022171\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.1646168977022171, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 35] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.09966737776994705\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.09966737776994705, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 71] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.09797980636358261\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.09797980636358261, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 44] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6174358129501343\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.6174358129501343, 'test_accuracy': 0.7142857142857143}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 36] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.18595640361309052\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.18595640361309052, 'test_accuracy': 0.8571428571428571}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 34] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.012096187099814415\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.012096187099814415, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 1] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 1.1441709995269775\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 1.1441709995269775, 'test_accuracy': 0.7142857142857143}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 53] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.15535475313663483\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.15535475313663483, 'test_accuracy': 0.8571428571428571}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 28] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.9065967798233032\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.9065967798233032, 'test_accuracy': 0.5714285714285714}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 43] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.23140212893486023\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.23140212893486023, 'test_accuracy': 0.8571428571428571}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 17] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.26236340403556824\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.26236340403556824, 'test_accuracy': 0.8571428571428571}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 81] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.431308388710022\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.431308388710022, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 78] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.9774903059005737\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.9774903059005737, 'test_accuracy': 0.5714285714285714}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 76] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.29566851258277893\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.29566851258277893, 'test_accuracy': 0.8571428571428571}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 26] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.7585023045539856\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.7585023045539856, 'test_accuracy': 0.7142857142857143}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 66] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.04892507940530777\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.04892507940530777, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 58] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.2401321977376938\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.2401321977376938, 'test_accuracy': 0.8571428571428571}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 19] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.4521387219429016\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.4521387219429016, 'test_accuracy': 0.7142857142857143}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 95] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.7764194011688232\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.7764194011688232, 'test_accuracy': 0.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 90] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6511720418930054\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.6511720418930054, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 2] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.46399086713790894\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.46399086713790894, 'test_accuracy': 0.7142857142857143}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 93] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.41247430443763733\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.41247430443763733, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 77] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.08187631517648697\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.08187631517648697, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 31] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.11376051604747772\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.11376051604747772, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 37] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.4210655093193054\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.4210655093193054, 'test_accuracy': 0.7142857142857143}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 14] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.22990022599697113\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.22990022599697113, 'test_accuracy': 0.8571428571428571}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 68] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.11969957500696182\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.11969957500696182, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 38] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.23283959925174713\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.23283959925174713, 'test_accuracy': 0.8571428571428571}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 33] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.06621149182319641\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.06621149182319641, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 50] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.0854397863149643\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.0854397863149643, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 32] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.3356626033782959\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.3356626033782959, 'test_accuracy': 0.8571428571428571}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 7] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.16396485269069672\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.16396485269069672, 'test_accuracy': 0.8571428571428571}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 39] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.18208667635917664\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.18208667635917664, 'test_accuracy': 0.8571428571428571}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 3] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.38173478841781616\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.38173478841781616, 'test_accuracy': 0.7142857142857143}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 67] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.18250489234924316\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.18250489234924316, 'test_accuracy': 0.8571428571428571}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 8] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.09593868255615234\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.09593868255615234, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 65] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.41194015741348267\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.41194015741348267, 'test_accuracy': 0.7142857142857143}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 11] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.20669874548912048\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.20669874548912048, 'test_accuracy': 0.8571428571428571}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 92] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.3602861762046814\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.3602861762046814, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 96] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.5240305066108704\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.5240305066108704, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 86] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.2366401106119156\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.2366401106119156, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 25] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.5550996661186218\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.5550996661186218, 'test_accuracy': 0.5714285714285714}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 99] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.43085646629333496\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.43085646629333496, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 75] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.11206706613302231\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.11206706613302231, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 73] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.29396647214889526\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.29396647214889526, 'test_accuracy': 0.7142857142857143}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 87] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.616981029510498\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.616981029510498, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 46] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.46167558431625366\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.46167558431625366, 'test_accuracy': 0.8571428571428571}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 91] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.15331211686134338\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.15331211686134338, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 69] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.5026234984397888\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.5026234984397888, 'test_accuracy': 0.8571428571428571}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 88] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6750105023384094\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.6750105023384094, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 59] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.2747478187084198\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.2747478187084198, 'test_accuracy': 0.8571428571428571}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 49] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.19634047150611877\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.19634047150611877, 'test_accuracy': 0.8571428571428571}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 98] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.4556572735309601\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.4556572735309601, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 27] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.1083218976855278\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.1083218976855278, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 47] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.07950680702924728\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.07950680702924728, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 22] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.20482082664966583\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.20482082664966583, 'test_accuracy': 0.8571428571428571}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 54] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.15919364988803864\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.15919364988803864, 'test_accuracy': 0.8571428571428571}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 79] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.7055955529212952\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.7055955529212952, 'test_accuracy': 0.7}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 15] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.1005898043513298\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.1005898043513298, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 89] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6423200964927673\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.6423200964927673, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 72] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.16753898561000824\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.16753898561000824, 'test_accuracy': 0.8571428571428571}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 63] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.24013550579547882\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.24013550579547882, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 60] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.07087462395429611\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.07087462395429611, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 13] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.24127104878425598\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.24127104878425598, 'test_accuracy': 0.8571428571428571}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 80] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.7399893999099731\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.7399893999099731, 'test_accuracy': 0.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 16] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.04433315247297287\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.04433315247297287, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m [Client 74] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-08-24 14:24:37,380 | server.py:182 | evaluate_round 3 received 100 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 3 received 100 results and 0 failures\n",
            "DEBUG flwr 2023-08-24 14:24:37,385 | server.py:218 | fit_round 4: strategy sampled 100 clients (out of 100)\n",
            "DEBUG:flwr:fit_round 4: strategy sampled 100 clients (out of 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.12115556746721268\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2951)\u001b[0m EVAL_LIST [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'test_loss': 0.12115556746721268, 'test_accuracy': 1.0}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 93] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.48650476336479187\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 1 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 1]                     loss: 1.7321231365203857 accuracy: 0.3076923076923077\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 1]                     loss: 0.5791503190994263 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 1]                     loss: 0.5616052746772766 accuracy: 0.7692307692307693\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 1]                     loss: 0.9213387966156006 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 1]                     loss: 0.7106529474258423 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.48650476336479187, 'train_accuracy': 0.8461538461538461}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 93] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 76] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.33546243607997894\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.2898487150669098 accuracy: 0.8888888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.2665521303812663 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.2185449500878652 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.10662096738815308 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.10030982022484143 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.33546243607997894, 'train_accuracy': 0.9166666666666666}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 76] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 5] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.23630941907564798\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.28956082959969837 accuracy: 0.8611111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.14344857881466547 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.11197872708241145 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.127371267726024 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.07389280820886295 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.23630941907564798, 'train_accuracy': 0.9166666666666666}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 5] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 10] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.15001127123832703\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.21490559975306192 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.27530569583177567 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.09852530807256699 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.12293976296981175 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.28044721484184265 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.15001127123832703, 'train_accuracy': 0.9305555555555556}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 10] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 23] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.13772213707367578\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.2651538948218028 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.1379734625418981 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.09826882369816303 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.055999756480256714 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.05220619961619377 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.13772213707367578, 'train_accuracy': 0.8888888888888888}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 23] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 40] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.23413321375846863\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.21441483249266943 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.1641170158982277 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.11072591071327527 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.045719110096494354 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.042388818226754665 accuracy: 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.23413321375846863, 'train_accuracy': 0.9027777777777778}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 40] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 88] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.7649393081665039\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 1 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 1]                     loss: 1.4239211082458496 accuracy: 0.38461538461538464\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 1]                     loss: 0.6140584349632263 accuracy: 0.6153846153846154\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 1]                     loss: 0.4179624915122986 accuracy: 0.9230769230769231\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 1]                     loss: 0.554125964641571 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 1]                     loss: 0.5551677346229553 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.7649393081665039, 'train_accuracy': 0.5384615384615384}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 88] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 38] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.46487237016359967\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.3691169818242391 accuracy: 0.8055555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.23272867997487387 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.1556566854317983 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.19392051299413046 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.08006018276015918 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.46487237016359967, 'train_accuracy': 0.8472222222222222}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 38] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 4] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.21412187814712524\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.2402401715517044 accuracy: 0.875\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.22393294920523962 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.1107917254169782 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.18452626590927443 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.18247359742720923 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.21412187814712524, 'train_accuracy': 0.8888888888888888}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 4] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 18] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.32009949286778766\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.35901252925395966 accuracy: 0.8888888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.13112678875525793 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.1625461975733439 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.049016871800025306 accuracy: 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.0856906995177269 accuracy: 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.32009949286778766, 'train_accuracy': 0.8888888888888888}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 18] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 29] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.16499411563078561\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.24133502940336862 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.35801903655131656 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.1320241540670395 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.23396939287583032 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.237265278895696 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.16499411563078561, 'train_accuracy': 0.9027777777777778}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 29] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 63] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.18430543939272562\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.37636753420035046 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.16962661345799765 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.25199082245429355 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.1613020400206248 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.11057952046394348 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.18430543939272562, 'train_accuracy': 0.9305555555555556}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 63] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 17] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.22335139413674673\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.2808131625254949 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.14774096881349882 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.13695250203212103 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.05153707539041837 accuracy: 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.07823049277067184 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.22335139413674673, 'train_accuracy': 0.9027777777777778}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 17] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 34] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.23881013691425323\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.20286339024702707 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.1642203082640966 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.2507973574101925 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.1960288311044375 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.10345153510570526 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.23881013691425323, 'train_accuracy': 0.9166666666666666}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 34] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 37] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.28555161009232205\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.3396978974342346 accuracy: 0.8611111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.1863227585951487 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.13046065345406532 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.15892347693443298 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.14545328418413797 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.28555161009232205, 'train_accuracy': 0.8888888888888888}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 37] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 27] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.15485888719558716\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.21109268069267273 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.17455741266409555 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.266962680965662 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.11844900126258533 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.05524983505407969 accuracy: 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.15485888719558716, 'train_accuracy': 0.9166666666666666}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 27] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 47] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.22992918640375137\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.15565807620684305 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.1147553523381551 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.07608680427074432 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.07391801724831264 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.04054624463121096 accuracy: 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.22992918640375137, 'train_accuracy': 0.9583333333333334}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 47] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 33] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.2170689801375071\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.22493127981821695 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.23539363841215769 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.19526169200738272 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.26145918170611065 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.07547842090328534 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.2170689801375071, 'train_accuracy': 0.8888888888888888}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 33] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 91] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.7045878171920776\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 1 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 1]                     loss: 1.7828240394592285 accuracy: 0.3076923076923077\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 1]                     loss: 0.6019183397293091 accuracy: 0.7692307692307693\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 1]                     loss: 0.6307030320167542 accuracy: 0.7692307692307693\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 1]                     loss: 0.7285910844802856 accuracy: 0.7692307692307693\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 1]                     loss: 0.5752602219581604 accuracy: 0.7692307692307693\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.7045878171920776, 'train_accuracy': 0.6153846153846154}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 91] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 11] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.11433161546786626\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.11204551408688228 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.15024036169052124 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.0708397130171458 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.020957307269175846 accuracy: 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.036116864532232285 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.11433161546786626, 'train_accuracy': 0.9722222222222222}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 11] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 46] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.1570269117752711\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.14206185936927795 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.15219536299506822 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.142933522661527 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.14005505169431368 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.0757828230659167 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.1570269117752711, 'train_accuracy': 0.9583333333333334}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 46] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 25] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.19954718152681986\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.21976566314697266 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.19103879978259405 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.11574581762154897 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.1080747867623965 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.1330193281173706 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.19954718152681986, 'train_accuracy': 0.875}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 25] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 70] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.18268907566865286\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.19712503254413605 accuracy: 0.8888888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.09586371233065923 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.3924875383575757 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.09486340483029683 accuracy: 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.08307811617851257 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.18268907566865286, 'train_accuracy': 0.9166666666666666}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 70] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 2] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.1382166345914205\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.24895232915878296 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.18289040277401605 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.09380391488472621 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.04996114100019137 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.0761458749572436 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.1382166345914205, 'train_accuracy': 0.9861111111111112}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 2] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 30] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.1924546162287394\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.3280492077271144 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.18724743276834488 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.11732658247152965 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.23213858902454376 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.053377432748675346 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.1924546162287394, 'train_accuracy': 0.9305555555555556}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 30] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 21] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.2176815668741862\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.3191802153984706 accuracy: 0.8888888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.2750066990653674 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.3872619594136874 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.34108134110768634 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.10880372300744057 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.2176815668741862, 'train_accuracy': 0.8888888888888888}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 21] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 49] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.20650204829871655\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.2418208047747612 accuracy: 0.8611111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.1615069036682447 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.08048992976546288 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.05598549793163935 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.23976866031686464 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.20650204829871655, 'train_accuracy': 0.875}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 49] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 50] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.15346712867418924\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.17216837157805762 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.16591528554757437 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.04953461016217867 accuracy: 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.07034658392270406 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.1439999391635259 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.15346712867418924, 'train_accuracy': 0.9166666666666666}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 50] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 78] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.2799353301525116\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.27402696510155994 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.3601244240999222 accuracy: 0.875\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.23511415223280588 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.11181224882602692 accuracy: 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.10379373282194138 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.2799353301525116, 'train_accuracy': 0.9166666666666666}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 78] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 28] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.35398373007774353\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.29101454714934033 accuracy: 0.875\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.16644328087568283 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.1253414750099182 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.13228328774372736 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.09845748419562976 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.35398373007774353, 'train_accuracy': 0.8611111111111112}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 28] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 60] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.18839233120282492\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.18373187879721323 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.11910724019010861 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.056610146537423134 accuracy: 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.03397178649902344 accuracy: 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.05566287351151308 accuracy: 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.18839233120282492, 'train_accuracy': 0.8888888888888888}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 60] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 94] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6971887350082397\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 1 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 1]                     loss: 1.6679859161376953 accuracy: 0.23076923076923078\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 1]                     loss: 0.5621378421783447 accuracy: 0.7692307692307693\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 1]                     loss: 0.6568939685821533 accuracy: 0.8461538461538461\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 1]                     loss: 0.8237285017967224 accuracy: 0.7692307692307693\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 1]                     loss: 0.671453595161438 accuracy: 0.7692307692307693\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6971887350082397, 'train_accuracy': 0.6153846153846154}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 94] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 65] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.34917240341504413\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.3484897315502167 accuracy: 0.8472222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.2659933219353358 accuracy: 0.875\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.1017955740292867 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.07100377976894379 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.09602649261554082 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.34917240341504413, 'train_accuracy': 0.875}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 65] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 68] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.16138750687241554\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.26690514882405597 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.1830662041902542 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.11596711352467537 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.10400743285814922 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.0640038326382637 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.16138750687241554, 'train_accuracy': 0.9166666666666666}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 68] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 95] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.8189990520477295\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 1 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 1]                     loss: 1.2565600872039795 accuracy: 0.5384615384615384\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 1]                     loss: 0.9723629355430603 accuracy: 0.38461538461538464\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 1]                     loss: 0.43588414788246155 accuracy: 0.7692307692307693\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 1]                     loss: 0.5555314421653748 accuracy: 0.6153846153846154\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 1]                     loss: 0.35022470355033875 accuracy: 0.7692307692307693\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.8189990520477295, 'train_accuracy': 0.5384615384615384}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 95] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 86] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.8792973756790161\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 1 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 1]                     loss: 1.2821577787399292 accuracy: 0.5384615384615384\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 1]                     loss: 0.6980313062667847 accuracy: 0.5384615384615384\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 1]                     loss: 0.32257479429244995 accuracy: 0.9230769230769231\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 1]                     loss: 0.37963807582855225 accuracy: 0.8461538461538461\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 1]                     loss: 0.28864991664886475 accuracy: 0.8461538461538461\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.8792973756790161, 'train_accuracy': 0.23076923076923078}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 86] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 73] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.17546081046263376\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.27386508385340375 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.2354933296640714 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.1349718471368154 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.08211086442073186 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.17022467156251272 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.17546081046263376, 'train_accuracy': 0.9444444444444444}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 73] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 19] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.23754043380419412\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.33058277269204456 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.2619546328981717 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.27914585421482724 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.08763924489418666 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.15282814825574556 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.23754043380419412, 'train_accuracy': 0.8888888888888888}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 19] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 62] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.21097137033939362\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.2590230703353882 accuracy: 0.8472222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.16345185041427612 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.053167382876078285 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.12921738252043724 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.057487632458408676 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.21097137033939362, 'train_accuracy': 0.9166666666666666}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 62] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 89] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.6866104602813721\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 1 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 1]                     loss: 1.1028803586959839 accuracy: 0.5384615384615384\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 1]                     loss: 0.5332518815994263 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 1]                     loss: 0.31595292687416077 accuracy: 0.8461538461538461\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 1]                     loss: 0.4832744300365448 accuracy: 0.6153846153846154\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 1]                     loss: 0.44019052386283875 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6866104602813721, 'train_accuracy': 0.6153846153846154}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 89] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 97] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.7191794514656067\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 1 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 1]                     loss: 1.3547166585922241 accuracy: 0.3076923076923077\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 1]                     loss: 0.5493112206459045 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 1]                     loss: 0.4647887349128723 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 1]                     loss: 0.4848315417766571 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 1]                     loss: 0.723350465297699 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.7191794514656067, 'train_accuracy': 0.6153846153846154}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 97] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 3] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.1883097986380259\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.18954111138979593 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.14533870667219162 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.16464699183901152 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.17769558851917586 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.08679192637403806 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.1883097986380259, 'train_accuracy': 0.8472222222222222}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 3] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 6] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.1718225528796514\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.12115263938903809 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.19037717829147974 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.11462493737538655 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.06488461916645367 accuracy: 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.04559525350729624 accuracy: 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.1718225528796514, 'train_accuracy': 0.9444444444444444}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 6] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 7] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.3353178600470225\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.2564048220713933 accuracy: 0.875\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.18179733554522196 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.11334947248299916 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.08975935727357864 accuracy: 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.30881406863530475 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.3353178600470225, 'train_accuracy': 0.9166666666666666}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 7] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 79] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.19066093365351358\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.25409916043281555 accuracy: 0.8829787234042553\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.10423387338717778 accuracy: 0.9787234042553191\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.07932023952404658 accuracy: 0.9893617021276596\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.045914240181446075 accuracy: 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.028752222657203674 accuracy: 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.19066093365351358, 'train_accuracy': 0.9148936170212766}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 79] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 32] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.14819111799200377\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.35011742015679675 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.1631718873977661 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.19282778600851694 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.10688337000707786 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.16073318819204965 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.14819111799200377, 'train_accuracy': 0.9583333333333334}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 32] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 69] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.24011139074961343\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.3188045124212901 accuracy: 0.8611111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.2411251664161682 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.21500755846500397 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.10831284771362941 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.15113126238187155 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.24011139074961343, 'train_accuracy': 0.9027777777777778}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 69] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 67] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.24998230238755545\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.25062498450279236 accuracy: 0.875\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.2906697293122609 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.3265274465084076 accuracy: 0.875\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.1773748646179835 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.1111107338219881 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.24998230238755545, 'train_accuracy': 0.8472222222222222}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 67] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 56] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.16711184879144034\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.20299267023801804 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.08658500760793686 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.11441296339035034 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.06777639935413997 accuracy: 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.044539790600538254 accuracy: 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.16711184879144034, 'train_accuracy': 0.9444444444444444}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 56] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 59] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.2657022774219513\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.2457961936791738 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.1372626175483068 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.23269574344158173 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.08558867995937665 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.05273101106286049 accuracy: 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.2657022774219513, 'train_accuracy': 0.9027777777777778}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 59] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 83] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.610607385635376\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 1 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 1]                     loss: 1.8266581296920776 accuracy: 0.15384615384615385\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 1]                     loss: 0.5490336418151855 accuracy: 0.6153846153846154\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 1]                     loss: 0.5507857203483582 accuracy: 0.8461538461538461\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 1]                     loss: 0.6536238193511963 accuracy: 0.8461538461538461\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 1]                     loss: 0.9985414147377014 accuracy: 0.8461538461538461\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.610607385635376, 'train_accuracy': 0.6153846153846154}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 83] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 80] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.8472559452056885\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 1 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 1]                     loss: 0.6668558716773987 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 1]                     loss: 0.5061822533607483 accuracy: 0.6153846153846154\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 1]                     loss: 0.4048592746257782 accuracy: 0.8461538461538461\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 1]                     loss: 0.32056957483291626 accuracy: 0.9230769230769231\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 1]                     loss: 0.2514369785785675 accuracy: 0.9230769230769231\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.8472559452056885, 'train_accuracy': 0.46153846153846156}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 80] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 57] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.15268723045786223\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.26385371883710224 accuracy: 0.875\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.21735315894087157 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.21077140172322592 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.2190289298693339 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.19915915156404176 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.15268723045786223, 'train_accuracy': 0.9166666666666666}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 57] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m [Client 51] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Dataset HBCDs with evaluation loss: 0.2296327749888102\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.18411143372456232 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2951)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.13023861745993295 accuracy: 0.9444444444444444\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR flwr 2023-08-24 15:21:31,107 | ray_client_proxy.py:87 | Task was killed due to the node running low on memory.\n",
            "Memory on the node (IP: 172.28.0.12, ID: 284727c58bf996a412d2b883aa5bf57a1943c709dbdaa69932a9efae) where the task (task ID: 266d08d2b468d545570721718cdaa07a0ea3ef2101000000, name=launch_and_fit, pid=2951, memory used=4.09GB) was running was 12.06GB / 12.68GB (0.950972), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: 7cf68ae7be52444fade4c465a39f5d908a329fbe441013f7e3b9f3d0) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 172.28.0.12`. To see the logs of the worker, use `ray logs worker-7cf68ae7be52444fade4c465a39f5d908a329fbe441013f7e3b9f3d0*out -ip 172.28.0.12. Top 10 memory users:\n",
            "PID\tMEM(GB)\tCOMMAND\n",
            "581\t5.05\t/usr/bin/python3 -m ipykernel_launcher -f /root/.local/share/jupyter/runtime/kernel-c95dc878-399e-47...\n",
            "2951\t4.09\tray::launch_and_fit\n",
            "79\t0.11\t/usr/bin/python3 /usr/local/bin/jupyter-notebook --debug --transport=\"ipc\" --ip=172.28.0.12 --Notebo...\n",
            "2936\t0.06\t/usr/bin/python3 -u /usr/local/lib/python3.10/dist-packages/ray/dashboard/agent.py --node-ip-address...\n",
            "2825\t0.06\t/usr/local/lib/python3.10/dist-packages/ray/core/src/ray/gcs/gcs_server --log_dir=/tmp/ray/session_2...\n",
            "2858\t0.06\t/usr/bin/python3 /usr/local/lib/python3.10/dist-packages/ray/dashboard/dashboard.py --host=127.0.0.1...\n",
            "2853\t0.05\t/usr/bin/python3 -u /usr/local/lib/python3.10/dist-packages/ray/autoscaler/_private/monitor.py --log...\n",
            "2894\t0.05\t/usr/bin/python3 -u /usr/local/lib/python3.10/dist-packages/ray/_private/log_monitor.py --logs-dir=/...\n",
            "7\t0.03\t/tools/node/bin/node /datalab/web/app.js\n",
            "62\t0.03\tpython3 /usr/local/bin/colab-fileshim.py\n",
            "Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
            "ERROR:flwr:Task was killed due to the node running low on memory.\n",
            "Memory on the node (IP: 172.28.0.12, ID: 284727c58bf996a412d2b883aa5bf57a1943c709dbdaa69932a9efae) where the task (task ID: 266d08d2b468d545570721718cdaa07a0ea3ef2101000000, name=launch_and_fit, pid=2951, memory used=4.09GB) was running was 12.06GB / 12.68GB (0.950972), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: 7cf68ae7be52444fade4c465a39f5d908a329fbe441013f7e3b9f3d0) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 172.28.0.12`. To see the logs of the worker, use `ray logs worker-7cf68ae7be52444fade4c465a39f5d908a329fbe441013f7e3b9f3d0*out -ip 172.28.0.12. Top 10 memory users:\n",
            "PID\tMEM(GB)\tCOMMAND\n",
            "581\t5.05\t/usr/bin/python3 -m ipykernel_launcher -f /root/.local/share/jupyter/runtime/kernel-c95dc878-399e-47...\n",
            "2951\t4.09\tray::launch_and_fit\n",
            "79\t0.11\t/usr/bin/python3 /usr/local/bin/jupyter-notebook --debug --transport=\"ipc\" --ip=172.28.0.12 --Notebo...\n",
            "2936\t0.06\t/usr/bin/python3 -u /usr/local/lib/python3.10/dist-packages/ray/dashboard/agent.py --node-ip-address...\n",
            "2825\t0.06\t/usr/local/lib/python3.10/dist-packages/ray/core/src/ray/gcs/gcs_server --log_dir=/tmp/ray/session_2...\n",
            "2858\t0.06\t/usr/bin/python3 /usr/local/lib/python3.10/dist-packages/ray/dashboard/dashboard.py --host=127.0.0.1...\n",
            "2853\t0.05\t/usr/bin/python3 -u /usr/local/lib/python3.10/dist-packages/ray/autoscaler/_private/monitor.py --log...\n",
            "2894\t0.05\t/usr/bin/python3 -u /usr/local/lib/python3.10/dist-packages/ray/_private/log_monitor.py --logs-dir=/...\n",
            "7\t0.03\t/tools/node/bin/node /datalab/web/app.js\n",
            "62\t0.03\tpython3 /usr/local/bin/colab-fileshim.py\n",
            "Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
            "\u001b[2m\u001b[36m(pid=92101)\u001b[0m 2023-08-24 15:21:40.029818: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m [Client 15] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Dataset HBCDs with evaluation loss: 0.21698181331157684\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-08-24 15:22:05,888 E 2893 2893] (raylet) node_manager.cc:3084: 1 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 284727c58bf996a412d2b883aa5bf57a1943c709dbdaa69932a9efae, IP: 172.28.0.12) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.28.0.12`\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.2601291040579478 accuracy: 0.8888888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.17689304798841476 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.16511793931325278 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.19655541082223257 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.11629275729258855 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.21698181331157684, 'train_accuracy': 0.875}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m [Client 15] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m [Client 9] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Dataset HBCDs with evaluation loss: 0.2745137959718704\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.2565240114927292 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.15593178570270538 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.07928427308797836 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.0799327294031779 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.07701317841808002 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.2745137959718704, 'train_accuracy': 0.9444444444444444}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m [Client 9] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m [Client 12] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Dataset HBCDs with evaluation loss: 0.17305561155080795\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.20075149337450662 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.06742529198527336 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.05691251282890638 accuracy: 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.048404041677713394 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.028331217045585316 accuracy: 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.17305561155080795, 'train_accuracy': 0.9305555555555556}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m [Client 12] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Dataset HBCDs with evaluation loss: 0.29994258284568787\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.4128255049387614 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.26197347044944763 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.35881966600815457 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.19629441450039545 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.10291137546300888 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.29994258284568787, 'train_accuracy': 0.875}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m [Client 1] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m [Client 35] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Dataset HBCDs with evaluation loss: 0.20965013404687247\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.21608294546604156 accuracy: 0.875\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.1956023946404457 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.06523969024419785 accuracy: 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.05720717832446098 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.051436434189478554 accuracy: 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.20965013404687247, 'train_accuracy': 0.875}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m [Client 35] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m [Client 55] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Dataset HBCDs with evaluation loss: 0.22917896012465158\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.2434111386537552 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.2164872189362844 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.09731404234965642 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.11532281835873921 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.05424500505129496 accuracy: 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.22917896012465158, 'train_accuracy': 0.9166666666666666}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m [Client 55] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m [Client 54] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Dataset HBCDs with evaluation loss: 0.3969791730244954\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.23954698691765466 accuracy: 0.8611111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.23729336758454642 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.1152120108405749 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.11177404100696246 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.12184671560923259 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.3969791730244954, 'train_accuracy': 0.9027777777777778}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m [Client 54] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m [Client 75] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Dataset HBCDs with evaluation loss: 0.2753090610106786\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.3916784425576528 accuracy: 0.8611111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.31984808047612506 accuracy: 0.8472222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.20111791789531708 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.09424764662981033 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.08256965254743893 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.2753090610106786, 'train_accuracy': 0.9166666666666666}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m [Client 75] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m [Client 82] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Dataset HBCDs with evaluation loss: 0.7249035239219666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 1 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [1, 1]                     loss: 1.822372555732727 accuracy: 0.3076923076923077\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [2, 1]                     loss: 0.46663886308670044 accuracy: 0.7692307692307693\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [3, 1]                     loss: 0.7109259366989136 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [4, 1]                     loss: 0.6031569838523865 accuracy: 0.6153846153846154\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [5, 1]                     loss: 0.6283932328224182 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.7249035239219666, 'train_accuracy': 0.5384615384615384}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m [Client 82] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m [Client 13] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Dataset HBCDs with evaluation loss: 0.1718083620071411\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.26603666692972183 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.28372431298096973 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.22439718743165335 accuracy: 0.875\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.14797414590915045 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.09053657948970795 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.1718083620071411, 'train_accuracy': 0.9166666666666666}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m [Client 13] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m [Client 48] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Dataset HBCDs with evaluation loss: 0.3672793010870616\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.27740058799584705 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.16615966459115347 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.1483253836631775 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.07857327784101169 accuracy: 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.05273364235957464 accuracy: 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.3672793010870616, 'train_accuracy': 0.9027777777777778}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m [Client 48] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m [Client 64] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Dataset HBCDs with evaluation loss: 0.2166896859804789\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.23536651829878488 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.2014729082584381 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.07683410992225011 accuracy: 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.08700212463736534 accuracy: 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.07362076950569947 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.2166896859804789, 'train_accuracy': 0.9166666666666666}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m [Client 64] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m [Client 20] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Dataset HBCDs with evaluation loss: 0.23932314664125443\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.18265380213658014 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.20097161332766214 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.05436507612466812 accuracy: 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.26075244322419167 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.07476217113435268 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.23932314664125443, 'train_accuracy': 0.8472222222222222}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m [Client 20] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m [Client 42] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Dataset HBCDs with evaluation loss: 0.18483455292880535\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.5960680643717448 accuracy: 0.875\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.5626115401585897 accuracy: 0.8611111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.12192178145051003 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.3640284091234207 accuracy: 0.8472222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.22636052717765173 accuracy: 0.875\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.18483455292880535, 'train_accuracy': 0.9027777777777778}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m [Client 42] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m [Client 24] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Dataset HBCDs with evaluation loss: 0.20689116418361664\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.2819301088651021 accuracy: 0.8888888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.3502781043450038 accuracy: 0.8611111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.1367180347442627 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.3430764079093933 accuracy: 0.8333333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.26332103709379834 accuracy: 0.8333333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.20689116418361664, 'train_accuracy': 0.9027777777777778}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m [Client 24] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m [Client 71] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Dataset HBCDs with evaluation loss: 0.2083071917295456\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.3328827867905299 accuracy: 0.875\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.3128233427802722 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.20593238870302835 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.20647137115399042 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.18547246605157852 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.2083071917295456, 'train_accuracy': 0.875}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m [Client 71] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m [Client 52] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Dataset HBCDs with evaluation loss: 0.15194016446669897\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.1568918526172638 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.12206665923198064 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.11915083602070808 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.06417793035507202 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.0375176394979159 accuracy: 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.15194016446669897, 'train_accuracy': 0.9444444444444444}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m [Client 52] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m [Client 81] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Dataset HBCDs with evaluation loss: 0.7599235773086548\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 1 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [1, 1]                     loss: 1.8519492149353027 accuracy: 0.23076923076923078\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [2, 1]                     loss: 0.5262349247932434 accuracy: 0.6153846153846154\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [3, 1]                     loss: 0.7641739249229431 accuracy: 0.7692307692307693\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [4, 1]                     loss: 0.9375231862068176 accuracy: 0.7692307692307693\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [5, 1]                     loss: 0.8121551871299744 accuracy: 0.7692307692307693\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.7599235773086548, 'train_accuracy': 0.5384615384615384}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m [Client 81] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m [Client 85] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Dataset HBCDs with evaluation loss: 0.670906126499176\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 1 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [1, 1]                     loss: 1.2655495405197144 accuracy: 0.5384615384615384\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [2, 1]                     loss: 0.543318510055542 accuracy: 0.5384615384615384\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [3, 1]                     loss: 0.4194009006023407 accuracy: 0.7692307692307693\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [4, 1]                     loss: 0.5995252728462219 accuracy: 0.8461538461538461\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [5, 1]                     loss: 0.523661196231842 accuracy: 0.7692307692307693\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.670906126499176, 'train_accuracy': 0.6153846153846154}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m [Client 85] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m [Client 66] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Dataset HBCDs with evaluation loss: 0.1884587655464808\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.24003521104653677 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.16233354061841965 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.1688395912448565 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.18686719487110773 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.1742838645974795 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.1884587655464808, 'train_accuracy': 0.9444444444444444}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m [Client 66] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m [Client 61] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Dataset HBCDs with evaluation loss: 0.22079529613256454\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.35796937843163806 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.2661287784576416 accuracy: 0.8888888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.2403788541754087 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.12030718227227528 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.09830207874377568 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.22079529613256454, 'train_accuracy': 0.875}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m [Client 61] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m [Client 87] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Dataset HBCDs with evaluation loss: 0.6082591414451599\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 1 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [1, 1]                     loss: 1.754218339920044 accuracy: 0.3076923076923077\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [2, 1]                     loss: 0.4803750813007355 accuracy: 0.8461538461538461\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [3, 1]                     loss: 0.4367455244064331 accuracy: 0.7692307692307693\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [4, 1]                     loss: 0.506197988986969 accuracy: 0.7692307692307693\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [5, 1]                     loss: 0.5194278359413147 accuracy: 0.7692307692307693\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6082591414451599, 'train_accuracy': 0.6923076923076923}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m [Client 87] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m [Client 45] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Dataset HBCDs with evaluation loss: 0.18177181482315063\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.14079001049200693 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.11216292281945546 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.06524755184849103 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.1584718581289053 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.04109878900150458 accuracy: 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.18177181482315063, 'train_accuracy': 0.9444444444444444}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m [Client 45] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Dataset HBCDs with evaluation loss: 0.1911669373512268\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.23204385737578073 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.21280633906523386 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.24746189514795938 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.08643958220879237 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.11397496362527211 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.1911669373512268, 'train_accuracy': 0.9166666666666666}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m [Client 0] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m [Client 14] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Dataset HBCDs with evaluation loss: 0.2401427080233892\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.30209334194660187 accuracy: 0.8333333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.17864753057559332 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.12018742163976033 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.08286723742882411 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.10964801907539368 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.2401427080233892, 'train_accuracy': 0.8472222222222222}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m [Client 14] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m [Client 90] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Dataset HBCDs with evaluation loss: 0.5535098910331726\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 1 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [1, 1]                     loss: 1.5668036937713623 accuracy: 0.23076923076923078\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [2, 1]                     loss: 0.4620513617992401 accuracy: 0.8461538461538461\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [3, 1]                     loss: 0.40397772192955017 accuracy: 0.7692307692307693\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [4, 1]                     loss: 0.6203761696815491 accuracy: 0.7692307692307693\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [5, 1]                     loss: 0.44656312465667725 accuracy: 0.7692307692307693\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.5535098910331726, 'train_accuracy': 0.6153846153846154}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m [Client 90] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m [Client 72] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Dataset HBCDs with evaluation loss: 0.2508454769849777\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.20990605900684992 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.14323357492685318 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.12994189063707987 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.1298342322309812 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.061633446564277015 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.2508454769849777, 'train_accuracy': 0.8611111111111112}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m [Client 72] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m [Client 99] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Dataset HBCDs with evaluation loss: 0.8159769177436829\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 1 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [1, 1]                     loss: 1.1868492364883423 accuracy: 0.47619047619047616\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [2, 1]                     loss: 0.7822966575622559 accuracy: 0.6190476190476191\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [3, 1]                     loss: 0.7033334374427795 accuracy: 0.5714285714285714\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [4, 1]                     loss: 0.8270280957221985 accuracy: 0.6190476190476191\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [5, 1]                     loss: 0.8568384051322937 accuracy: 0.6666666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.8159769177436829, 'train_accuracy': 0.47619047619047616}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m [Client 99] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m [Client 74] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Dataset HBCDs with evaluation loss: 0.35863302896420163\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.22247333576281866 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.10354755322138469 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.0881287157535553 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.03847974787155787 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.2760583230604728 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.35863302896420163, 'train_accuracy': 0.9166666666666666}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m [Client 74] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m [Client 39] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Dataset HBCDs with evaluation loss: 0.4502090513706207\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.2608712315559387 accuracy: 0.8611111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.13128849615653357 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.10935060183207194 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.06824624290068944 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.05264168977737427 accuracy: 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.4502090513706207, 'train_accuracy': 0.8611111111111112}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m [Client 39] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m [Client 8] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Dataset HBCDs with evaluation loss: 0.22884061932563782\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.4030637939771016 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.16133254518111548 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.11631698906421661 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.0881919264793396 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.03392714696625868 accuracy: 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.22884061932563782, 'train_accuracy': 0.9305555555555556}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m [Client 8] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m [Client 98] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Dataset HBCDs with evaluation loss: 0.742374062538147\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 1 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [1, 1]                     loss: 1.4595482349395752 accuracy: 0.38461538461538464\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [2, 1]                     loss: 0.5965667366981506 accuracy: 0.7692307692307693\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [3, 1]                     loss: 0.5555209517478943 accuracy: 0.6153846153846154\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [4, 1]                     loss: 0.7120447158813477 accuracy: 0.6153846153846154\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [5, 1]                     loss: 0.618507981300354 accuracy: 0.6153846153846154\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.742374062538147, 'train_accuracy': 0.46153846153846156}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m [Client 98] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m [Client 26] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Dataset HBCDs with evaluation loss: 0.243806853890419\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.18324275066455206 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.11416077117125194 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.05272487054268519 accuracy: 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.02989992778748274 accuracy: 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.1809697293986877 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.243806853890419, 'train_accuracy': 0.8611111111111112}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m [Client 26] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m [Client 96] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Dataset HBCDs with evaluation loss: 0.7902328968048096\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 1 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [1, 1]                     loss: 1.7127525806427002 accuracy: 0.38461538461538464\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [2, 1]                     loss: 0.600009024143219 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [3, 1]                     loss: 0.4873219132423401 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [4, 1]                     loss: 0.664494514465332 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [5, 1]                     loss: 0.7454107999801636 accuracy: 0.7692307692307693\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.7902328968048096, 'train_accuracy': 0.46153846153846156}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m [Client 96] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m [Client 84] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Dataset HBCDs with evaluation loss: 0.6283772587776184\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 1 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [1, 1]                     loss: 1.6756443977355957 accuracy: 0.38461538461538464\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [2, 1]                     loss: 0.6867951154708862 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [3, 1]                     loss: 0.7361937761306763 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [4, 1]                     loss: 1.113478183746338 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [5, 1]                     loss: 0.9979057908058167 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.6283772587776184, 'train_accuracy': 0.6153846153846154}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m [Client 84] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m [Client 41] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Dataset HBCDs with evaluation loss: 0.213372141122818\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.24202925711870193 accuracy: 0.8888888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.31339003642400104 accuracy: 0.9166666666666666\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.14513378341992697 accuracy: 0.9583333333333334\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.19902817408243814 accuracy: 0.8888888888888888\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.12679526830712953 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.213372141122818, 'train_accuracy': 0.8888888888888888}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m [Client 41] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m [Client 77] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Dataset HBCDs with evaluation loss: 0.25756874680519104\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.32781684398651123 accuracy: 0.875\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.31045659879843396 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.10092795516053836 accuracy: 0.9722222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.3313770741224289 accuracy: 0.8472222222222222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.42433244983355206 accuracy: 0.8611111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.25756874680519104, 'train_accuracy': 0.875}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m [Client 77] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m [Client 58] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Dataset HBCDs with evaluation loss: 0.24804660429557165\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.28298519551754 accuracy: 0.9027777777777778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [2, 3]                     loss: 0.19164115687211355 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [3, 3]                     loss: 0.13226831207672754 accuracy: 0.9305555555555556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [4, 3]                     loss: 0.09188594048221906 accuracy: 0.9861111111111112\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [5, 3]                     loss: 0.19741660356521606 accuracy: 0.9444444444444444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.24804660429557165, 'train_accuracy': 0.9305555555555556}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m [Client 58] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m [Client 92] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Dataset HBCDs with evaluation loss: 0.601449728012085\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 1 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [1, 1]                     loss: 1.5327447652816772 accuracy: 0.38461538461538464\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [2, 1]                     loss: 0.6711202263832092 accuracy: 0.6153846153846154\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [3, 1]                     loss: 0.7358137369155884 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [4, 1]                     loss: 0.6824207305908203 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [5, 1]                     loss: 0.8524731397628784 accuracy: 0.6923076923076923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m EVAL_LIST_FIT [{'dataset': 'HBCDs', 'fl_round': 0, 'strategy': 'fedbn', 'train_loss': 0.601449728012085, 'train_accuracy': 0.6923076923076923}]\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m [Client 92] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m ROUND BACK OTHER CLIENT 0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m [Client 22] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Dataset HBCDs with evaluation loss: 0.4637619157632192\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Training HBCDs dataset with 5 local epoch(s) w/ 3 batches each\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=92101)\u001b[0m Train Dataset HBCDs with [1, 3]                     loss: 0.30281933148701984 accuracy: 0.875\n"
          ]
        }
      ],
      "source": [
        "# Create FedBN strategy\n",
        "strategy = fl.server.strategy.FedAvg(\n",
        "    fraction_fit=1,\n",
        "    fraction_evaluate=1,\n",
        "    min_fit_clients=10,\n",
        "    min_evaluate_clients=1,\n",
        "    min_available_clients=10,\n",
        "    evaluate_metrics_aggregation_fn=weighted_average,  # <-- pass the metric aggregation function\n",
        ")\n",
        "\n",
        "# Specify client resources if you need GPU (defaults to 1 CPU and 0 GPU)\n",
        "client_resources = {\"num_cpus\" : 2}\n",
        "if DEVICE.type == \"cuda\":\n",
        "    print(\"Using GPU\")\n",
        "    client_resources = {\"num_gpus\": 1}\n",
        "\n",
        "\n",
        "# Start simulation\n",
        "history = fl.simulation.start_simulation(\n",
        "    client_fn=client_fn,\n",
        "    num_clients=NUM_CLIENTS,\n",
        "    config=fl.server.ServerConfig(num_rounds=60),\n",
        "    strategy=strategy,\n",
        "    client_resources=client_resources,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-SCHeXjlTyFy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "outputId": "13b05e33-dc4d-4b9c-8256-dbb9cd6224a9"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-0b220396248c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        }
      ],
      "source": [
        "print(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mMYmQB93TzSS"
      },
      "outputs": [],
      "source": [
        "with open('Histopathological Breast Cancer Dataset_FedBN_results.json', 'w') as fp:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kDHIcKfzT0q7"
      },
      "outputs": [],
      "source": [
        "with open(\n",
        "    \"Histopathological Breast Cancer Dataset_FedBN_results.json\", mode=\"r+\"\n",
        ") as eval_file:\n",
        "    json.dump(eval_list, eval_file)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "with open('Loss_breakHis_dataset.pkl', 'wb') as file:\n",
        "    pickle.dump((history), file)"
      ],
      "metadata": {
        "id": "H9clpGFVl2Oz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Đọc dữ liệu từ file pickle\n",
        "with open('Loss_breakHis_dataset.pkl', 'rb') as file:\n",
        "    read_data_1, read_data_2 = pickle.load(file)\n",
        "\n",
        "# Số lượng epochs\n",
        "epochs = 60\n",
        "plt.figure(figsize=(10, 6))\n",
        "# Tạo list chứa giá trị x-axis từ 0 đến epochs-1\n",
        "x = list(range(epochs))\n",
        "\n",
        "plt.ylim(bottom=0, top=1)\n",
        "plt.grid(True)\n",
        "# Vẽ đồ thị\n",
        "plt.plot(x, read_data_1, label='FedBN')\n",
        "plt.plot(x, read_data_2, label='FedAvg')\n",
        "plt.xlabel('Step')\n",
        "plt.ylabel('Training Loss')\n",
        "plt.title('BreakHis')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "B3CsDFzCmAvu",
        "outputId": "f8063b4e-5433-4a44-a02d-9e2cd4ac6b5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA04AAAIjCAYAAAA0vUuxAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAADWWklEQVR4nOzdd3zV9fXH8de9NzshiwxW2EOGgIAgbpShiHsvFFdtpVVx608tttXaWrW2rqpU66izLlwgiqIiUxCRvcEQEkISsse9vz8+93uTQMa9yV0J7+fjwePe3PkJ3wTu+Z7zOcfmcrlciIiIiIiISKPsoV6AiIiIiIhIuFPgJCIiIiIi0gwFTiIiIiIiIs1Q4CQiIiIiItIMBU4iIiIiIiLNUOAkIiIiIiLSDAVOIiIiIiIizVDgJCIiIiIi0gwFTiIiIiIiIs1Q4CQiIoe0+fPnY7PZePvtt/3+2j179uTKK6/0++uKiEjwKXASEZGgefHFF7HZbPX+ZGRkMG7cOD755JNQL69J1tqXLl3a4P0nnngiQ4YMCfKqREQkWCJCvQARETn0PPDAA/Tq1QuXy0VOTg4vvvgikydP5sMPP2TKlCmhXp7frFu3Drtd5yhFRNoDBU4iIhJ0p556KqNGjfJ8ffXVV5OZmcl///vfRgOn6upqnE4nUVFRwVpmq0VHR4d6CSIi4ic6DSYiIiGXnJxMbGwsERHmfN7WrVux2Ww88sgjPP744/Tp04fo6Gh+/vlnANauXct5551HamoqMTExjBo1ig8++KDea+bn53Prrbdy+OGHk5CQQGJiIqeeeiorV65sdj0VFRVMmTKFpKQkvvvuuxZ/XwfucaqqqmLmzJn069ePmJgYOnbsyLHHHsvcuXNb/B4iIhIcyjiJiEjQFRYWkpeXh8vlYs+ePfzjH/+guLiYyy67rN7j/v3vf1NeXs51111HdHQ0qamprF69mmOOOYauXbty5513Eh8fz5tvvslZZ53FO++8w9lnnw3A5s2bee+99zj//PPp1asXOTk5PPvss5xwwgn8/PPPdOnSpcG1lZWVceaZZ7J06VI+//xzjjzyyAbXfqCqqqpmv+/f//73PPTQQ1xzzTWMHj2aoqIili5dyvLly5kwYYK3f30iIhICCpxERCToxo8fX+/r6OhoZs2adVDwsHPnTjZu3Eh6enq953bv3p0lS5Z4SuF+85vfcOyxx3LHHXd4AqfDDz+c9evX19tjdPnll3PYYYfxwgsvcO+99x60ruLiYqZMmcLq1av54osvGD58eLNrr2vw4MFNft8fffQRkydP5l//+leTjxMRkfCjwElERILuySefpH///gDk5OTwyiuvcM0119ChQwfOOeccz+POPffcekFTfn4+X3zxBQ888AD79+9n//79nvsmTZrE/fffz65du+jatWu9/UU1NTUUFBSQkJDAgAEDWL58+UFrKiwsZOLEiWzevJn58+c3GgTVXXtdt9xyCzU1NU1+38nJyaxevZoNGzbQr1+/Jh8rIiLhRYGTiIgE3ejRo+s1h7j44os54ogjmD59er3mEL169ar3vI0bN+Jyubj33nsbzBgB7Nmzh65du+J0Ovn73//OU089xZYtW+oFNR07djzoeTfddBPl5eX88MMPTWaODly7JSUlpcESvroeeOABzjzzTPr378+QIUM45ZRTuPzyyxk6dGiTzxMRkdBTcwgREQk5u93OuHHjyM7OZsOGDZ7bY2Nj6z3O6XQCcOuttzJ37twG//Tt2xeABx98kBkzZnD88cfzyiuv8NlnnzF37lwGDx7seZ26zjzzTFwuF3/+858bvN8fjj/+eDZt2sSsWbMYMmQIzz//PCNGjOD5558PyPuJiIj/KOMkIiJhobq6GjD7jOLj4xt8TO/evQGIjIxscq8RwNtvv824ceN44YUX6t1eUFBAWlraQY8/66yzmDhxIldeeSUdOnTg6aefbsm30azU1FSmTZvGtGnTKC4u5vjjj+f3v/8911xzTUDeT0RE/EMZJxERCbmqqirmzJlDVFQUAwcObPRxGRkZnHjiiTz77LNkZ2cfdH9ubq7nusPhwOVy1bv/rbfeYteuXY2+/tSpU3niiSd45plnuOOOO1rwnTRt79699b5OSEigb9++VFRU+P29RETEv5RxEhGRoPvkk09Yu3YtYPYkvfbaa2zYsIE777yTxMRE8vPzG33uk08+ybHHHsvhhx/OtddeS+/evcnJyWHhwoXs3LnTM6dpypQpPPDAA0ybNo2jjz6aVatW8eqrr3qyVo2ZPn06RUVF3HPPPSQlJXH33Xf77fseNGgQJ554IiNHjiQ1NZWlS5fy9ttvM336dL+9h4iIBIYCJxERCbr77rvPcz0mJobDDjuMp59+ml/96lfNPnfQoEEsXbqUmTNn8uKLL7J3714yMjI44ogj6r3u3XffTUlJCa+99hpvvPEGI0aM4KOPPuLOO+9s9j3uvvtuCgsLPcHTDTfc0LJv9AC/+93v+OCDD5gzZw4VFRX06NGDP/7xj9x2221+eX0REQkcm+vAOgYRERERERGpR3ucREREREREmqHASUREREREpBkKnERERERERJoR0sDp66+/5vTTT6dLly7YbDbee++9Zp8zf/58RowYQXR0NH379uXFF18M+DpFREREROTQFtLAqaSkhGHDhvHkk0969fgtW7Zw2mmnMW7cOFasWMFNN93ENddcw2effRbglYqIiIiIyKEsbLrq2Ww23n33Xc4666xGH3PHHXfw0Ucf8dNPP3luu+iiiygoKODTTz8NwipFRERERORQ1KbmOC1cuJDx48fXu23SpEncdNNNjT6noqKi3kR2p9NJfn4+HTt2xGazBWqpIiIiIiIS5lwuF/v376dLly7Y7U0X47WpwGn37t1kZmbWuy0zM5OioiLKysqIjY096DkPPfQQM2fODNYSRURERESkjdmxYwfdunVr8jFtKnBqibvuuosZM2Z4vi4sLKR79+5s2bKFDh06hHBlRlVVFV9++SUnH5ZMzJsX4krKovrar0O9LPED69iOGzeOyMjIUC9H/EjHtn3T8W2/dGzbNx3f9iuQx3b//v306tXLq7igTQVOnTp1Iicnp95tOTk5JCYmNphtAoiOjiY6Ovqg21NTU0lMTAzIOn1RVVVFXFwcKV37EBltg5p90LFjqJclfmAd244dO+of8HZGx7Z90/Ftv3Rs2zcd3/YrkMfWej1vtvC0qTlOY8eOZd68efVumzt3LmPHjg3RivwoLs1cVpVAZUlo1yIiIiIiIvWENHAqLi5mxYoVrFixAjDtxlesWMH27dsBU2Y3depUz+Ovv/56Nm/ezO23387atWt56qmnePPNN7n55ptDsXz/ikqAiBhzvSQvtGsREREREZF6Qho4LV26lCOOOIIjjjgCgBkzZnDEEUdw3333AZCdne0JogB69erFRx99xNy5cxk2bBh/+9vfeP7555k0aVJI1u9XNhvEp5vrCpxERERERMJKSPc4nXjiiTQ1RurFF19s8Dk//PBDAFcVQvFpULgDSnJDvRIRERERaSWXy0V1dTU1NTWhXkqbVlVVRUREBOXl5S36u4yMjMThcLR6HW2qOUS758k4KXASERERacsqKyvJzs6mtLQ01Etp81wuF506dWLHjh0tmsNqs9no1q0bCQkJrVqHAqdwosBJREREpM1zOp1s2bIFh8NBly5diIqKatEHfjGcTifFxcUkJCQ0O6T2QC6Xi9zcXHbu3Em/fv1alXlS4BRO4t2d9bTHSURERKTNqqysxOl0kpWVRVxcXKiX0+Y5nU4qKyuJiYnxOXACSE9PZ+vWrVRVVbUqcGpT7cjbPWWcRERERNqNlnzIF//zV7ZPRzOcKHASEREREQlLCpzCiUr1RERERETCkgKncKKMk4iIiIi0Izabjffeey/Uy/ALBU7hxAqcSvPA6QztWkRERETkkHPllVdis9kO+rNx40a/vH7d14yIiKB79+7MmDGDiooKz2NefPFFbDYbp5xySr3nFhQUYLPZmD9/vl/W4isFTuEkzl2q56yG8oKQLkVEREREDk2nnHIK2dnZ9f706tXLb6//73//m+zsbLZs2cJTTz3Fyy+/zB//+Md6j4mIiODzzz/nyy+/9Nv7tpYCp3ASEQUxSea69jmJiIiItAsul4vSyuqQ/HG5XD6vNzo6mk6dOtX743A4eP/99xkxYgQxMTH07t2bmTNnUl1d7Xnehg0bOP7444mJiWHQoEHMnTu3wddPTk6mU6dOZGVlMWXKFM4880yWL19e7zHx8fFcddVV3HnnnT6vP1A0xyncxKdDeSGU7IH0/qFejYiIiIi0UllVDYPu+ywk7/3zA5OIi2r9R/4FCxYwdepUnnjiCY477jg2bdrEddddB8D999+P0+nknHPOITMzk0WLFlFYWMhNN93U7OuuX7+eL774giuvvPKg+37/+9/Tt29f3n77bSZOnNjq76G1FDiFm/h02LtRDSJEREREJCRmz55NQkKC5+tTTz2Vffv2ceedd3LFFVcA0Lt3b/7whz9w++23c//99/P555+zdu1aPvvsM7p06QLAgw8+yKmnnnrQ61988cU4HA6qq6upqKhgypQp3HXXXQc9rkuXLtx4443ce++9nHTSSSGfi6XAKdx4OuupVE9ERESkPYiNdPDzA5NC9t6+GjduHE8//bTn6/j4eIYOHcq3337Ln/70J8/tNTU1lJeXU1paypo1a8jKyvIETQBjx45t8PUfe+wxxo8fT01NDRs3bmTGjBlcfvnlvP766wc99o477uDZZ5/llVdeYerUqT5/L/6kwCncqCW5iIiISLtis9n8Ui4XLPHx8fTt27febcXFxcycOZNzzjnnoMfHxMT49PqdOnXyvP6AAQPYv38/F198MX/84x8Pet/k5GTuvPNO/vKXv3Deeef5+J34V9s5gocKBU4iIiIiEmZGjBjBunXrDgpsLAMHDmTHjh1kZ2fTuXNnAL7//nuvXtvhMFmxsrKyBu+fPn06f//733niiSdasHL/UeAUbuLdLckVOImIiIhImLjvvvuYMmUK3bt357zzzsNut7Ny5Up++ukn/vjHPzJ+/Hj69+/PFVdcwV//+leKioq45557GnytgoICdu/ejdPpZMOGDTzwwAP079+fgQMHNvj4mJgY7rrrLm677bZAfovNUjvycKM9TiIiIiISZiZNmsTs2bOZM2cORx55JEcddRSPPfYYPXr0AMBut/Puu+9SVlbG6NGjueaaa+rth6pr2rRpdO7cmW7dunHxxRczePBgPvnkEyIiGs/pXHzxxfTu3Tsg35u3lHEKNyrVExEREZEQefHFFxu9b9KkSUya1HiTi/79+7NgwYJ6tx04R8qbuVJXXnnlQe3JHQ4Hq1atCmlnPWWcwo0CJxERERGRsKPAKdxYe5zKC6G6MrRrERERERERQIFT+IlJBru7grJU+5xERERERMKBAqdwY7dDnDrriYiIiIiEEwVO4Uj7nEREREREwooCp3DkmeWkUj0RERERkXCgwCkcKeMkIiIiIhJWFDiFIwVOIiIiIiJhRYFTOFKpnoiIiIhIWFHgFI6UcRIRERGRdsBms/Hee++Fehl+ocApHFmBU/Ge0K5DRERERA4pV155JTab7aA/Gzdu9Ov7/OpXv8LhcPDWW2/59XUDSYFTOPJknFSqJyIiIiLBdcopp5CdnV3vT69evfz2+qWlpbz++uvcfvvtzJo1y2+vG2gKnMJRfJ0BuC5XaNciIiIiIq3jckFlSWj+tOCzZHR0NJ06dar3x+Fw8P777zNixAhiYmLo3bs3M2fOpLq62vO8DRs2cPzxxxMTE8OgQYOYO3dug6//1ltvMWjQIO68806+/vprduzYAUBRURGxsbF88skn9R7/7rvvkpWVRWlpKQDfffcdw4cPJyYmhlGjRvHee+9hs9lYsWKFz9+rLyIC+urSMlbGqaYCKvZDTGJo1yMiIiIiLVdVCg92Cc173/0LRMW3+mUWLFjA1KlTeeKJJzjuuOPYtGkT1113HQD3338/TqeTc845h8zMTBYtWkRhYSE33XRTg6/1wgsvcNlll5GUlMSpp57Kiy++yL333ktiYiJTpkzhtdde49RTT/U8/rXXXmPy5MnExcVRVFTE6aefzuTJk3nttdfYtm1bo+/jb8o4haOoOIhKMNfVIEJEREREgmj27NkkJCR4/px//vnMnDmTO++8kyuuuILevXszYcIE/vCHP/Dss88C8Pnnn7N27Vr+85//MGzYMI4//ngefPDBg157w4YNfP/991x44YUAXHbZZfz73//G5c6MXXrppbz33nue7FJRUREff/wx559/PmCCKJvNxnPPPcegQYM49dRTue2224Lx16KMU9iKT4PKYrPPqWOfUK9GRERERFoqMs5kfkL13j4aN24cTz/9tOfr+Ph4hg4dyrfffsuf/vQnz+01NTWUl5dTWlrKmjVryMrKokuX2sza2LFjD3rtWbNmMWnSJNLSzNaUyZMnc/XVV/PFF19w8sknM3nyZCIjI/nggw+46KKLeOedd0hMTOTEE08EYN26dQwdOpSYmBjPa44ePdrn77ElFDiFq/h02LdVGScRERGRts5m80u5XLDEx8fTt2/fercVFxczc+ZMzjnnnIMeXzeIaUpNTQ0vvfQSu3fvJiIiot7ts2bN4uSTTyYqKorzzjuP1157jYsuuojXXnuNCy64oN7jQyX0K5CGaZaTiIiIiISJESNGsG7duoMCKsvAgQPZsWMH2dnZdO7cGYDvv/++3mM+/vhj9u/fzw8//IDD4fDc/tNPPzFt2jQKCgpITk7m0ksvZcKECaxevZovvviCBx54wPPYAQMG8Morr1BRUUF0dDQAS5Ys8fe32yDtcQpXns56akkuIiIiIqF133338Z///IeZM2eyevVq1qxZw+uvv87//d//ATB+/Hj69+/PFVdcwcqVK1mwYAH33HNPvdd44YUXOO200xg2bBhDhgzx/LngggtITk7m1VdfBeD444+nU6dOXHrppfTq1YsxY8Z4XuOSSy7B6XRy3XXXsWbNGj777DMeeeQRwAzbDSQFTuFKGScRERERCROTJk1i9uzZzJkzhyOPPJKjjjqKxx57jB49egBgt9t59913KSsrY/To0VxzzTX19kPl5OTw0Ucfce655x702na7nbPPPpsXXngBMAHQxRdfzMqVK7n00kvrPTYxMZEPP/yQFStWMHz4cO655x7uu+8+wPuSwZZSqV64UuAkIiIiIkH24osvNnrfpEmTmDRpUqP39+/fnwULFtS7zVVnjlRVVVWjz33qqafqff3www/z8MMPA+B0Ouvdd/TRR7Ny5UrP16+++iqRkZF079690df3BwVO4UqBk4iIiIjIQf7zn//Qu3dvunbtysqVK7njjju44IILiI2NDej7KnAKV9rjJCIiIiJykN27d3Pfffexe/duOnfuzPnnn1+vLDBQFDiFK2WcREREREQOcvvtt3P77bcH/X3VHCJcWYFT6V5w1oR2LSIiIiIihzgFTuEqNhWwAS4ozQ/1akRERETER3UbI0jo+Os4KHAKV44IiEs111WuJyIiItJmREZGAlBaWhrilQhAZWUlQL2huy2hPU7hLD7dlOopcBIRERFpMxwOB8nJyezZsweAuLi4gA9nbc+cTieVlZWUl5djt/uW93E6neTm5hIXF0dEROtCHwVO4Sw+HXLXKnASERERaWM6deoE4AmepOVcLhdlZWXExsa2KAC12+1079691cGrAqdw5mlJrsBJREREpC2x2Wx07tyZjIyMJge/SvOqqqr4+uuvOf744z1lkL6IioryOVPVEAVO4UwtyUVERETaNIfD0eq9NYc6h8NBdXU1MTExLQqc/EXNIcKZAicRERERkbCgwCmceQKnvNCuQ0RERETkEKfAKZwp4yQiIiIiEhYUOIUzBU4iIiIiImFBgVM483TVU6meiIiIiEgoKXAKZ1bGqbIYKjV5WkREREQkVBQ4hbPoDuCINtdLlXUSEREREQkVBU7hzGbTPicRERERkTCgwCncaZ+TiIiIiEjIKXAKd8o4iYiIiIiEnAKncKfASUREREQk5BQ4hTuV6omIiIiIhJwCp3CnjJOIiIiISMhFhHoBh7KteSVsyClkd1MjmhQ4iYiIiIiEnDJOIfTSwq1c+/IPLM5t4jBYgVOxAicRERERkVBR4BRCKXFRAJRWN/Egzx4nBU4iIiIiIqGiwCmEUuIiAShpMnByZ5xK88DpDPyiRERERETkIAqcQijJk3GyNf4gK+PkrIbygsAvSkREREREDqLAKYQ8GaeqJh4UEQ3RSea6WpKLiIiIiISEAqcQsvY4NVmqB9rnJCIiIiISYgqcQijZnXEqrQaXy9X4AxMyzKUCJxERERGRkFDgFELJ7oxTtctGWVVN4w9UxklEREREJKQUOIVQfJSDSIdpDFFQ2sRGJ88QXO1xEhEREREJBQVOIWSz2UiONeV6BWXeBE7KOImIiIiIhIICpxCz9jl5l3FS4CQiIiIiEgoKnEIsKdabwMna46RSPRERERGRUFDgFGJWS/J9KtUTEREREQlbCpxCzCrVK1SpnoiIiIhI2FLgFGJJvjSHKC+A6srAL0pEREREROpR4BRinq56pU0ERDHJYHOY66V7A78oERERERGpR4FTiKXEeZFxsts1BFdEREREJIQUOIWYV+3IQfucRERERERCKOSB05NPPknPnj2JiYlhzJgxLF68uMnHP/744wwYMIDY2FiysrK4+eabKS8vD9Jq/c+rduSgjJOIiIiISAiFNHB64403mDFjBvfffz/Lly9n2LBhTJo0iT179jT4+Ndee40777yT+++/nzVr1vDCCy/wxhtvcPfddwd55f7jVakeKOMkIiIiIhJCIQ2cHn30Ua699lqmTZvGoEGDeOaZZ4iLi2PWrFkNPv67777jmGOO4ZJLLqFnz55MnDiRiy++uNksVThLds9xKiyrwul0Nf5ABU4iIiIiIiETEao3rqysZNmyZdx1112e2+x2O+PHj2fhwoUNPufoo4/mlVdeYfHixYwePZrNmzfz8ccfc/nllzf6PhUVFVRUVHi+LioqAqCqqoqqqmayPEEQ7z4CThfkF5d5SvcOZI9JxQE49++hJgzWLc2zfr7C4edM/EvHtn3T8W2/dGzbNx3f9iuQx9aX1wxZ4JSXl0dNTQ2ZmZn1bs/MzGTt2rUNPueSSy4hLy+PY489FpfLRXV1Nddff32TpXoPPfQQM2fOPOj2OXPmEBcX17pvwk+i7A4qnTbe+3gu6bENP6b73myOAPZs/ZlFH38c1PVJ68ydOzfUS5AA0bFt33R82y8d2/ZNx7f9CsSxLS0t9fqxIQucWmL+/Pk8+OCDPPXUU4wZM4aNGzdy44038oc//IF77723wefcddddzJgxw/N1UVERWVlZTJw4kcTExGAtvVFVVVXEL/uCykoYNvpohmclN/g423o7bH+BjHgbkydPDu4ipUWqqqqYO3cuEyZMIDKy4UyitE06tu2bjm/7pWPbvun4tl+BPLZWNZo3QhY4paWl4XA4yMnJqXd7Tk4OnTp1avA59957L5dffjnXXHMNAIcffjglJSVcd9113HPPPdjtB2/Zio6OJjo6+qDbIyMjw+aXKj4S9lVCcZWr8TUldQbAXroXe5isW7wTTj9r4l86tu2bjm/7pWPbvun4tl+BOLa+vF7ImkNERUUxcuRI5s2b57nN6XQyb948xo4d2+BzSktLDwqOHA4HAC5XE40VwlxchFl7QWll4w+q2xyiDX+vIiIiIiJtUUhL9WbMmMEVV1zBqFGjGD16NI8//jglJSVMmzYNgKlTp9K1a1ceeughAE4//XQeffRRjjjiCE+p3r333svpp5/uCaDaIqtBxL6SJjanWXOcqsuhshiiOwR+YSIiIiIiAoQ4cLrwwgvJzc3lvvvuY/fu3QwfPpxPP/3U0zBi+/bt9TJM//d//4fNZuP//u//2LVrF+np6Zx++un86U9/CtW34Bdx7qPQ5CynqHiIjIeqEpN1UuAkIiIiIhI0IW8OMX36dKZPn97gffPnz6/3dUREBPfffz/3339/EFYWPFbGqclSPTBZp4ISKMmD1N6BX5iIiIiIiAAhHoArhrXHaV9pM33kNQRXRERERCQkFDiFgXh3M4/mM04KnEREREREQkGBUxioLdVrLuPkbhBRvCewCxIRERERkXoUOIWB2lK9ZjJOHdzzrfbvDvCKRERERESkLgVOYcDrjFMHMwSX/dmBXZCIiIiIiNSjwCkMWIFTcUU1ldXOxh+owElEREREJCQUOIWB2Aiw2cz1wqZmOSW6A6ciBU4iIiIiIsGkwCkM2G2QGGPSTk121uvQxVyW7IGa6iCsTEREREREQIFT2EiOjQKameUUnwY2B7icJngSEREREZGgUOAUJpLjzDCnJjNOdkdtZz2V64mIiIiIBI0CpzCRHGsFTt521vslwCsSERERERGLAqcwYWWcNMtJRERERCT8KHAKE7WBUzMZp0R3g4giZZxERERERIJFgVOYsEr1CsuUcRIRERERCTcKnMKEJ+NU0tweJ3fGSXucRERERESCRoFTmLAyTs3ucdIQXBERERGRoFPgFCaS48wcp8Iyb7vqqVRPRERERCRYFDiFiRSvu+q5A6eKQqgsCfCqREREREQEFDiFjaTY2q56Lper8QfGJEJUgrmucj0RERERkaBQ4BQmrOYQldVOyqpqmn6wp7OeAicRERERkWBQ4BQm4qMcRDpsABQ0N8vJs89JgZOIiIiISDAocAoTNpuNpFjTIKL5znpWS3IFTiIiIiIiwaDAKYxYDSKazzi5S/W0x0lEREREJCgUOIWRlDgvM04agisiIiIiElQKnMJIsq8ZJ81yEhEREREJCgVOYaQ2cPJyj5NK9UREREREgkKBUxipLdXzoaue0xngVYmIiIiIiAKnMJLsDpyaLdVLyDSXziooyw/wqkRERERERIFTGPG6VC8iCuLTzfUiNYgQEREREQk0BU5hxGpH3mxXPahTrqcGESIiIiIigabAKYx4XaoHdQInZZxERERERAJNgVMYsZpDFJR5ETglugMnddYTEREREQk4BU5hpO4eJ6fT1fSD63bWExERERGRgFLgFEaswMnpgv3l1U0/WIGTiIiIiEjQKHAKI9ERDuKiHIAXDSI0BFdEREREJGgUOIUZr/c5dehkLpVxEhEREREJOAVOYSYp1suW5B3cGafSPKiuCPCqREREREQObQqcwkxKvJdDcONSwWGyUxTnBHhVIiIiIiKHNgVOYcbrWU42W225nvY5iYiIiIgElAKnMJPsKdXzZgiuu1xPQ3BFRERERAJKgVOY8TSHaK5UD+o0iNgdwBWJiIiIiIgCpzBjzXLyKuPkaUmujJOIiIiISCApcAozvmWcNARXRERERCQYFDiFGSvj1GxzCKgTOKlUT0REREQkkBQ4hRmrq16zc5wAEt2Bk0r1REREREQCSoFTmElxZ5wKfc04uVwBXJWIiIiIyKFNgVOYsTJO+yuqqapxNv1gK3CqKoGKogCvTERERETk0KXAKcwkxUZis5nrze5zioqDmCRzXUNwRUREREQCRoFTmHHYbSTGWA0ivOmsZw3BVeAkIiIiIhIoCpzCkLXPqaDMm31O1hBcBU4iIiIiIoGiwCkMJVmd9Uq86aynIbgiIiIiIoGmwCkMpfg0y8nKOGmWk4iIiIhIoChwCkMpvsxy8rQkV6meiIiIiEigKHAKQ8m+7HFKVHMIEREREZFAU+AUhpJjTcbJu6567lI9tSMXEREREQkYBU5hKCXeZJz2lXizx8mdcSrOAWdNAFclIiIiInLoUuAUhpLde5wKyrzIOCVkgM0OrhooyQ3wykREREREDk0KnMJQcqwPXfXsDkjINNfVklxEREREJCAUOIUhn7rqgTrriYiIiIgEmAKnMGR11dtXWoXL5Wr+CQqcREREREQCSoFTGEqJNxmnymon5VXO5p+Q6A6c1FlPRERERCQgFDiFofgoBxF2G+DrENzdAVyViIiIiMihS4FTGLLZbJ7Oer4FTmoOISIiIiISCAqcwlRKnA+d9VSqJyIiIiISUAqcwlSyL4GTNQRXzSFERERERAJCgVOY8q1Ur5O5LC+AqrLALUpERERE5BClwClM1ZbqeRE4xSRBZJy5riG4IiIiIiJ+p8ApTFlDcL0q1bPZarNO6qwnIiIiIuJ3CpzCVFKdIbhe0T4nEREREZGAUeAUpmozTl6U6kFtZz0FTiIiIiIifqfAKUyleDJOXgZOVqmeWpKLiIiIiPidAqcwZXXVKyjztVRPzSFERERERPxNgVOY8mmOE9Qp1VNzCBERERERf1PgFKbq7nFyOl3NP6GDO3BSO3IREREREb9T4BSmkmJNxsnpgv0V1c0/oUOdjJPLi0BLRERERES8psApTMVEOoiNdABedtazmkPUVEDZvgCuTERERETk0KPAKYyl+DLLKSIa4jqa6yrXExERERHxKwVOYczqrOd9S3Krs54aRIiIiIiI+JMCpzCWEm8yToXedtazyvXUklxERERExK8UOIWx5FgfM05WS3INwRURERER8SsFTmEs2Zc9TlCnVE+Bk4iIiIiIPylwCmN1Zzl5xVOqp8BJRERERMSfQh44Pfnkk/Ts2ZOYmBjGjBnD4sWLm3x8QUEBN9xwA507dyY6Opr+/fvz8ccfB2m1wWVlnAq8zTglujNO6qonIiIiIuJXEaF88zfeeIMZM2bwzDPPMGbMGB5//HEmTZrEunXryMjIOOjxlZWVTJgwgYyMDN5++226du3Ktm3bSE5ODv7ig8D3rnp1huCKiIiIiIjfhDRwevTRR7n22muZNm0aAM888wwfffQRs2bN4s477zzo8bNmzSI/P5/vvvuOyEiTjenZs2cwlxxUKb5mnKzAqSQXaqrAERmglYmIiIiIHFpCFjhVVlaybNky7rrrLs9tdrud8ePHs3Dhwgaf88EHHzB27FhuuOEG3n//fdLT07nkkku44447cDgcDT6noqKCiooKz9dFRUUAVFVVUVXlZUASQNYaGlpLhyhTSbmvtNK7tUYlEmGPxOasoqpgFyR29etaxTdNHVtp23Rs2zcd3/ZLx7Z90/FtvwJ5bH15zZAFTnl5edTU1JCZmVnv9szMTNauXdvgczZv3swXX3zBpZdeyscff8zGjRv5zW9+Q1VVFffff3+Dz3nooYeYOXPmQbfPmTOHuLi41n8jfjJ37tyDbsspA4ggr6jU631cExyJxDn3svCzd9gX39e/i5QWaejYSvugY9u+6fi2Xzq27ZuOb/sViGNbWlrq9WNDWqrnK6fTSUZGBv/6179wOByMHDmSXbt28de//rXRwOmuu+5ixowZnq+LiorIyspi4sSJJCYmBmvpjaqqqmLu3LlMmDDBU35oyS+p5MEV8ymvsTFh0ilEOprv5eHY8w/YtZejD++F67DJgVq2eKGpYyttm45t+6bj237p2LZvOr7tVyCPrVWN5o2QBU5paWk4HA5ycnLq3Z6Tk0OnTp0afE7nzp2JjIysV5Y3cOBAdu/eTWVlJVFRUQc9Jzo6mujo6INuj4yMDKtfqobWk5YYgc0GLheUVEF6jBfrTeoCuyCiNBfC6Ps7lIXbz5r4j45t+6bj237p2LZvOr7tVyCOrS+v53M78pdeeomPPvrI8/Xtt99OcnIyRx99NNu2bfP6daKiohg5ciTz5s3z3OZ0Opk3bx5jx45t8DnHHHMMGzduxOl0em5bv349nTt3bjBoauscdhuJ7mCpsMzHznpqSS4iIiIi4jc+B04PPvggsbGxACxcuJAnn3ySv/zlL6SlpXHzzTf79FozZszgueee46WXXmLNmjX8+te/pqSkxNNlb+rUqfWaR/z6178mPz+fG2+8kfXr1/PRRx/x4IMPcsMNN/j6bbQZ1iynfb521tMQXBERERERv/G5VG/Hjh307WuaDrz33nuce+65XHfddRxzzDGceOKJPr3WhRdeSG5uLvfddx+7d+9m+PDhfPrpp56GEdu3b8dur43tsrKy+Oyzz7j55psZOnQoXbt25cYbb+SOO+7w9dtoM5Ljoti2t5R9JV5mnKwhuAqcRERERET8xufAKSEhgb1799K9e3fmzJnjabwQExNDWVmZzwuYPn0606dPb/C++fPnH3Tb2LFj+f77731+n7bK91lO7v1hRQqcRERERET8xefAacKECVxzzTUcccQRrF+/nsmTTee21atXt+thtKGSHOsOnLze42RlnHYHaEUiIiIiIocen/c4Pfnkk4wdO5bc3FzeeecdOnbsCMCyZcu4+OKL/b7AQ11ynGl64f0eJ3fGqXI/VOwP0KpERERERA4tPmeckpOT+ec//3nQ7Q0NmZXWS3EHTgWlXmacohMgOhEqiky5XnqHAK5OREREROTQ4HPG6dNPP+Wbb77xfP3kk08yfPhwLrnkEvbt2+fXxQmkxPu4xwnUWU9ERERExM98Dpxuu+02z4TdVatWccsttzB58mS2bNniaRQh/pMUa7Uj9zLjBLXlegqcRERERET8wudSvS1btjBo0CAA3nnnHaZMmcKDDz7I8uXLPY0ixH9qS/V8yDhZLclbMgS3phocPv9YiIiIiIi0az5nnKKioigtLQXg888/Z+LEiQCkpqZ6MlHiPyme5hC+ZJysUj0fO+t9fDs82AWyV/r2PBERERGRds7n1MKxxx7LjBkzOOaYY1i8eDFvvPEGAOvXr6dbt25+X+ChLtnXOU5QJ3DyIeO0ZjYsftZc//l96DzM++eKiIiIiLRzPmec/vnPfxIREcHbb7/N008/TdeuXQH45JNPOOWUU/y+wEOdFThVVDspq6zx7kmJ7sDJ2yG4xbnw4Y21X+9Y7MMKRURERETaP58zTt27d2f27NkH3f7YY4/5ZUFSX0J0BBF2G9VOF/tKK4mNim3+Sb4MwXW5YPZNUJpnMlX7s2HnUqipAkdkq9YuIiIiItJetKgLQE1NDe+99x5r1qwBYPDgwZxxxhk4HA6/Lk7AZrORHBdFXnEF+0or6ZLsTeDk7qpXvBucTrA3kVj88Q1YOxvsEXDx6/CfM6G8AHavgq4j/PI9iIiIiIi0dT6X6m3cuJGBAwcydepU/ve///G///2Pyy67jMGDB7Np06ZArPGQZ5XrFXq7zykhE7CBs9pkkhpTuBM+vs1cP/FO6DIcskabr1WuJyIiIiLi4XPg9Lvf/Y4+ffqwY8cOli9fzvLly9m+fTu9evXid7/7XSDWeMhLibNmOXkZODkiICHDXG+sJbnTCe/fABVF0HUUHHOzuT1rjLnc8X0rViwiIiIi0r74XKr31Vdf8f3335Oamuq5rWPHjvz5z3/mmGOO8evixEhuaUvy4hz3ENzhB9+/9AXYPB8iYuHsZ2pnN3kCJ2WcREREREQsPmecoqOj2b9//0G3FxcXExUV5ZdFSX1WxqmwrAVDcPc30Flv7yaYc6+5PmEmpPWrva/rCLA5oGgXFOxo4YpFRERERNoXnwOnKVOmcN1117Fo0SJcLhcul4vvv/+e66+/njPOOCMQazzkeTJOJb5knNwNIg5sSV5TDe/+CqrLoNfxcOS19e+PiofOQ831HYtauGIRERERkfbF58DpiSeeoE+fPowdO5aYmBhiYmI45phj6Nu3L48//ngAlijJvu5xgjotyQ/Y4/Td32HnEohOhDOfarjjnsr1RERERETq8XmPU3JyMu+//z4bN270tCMfOHAgffv29fvixEhxZ5wKfNnjZA3BrTvLafcq+PIhc/2UP0NyVsPPzRoNi55RgwgREREREbcWzXEC6Nu3b71g6ccff2TUqFFUVvrw4V68khxrMk4FvuxxOrBUr7oC3r0enFUw4DQYfknjz806ylzu/gkqiiE6oQWrFhERERFpP3wu1WuMy+WipqbGXy8ndbSsq94BzSHmPwQ5P0FcRzj972CzNf7cpK6Q2A1cNfDL8hauWkRERESk/fBb4CSBkxLvzjj5tMfJnXEqy4ctX8O3fzdfT3kcEtKbf741CHe7GkSIiIiIiChwagPq7nFyOl3ePSk2BSJizPW3poHLCUMvgkFedj7s7i7XU2c9ERERERHv9zgVFRU1eX9Ds53EP5Lce5ycLthfUe35ukk2mxmCu28LlOZBYlc49WHv39TKOO1cDE5nw933REREREQOEV4HTsnJydia2BfjcrmavF9aLibSQWykg7KqGgpKK70LnKA2cAI4858Qm+z9m2YOgcg4KC+EvHWQMdDndYuIiIiItBdeB05ffvllINchzUiJi6SssIZ9pVX06Ojlk9L7w/bv4MhroM9Jvr2hIxK6joStC0y5ngInERERETmEeR04nXDCCYFchzQjKS6KXwrLfZvldNJ9JmAaMLllb5o1xh04LYaRV7bsNURERERE2oEWz3GS4EqJa0FnvfiOMOjMlr9p1hhzuV2DcEVERETk0KYd/21ESktmObVW1pHmMn8TlOQF731FRERERMKMAqc2ItmdcdrnS8aptWJTIP0wc33H4uC9r4iIiIhImFHg1EZYgVNhMDNOUFuut0PleiIiIiJy6FLg1EbUluoFMeMEdQInZZxERERE5NDlc3OIs88+u8F5TTabjZiYGPr27csll1zCgAED/LJAMZJDsccJagOnXcuhugIiooP7/iIiIiIiYcDnjFNSUhJffPEFy5cvx2azYbPZ+OGHH/jiiy+orq7mjTfeYNiwYXz77beBWO8hy+qqV1gW5IxTxz4Q1xFqKiD7x+C+t4iIiIhImPA5cOrUqROXXHIJmzdv5p133uGdd95h06ZNXHbZZfTp04c1a9ZwxRVXcMcddwRivYes2uYQQc442Wx1yvUWBfe9RURERETChM+B0wsvvMBNN92E3V77VLvdzm9/+1v+9a9/YbPZmD59Oj/99JNfF3qos0r1CkqCnHECyBptLtUgQkREREQOUT4HTtXV1axdu/ag29euXUtNTQ0AMTExDe6DkpazmkPsr6imqsYZ3DfPOspc7lgMLldw39sX3/0TZs8I7zWKiIiISJvkc3OIyy+/nKuvvpq7776bI480A1KXLFnCgw8+yNSpUwH46quvGDx4sH9XeohLjKk9VIVlVaQlBLFJQ5fhYI+E4hwo2AYpPYP33t6qqYLPfw/OKhh5JXQeGuoViYSvylKoKoP4jqFeiYiISJvhc+D02GOPkZmZyV/+8hdycnIAyMzM5Oabb/bsa5o4cSKnnHKKf1d6iItw2EmMiaCovJqC0srgBk6RsdB5GOxaCtsXhWfgtG+rCZoActcqcBJpyqxJkL8Fbl5lBl2LiIhIs3wu1XM4HNxzzz1kZ2dTUFBAQUEB2dnZ3H333TgcDgC6d+9Ot27d/L7YQ11KfIhmOQF0t8r1wrRBRN6G2ut71oRuHSLhrqoMdv8IlfvhlxWhXo2IiEib0aoBuImJiSQmJvprLdIMzyynkiB31oM6DSLCdBBu3vra67nrQrcOkXBXuLP2uk4yiIiIeM3nwCknJ4fLL7+cLl26EBERgcPhqPdHAic51rQkLwj2LCeobUm+ZzWUFwX//ZtTN+OUqw+DIo0q3FF7fc/q0K1DRESkjfF5j9OVV17J9u3buffee+ncubO65wWRNQS3INiznAA6dILkHqY5xK6l0Oek4K+hKXvrBE75W0w5UmRs6NYjEq4K6gZOOskgIiLiLZ8Dp2+++YYFCxYwfPjwACxHmpKZGAPALwXloVlA1hgTOO1YHF6Bk8t1QHmey5TudR4WsiWJhK16Gae14HSCvVVV2yIiIocEn/+3zMrKwqU5OSHRKy0egC15JaFZgLXPaXuYDcIt3QvlBYANuhxhbttz8KwxEaH+HqeqEijcHrq1iIiItCE+B06PP/44d955J1u3bg3AcqQpIQ+crM56O5eCsyY0a2iItb8pOas2cMpV4CTSoLqleqByPRERES/5XKp34YUXUlpaSp8+fYiLiyMyMrLe/fn5+X5bnNTXK90ETjv3lVJRXUN0RJCbcWQMgqgE08Z4zxroNCS4798Yq6Nex36QPtBcV+Ak0jArw5TcHQq2w56fYcCpoV2TiIhIG+Bz4PT4448HYBnijfSEaBKiIyiuqGZHfil9MzoEdwF2B3QbBZvnw47vwy9wSusP6QPMdZ1FFzmYswaKfjHX+02CJc/pd0VERMRLPgdOV1xxRSDWIV6w2Wz0Sotn1a5CNueWBD9wAsg6yh04LYYjrwn++zdk70ZzmdYPMtwZp31bobIUouJCtiyRsLN/NzirwR4BfcYpcBIREfGBV4FTUVGRZ9BtUVHTM3w0EDewrMBJDSLq8GSc+kF8OsSmQlm+aVGuznoitayOeoldINOdMc5bDzVV4Ihs/HkiIiLiXXOIlJQU9uzZA0BycjIpKSkH/bFul8AKeYOIbqMAm2lLvn93aNZQV3UF7Ntmrqf1B5utNuukznoi9Vkd9ZK6Q1KW2bNYUwn5m0O7LhERkTbAq4zTF198QWpqKgBffvllQBckTevtbhCxOVSBU0wSZA6GnJ9Mud6gM0KzDkv+FnDVQHQiJGSa29IHwLZvIVclSCL1FLgbQyR1M7Ob0g8zA633/Fy7P1BEREQa5FXgdMIJJzR4XYIv5BknMOV6OT/BjkWhD5w8HfX6mmwT1HbWU8ZJpD6rVC85y1xmDHQHTmtg8NmhW5eIiEgb4HNzCICCggIWL17Mnj17cDqd9e6bOnWqXxYmDevpDpxy91ewv7yKDjEh2JeQNQaWzjKBU6jtdc9wSutfe1vGYeZSGSeR+jylelbgNMhc7vk5NOsRERFpQ3wOnD788EMuvfRSiouLSUxMxGad5cd0fVPgFFiJMZGkJUSTV1zBlrwShnZLDv4issaYy19WQFU5RMYEfw0Wa/htWt/a26yM075t6qwnUpc1/Dapm7n07AfUSQYREZHmeNUcoq5bbrmFq666iuLiYgoKCti3b5/nj4bfBkfvUJfrpfSE+AxwVsEvP4RmDZa6M5ws8Wmmsx6u2vtFDnUuV51Sve7m0so45W+GqrLQrEtERKSN8Dlw2rVrF7/73e+Ii9NZ/FCx9jltzg1R4GSz1bYlD2W5nssFedYMpzqBU93Oerna5yQCQHkBVBab61bGKSHDnGRwOXWSQUREpBk+B06TJk1i6dKlgViLeKlXehg0iOh+lLncsTh0ayjeAxWFYLNDau/696W79zmpBEnEsMr04tIgMtZct9nq7HPS74qIiEhTfN7jdNppp3Hbbbfx888/c/jhhxMZWb85wRlnhLjL2iEgPDrrufc57VhkMj919roFjXWGPLkHRETXv8+TcVoX3DWJhKsDO+pZMgbCtm/UIEJERKQZPgdO1157LQAPPPDAQffZbDZqampavyppUt09Ti6Xq16DjqDpPAwc0VCaZ/ZHdOwT/DU01FHPkq7OeiL1eBpDNBA4gTJOIiIizfC5VM/pdDb6R0FTcHTvGIfNBsUV1eQWV4RmERHR0HWEub71m9CswdNRr9/B91mBk9VZT+RQV9hY4KRSPREREW/4HDhJ6EVHOOiWYvYobAlVgwiAXseby81fhub9mwqcEtIhriOms57K9UQaL9U7rPb+8qLgrklERKQN8apU74knnuC6664jJiaGJ554osnH/u53v/PLwqRpvdIS2JFfxpa8Esb07hiaRfQeB189DJu/AqcT7EGOwxtqRV5XurV3Yy10OSJ46xIJR42V6sWmQIcusP8X04XS6pgpIiIi9XgVOD322GNceumlxMTE8NhjjzX6OJvNpsApSHqnxfP1+tzQNojoNgqiOkBZPuz+EboMD957V5VBwXZzvWMDGScwZ9K3faOW5CIAhTvNpdWKvK6MgSZw2vOzAicREZFGeBU4bdmypcHrEjqeWU6hDJwckdDzWFj/iSnXC2bglL8ZcEFMshl42xBPgwgFTnKIqyqHkj3mujX8tq6MgbBpnvY5iYiINEF7nNqosGhJDtBnnLncFOR9Tp4yvX6Nt0LXLCcRw8o2Rcab0rwDeRpEqCW5iIhIY3xuRw6wc+dOPvjgA7Zv305lZWW9+x599FG/LEyaZgVO2/aWUON04bCHoCU5mH1OANu/N+Vz1mDNQMtrohW5xWqzXLANKksgKj7w6xIJR3UbQzR0okEtyUVERJrlc+A0b948zjjjDHr37s3atWsZMmQIW7duxeVyMWLEiECsURrQJTmWqAg7ldVOdu0ro3vHuNAsJK1f7cby7Quhz0nBed+mOupZ4tMgLs3MmspbrwYRvijcCa9dCKOvhZFXhno10lqeVuQN7G8CSB8A2KAkF4pzTVdKERERqcfnUr277rqLW2+9lVWrVhETE8M777zDjh07OOGEEzj//PMDsUZpgMNuo6c7WNqcVxy6hdhsoSnXs0r1GmsMYfGU62mfk09+fh9yfoLv/hHqlYg/NNZRzxIVDyk9zXUNjRYREWmQz4HTmjVrmDp1KgARERGUlZWRkJDAAw88wMMPP+z3BUrjwmafk1WuF6x5Ti4X7N1orjdVqge1M2r0YdA3ue7ZV3s3Qsne0K6lJQp2wOe/h7J9oV5JeLD2OB04w6kuDcIVERFpks+BU3x8vGdfU+fOndm0aZPnvry8PP+tTJrVKy0BCIfA6URzuXuVKfMJtP3ZUFkM9ghI7dX0Y5VxapncOkODdy4O3Tpa6qs/wzePwTePh3ol4aGwmYwT1NnnpAYRIiIiDfE5cDrqqKP45ptvAJg8eTK33HILf/rTn7jqqqs46qij/L5AaVzvcMk4JaRD5uHm+pavAv9+VpleSk/TEr0p1odBZZy853LVb+G+Y1Ho1tJSu1eZy7a49kCwZp55FTjpd0VERKQhPjeHePTRRykuNntqZs6cSXFxMW+88Qb9+vVTR70g65XunuWUG+LACaD3CZCzypTrHX5eYN/Lm456FivjVLBdnfW8VbwHygtqv97RxjJOzprajNkvP0BNVfMBdnvmrIGiX8x1b0v1XK7G2/yLiIgconwKnGpqati5cydDhw4FTNneM888E5CFSfOsPU6/FJZRXlVDTKQjdIvpMw4W/hM2zQ/8hy4rcOrYt/nH1u2sl7sOuqrzY7Py3EFHRCxUl8GuZW0r+MjfDNXl5np1uck+HcrHvTgHnFVgc0BCp8Yf17GvKX+tKIKiXY134BMRETlE+VSq53A4mDhxIvv2acN1OOgYH0WHmAhcLti2tzS0i+l+NDiioGhnbeOGQPEMv/Ui4wR1yvW0z8krVram9wkQk+wOPn4M6ZJ8krO6/tc7l4RmHeHC6qiX2BUcTZwri4iq7VKpcj0REZGD+LzHaciQIWzevDkQaxEf2Wy2OvucQtiSHCAqDrq797gFui25tx31LJ4GEfow6BUrwEw/DLJGm+ttqVzP09zAnfU81AOnusNvm6MGESIiIo3yOXD64x//yK233srs2bPJzs6mqKio3h8JLqtcb3OoG0RAcNqSV5bUfhBsavhtXZ6W5Mo4ecXKONULnNpQkwUr49RvgrlsS0FfIDQ3/LYutSQXERFplNeB0wMPPEBJSQmTJ09m5cqVnHHGGXTr1o2UlBRSUlJITk4mJSUlkGuVBnhakodDgwhrEO6WBWZPTCBY2aa4jhCX6t1z0hU4+cQTOA2ArDHmelsKPqxsyRGXAzYo2GYaXhyqmht+W5cyTiIiIo3yujnEzJkzuf766/nyyyANORWvWJ31Qt6SHKDTUIhNMUNHdy2H7mP8/x6+dNSzpLs/DBZsh4piiE7w/7rai9J8KHEHGdbfsc1hmgUU7gz/hgGVJZC/xVzvfpQJBPb8bAK/gVNCu7ZQ8Wb4rcWzH3Cd6cZnD2HDGRERkTDjdeDkcrkAOOGEEwK2GPFd2MxyAvMhq9cJ8PN7plwvkIGTNx31LPEdIT4dSnJNx7iuI/2/rvbCyjYlZdUGmJ2GQPZKU64X7oFT7lrAZTopJmRAt1EmcNq55BAOnHwo1UvpVdtNcd9W6NgnoEsTERFpS3za42TTXI+w09MdOO0tqaSwNEDlcb6wyvUC1SDC1456Fk+DCJXrNSmvTpmepS2V6+W4S8wy3Xt1urn3aB2qDSJcrjqlet2bf7zdXrsnUOV6IiIi9fgUOPXv35/U1NQm/0hwJURHkNEhGoAte8Mg62Q1iNi5BMoD0CxkbwtK9UD7nLxVtzGExRM4tYEGEdaH/YzB5tJqbrFreeD23YWz8gKo3G+ue5stVIMIERGRBvk0AHfmzJkkJSX5fRFPPvkkf/3rX9m9ezfDhg3jH//4B6NHj272ea+//joXX3wxZ555Ju+9957f19VW9EqLZ8/+CrbkFTM8Kzm0i0npAam9zRDSrd/AYZP999pOJ+RZrci97KhnUWc971h/P3UDUyv4yP7R7CGKig/+urxlddSzMk4d+0FMEpQXmvu6DA/Z0kLC2t8Ul2ZGBnhDDSJEREQa5FPgdNFFF5GRkeHXBbzxxhvMmDGDZ555hjFjxvD4448zadIk1q1b1+R7bd26lVtvvZXjjjvOr+tpi3qnx7NoS354dNYDk3XK3wyb5/s3cCraZfZe2CMhuYdvz7UaRKhUr2kNZZySsqBDZ9ifDb/8AD2PDc3avHFgxsluh66jYNM8kwU91AKnAh/2N1k8gZMyTiIiInV5XaoXqP1Njz76KNdeey3Tpk1j0KBBPPPMM8TFxTFr1qxGn1NTU8Oll17KzJkz6d27d0DW1ZaE1SwngN4nmkt/z3Oy9jel9gaHTzF/7YfBQndnPTlYeZEJTgHS62ScbLa2Mc+pONc0AMFWm2GEtjnE1198GX5rsUr19m6E6gr/r0lERKSN8rmrnj9VVlaybNky7rrrLs9tdrud8ePHs3Dhwkaf98ADD5CRkcHVV1/NggULmnyPiooKKipq//O3hvRWVVVRVRX6PQ/WGlqzlu7JMQBszi0Oi++JrKOJsNmx5a2nau82SOzil5e171mLA3B27EuNr99nZAci4tOxleRSnb0aV9cRfllTU/xxbIPJtnsNEYArPoPqiASos257l1E4fn4f57bvqTkqPL8f2y8/mvWn9KTaFuVZv63TEeb2nUuo9tOxaCvH1r5vGw6gpkNXnN6uNSaNiJgkbOWFVOWsrQ2kDiFt5fiK73Rs2zcd3/YrkMfWl9f0OnByOp0tWkxT8vLyqKmpITMzs97tmZmZrF3bcEnVN998wwsvvMCKFSu8eo+HHnqImTNnHnT7nDlziIvzsuY/CObOndvi5+aUAUSwMaeIjz76mHBofnhcbC9SSzfx0/tPsL3j8X55zaE75tEL2FhgZ83HH/v8/KNtaaSTy49fvMWOjrv9siZvtObYBlPW3gWMAPJsaXx3wN9vSkk1xwPVW77lk48+Iix+yA7Qe8+nHA7sdqayuM76I6pLOA2w7dvC5++/TmVkot/eM9yP7agtS+gK/LyriM0+/M4c68ikI4WsnPNfdqWODdwCw1y4H19pOR3b9k3Ht/0KxLEtLS31+rE+1juF1v79+7n88st57rnnSEtL8+o5d911FzNmzPB8XVRURFZWFhMnTiQx0X8foFqqqqqKuXPnMmHCBCIjI1v0GpXVTv688nMqnTZGHXcSmYkxfl6l7+xxK+HbvzGsQz5DJvtnn5Pj1ecgD3qPnkSvob6/pv2zr2HpGoZ1ieLwk/2496oR/ji2wWSftxi2Q+phRzN50gF/PzWVuP76Z6JqSph8VH/TdCHMOGZ/Brsg4/ATmXxC/fW7sh/HlreOCQOTcPU/tdXv1VaOrePfj0MBDDxqEof5sN/QbvsClq/niK4xDBsX+N+VcNNWjq/4Tse2fdPxbb8CeWytajRvhDRwSktLw+FwkJOTU+/2nJwcOnXqdNDjN23axNatWzn99NM9t1mZsIiICNatW0efPvUHNkZHRxMdHX3Qa0VGRobVL1Vr1hMZCVmpcWzbW8qOgkq6dezg59W1QL+T4du/Yd/yNXaHw2zSb629pqNeROZA8037yt1pzZG3HkcQj324/aw1Kt/8/ToyBx789xMZCV1HwPaFRGYvh05hWL6Va5oZODoffvD6s46EvHVEZP8Ag8/w21uG/bF171mL6NjTt9+ZTkMAcOxdF9TflXAT9sdXWkzHtn3T8W2/AnFsfXk9P3yabbmoqChGjhzJvHnzPLc5nU7mzZvH2LEHl4ccdthhrFq1ihUrVnj+nHHGGYwbN44VK1aQleXDBuh2xmoQsSVcGkR0OxIi46E0D/asbv3rVew3Xd0AOvZt2WtYDSLUkrxhnlbkAxq+P5wbRDidteu3OurVdSgOwq0qh2L3SakkH/9tVEtyERGRg4S8VG/GjBlcccUVjBo1itGjR/P4449TUlLCtGnTAJg6dSpdu3bloYceIiYmhiFDhtR7fnJyMsBBtx9qeqXFM39dLlvywqRjXEQU9DwGNsyBTV9Cp8Nb93p57sG38RkQm9yy17BabBfuMIFYdBhk5sJFVRns22au121FXlfWUcDfw7M7XcFWqCoFR7TpunggzyDcZVBT7XtXxrbI6pAYGQdxPg4nt9r379sa/rO7REREgiSkGSeACy+8kEceeYT77ruP4cOHs2LFCj799FNPw4jt27eTnZ0d4lWGv97hlnECM88J/NOWfK81+LZ/049rSlyqCbwActe3fk3tSd4GwAWxqRDfyP5BK/jIXQtl+4K2NK/kuDMj6QMaDorSBkB0ogmu/JEBbQusVuRJWb4384jvCAnupj3K0IqIiABhkHECmD59OtOnT2/wvvnz5zf53BdffNH/C2qDeqUlAGE0ywmgjztw2vadKRuKbEXTCmuGU1ormxJkHAZb9pj9MN1Gtu612pO6g28b+5AdnwapfSB/E+xcCv0mBG99zbFKyjIbKNMD9yDckSaI37kEOg8L3tpCpSXDb+vKGGhK/fasMX93IiIih7iQZ5zEP3qlm4zT9r2lVNf4v3V8i6QfBh06Q3V56/fF+CtwskqQ9qxp3eu0N1ZWIb2ZjF7WGHMZbvucctxZpKZmDnn2aB0i+5xaMvy2LuvvUr8rIiIigAKndqNzYgzREXaqnS527isL9XIMmw16n2iut7ZcL88PpXpgSrlA5UcH8gROjexvsoRrgwgr49RU4NTtSHO5Mwz3aAVC4U5z6WtjCIsaRIiIiNSjwKmdsNtt4ddZD2oDp02tCJycNbV7nFraUc/i6ay3rnWv095YGb30RjrqWayM0053k4VwUFUOezeZ65lNBU6jzGX+ZijZG/h1hVrBdnPZ4sBJGScREZG6FDi1I1bgFFb7nKzAKXsllOa37DUKtkNNhemYlty9des5sLNeoJQV4Hj3WgbvfA1cYVI62ZjqytrAo7FW5Jb0w9xNFkrCp8lC3jpw1UBMsikNbUxsSm3G8lBoS97aUj0riN6f3fLfXRERkXZEgVM7UptxCpOW5AAdOrnPXLtg8/yWvUbdbJPd0br1xKXW6RYWoKxTZQm8dgH2n9+lb+6n2Bf8NTDv4y/5m0zgEdUBErs0/Vi7vbbkLVzakufUaQzRXPe4Q6Vcz+mEQnc78pZmnKI71J6oUGmriIiIAqf2JCxL9aBOW/L5LXu+pzFEK8v0LNaZ9ECUIFVXwOuXwo5FuCJiAXAs+Cusme3/9/IXz/6mAd61rQ63BhF7vGgMYfEETu0841ScA84qsDmazsI1x1Oup31OIiIiCpzakd7uznpbcsMscOpTZ56Ty+X78z2BUysbQ1isznr+PoteUw1vX2W+z8h4ai79H5vSJ5r73v0V7AnTs/bWTKvmGkNYwq1BhCfj5EXg5BmEu9zsnWuvrDK9xC6tG/Zr7QnMUeAkIiKiwKkdsWY5/VJYTlllGH0o7HE02CPNXqX8zb4/318d9SwZ7gDBn4GT0wnv3wBrZ4MjCi5+DVe3I1nd9SKcPY6BymJ4/RIoK/Dfe/qLt63ILV1Hgs1ujmdRGAyn9nTUa2SGU13ph5mSxMri9p1FqTv8tjXUIEJERMRDgVM7khIXSVJsJABb94ZR1ikqvra8qyVtya2MU2s76lk8s5z8FDi5XPDJ7fDj66Y06vyXPE0xXLYIas5+wXyAzd8E71wTfpmOusNvvRGTWBukhHqvUGm+aV4AtdmRptgd0HWEud6ey/UKWtkYwlK3JXlLssUiIiLtiAKndsRms9WW64XbPqc+J5pLX9uSlxVAyR5zvbXDby3WHqeinVBe1PrXm/cALHkOsMHZz8Jhk+vfH58GF74CETGwcS58+afWvyeYgKe1Gaya6trmG821Iq/LU64X4sDJyholdTcBnTcOhUG4noxTt9a9Tsd+5mRAeQHs393qZbVLBTvgqbGw6NlQr0RERAJMgVM7E74NIk4yl1sW+JZxsT7Ud+hsunz5gz87633zGHzzqLk+5VEYen7Dj+syHM74h7m+4G+w+r2Wv2dFMXx4Izw5Gl67oOWvA1CwzbR6j4g1wYe3wqVBhC/7myzd3IFTqLNlgdTa4beWyBjo2Mdcb8+lja3x09vm72bOvbWdDEVEpF1S4NTO9LZmOYVbg4guw82cnYpC+Pz33gdPnsYQfso2WdL9sM9p8XPmewGY8ACMuqrpxw+9AMZON9ff+w3ktGAO0vZF8MyxsOxF8/WORbBvq++vY7G+/7R+ptW4t6yszS8rzADaUPGlo57FGoS7d2P7nU/kr1I9qFOup31ODdq51FzWVMDXYT56QEREWkWBUztjNYgIq1lOYPaWHH+ruf7dEyZTUrav+eflbTCX/moMYcloZWe9lW/Ax+7v5/jb4JgbvXve+Jlm/1NViWkW4e0H9+pKUxL471Ng3xZI7FY7rLY1rc49jSG83N9kSekJ8Rmm5XX2ipa/f2vVneHkrbjU2v1y1ofe9sZfzSFADSKa4nLV/xn64eXaYdIiItLuKHBqZ8K2VA/g6N/CuS+YsrCNn8NzJzX/YczTGCJAGaeWfBhcMxve+7W5PvpXMO4e75/riIDz/g3JPUym6O2rzD6jpuxZC8+fbEr8XE4YehH8+ls48mpz/9rWBE5WK3If9jeBmfcU6rbkLlft8fMl4wTtu1yvrAAq3Hv3WrvHCeo3iJD6inZB8W6zD6znceCshvl/DvWqRKQtWvGaqSjRSaqwpsCpnemZFgfAvtIq9pVUhng1DTj8PLh6jtlPk78Znh/fdMbEk3EKUOCUs9oEJqX53nUN2/QlvD0NXDUw/FI45c/eDY2tKy4VLnoVIuNMl8F5Mxt+nNMJC5+CZ4+H3T9CbIrp2HfOsxCbDIedZh63/Xso3uPbGix1h9/6yrPPKUTBR8F2qNxvWt37+vNhleuFurlFIFj7m+I6mo6WrVU347R+TvOB/qHE6syYORgm/tFcX/WW5l6JiO++eRx2r4KPb1MX0zDWismIEo7ioiLonBRDdmE5W/aWkBIfFeolHazzULhuPrx1BWxdAG9cCifcASfcWX+fTU117dwnv5fquQOn4t3wlDsAsEdCQob5E+++TMisvc1ZAx/8FmoqYeAZcPoTvu0LqqvT4XDmkyYI++4J6DzMBJWWwp0mq7Xla/N13/Hm8R061T4mqRt0GQG/LIe1H8Goab6twemszej5WqoH9RtEuFy+B5CtZWVA0vqDI9K35x44CNfu8O/aQslfHfUsKb1M0F62D147H+LTYch5MOwi83Mb7OMeTqwyvW6jzD7OQWfBz++ZzpkXvRrChYlIm7I/B/Lczaq2LjBVOf0mhHZN0iBlnNohT7mejw0i8ksqmbcmB1cwznTEd4TL34Ux7pK3rx42AVTd9uAF28wemohYSOzq3/ePTYHjbjH7hGKSzW3OKlN688sPsOEzs19hwSNmRtNbV8I7V0NVqQlizn3elN21xpBz4NibzfX3p0P2jyYA+fFNeOpoEzRFxsFpj8Klb9cPmiwDp5jLNR/6/v6FO8z3Y480H4591XmYGfZbkmv2XQXbnhZ01LNkDILIeJOx8ucg5HBQ4Mf9TWB+zq+aA2Ouh7g0c7wXPQ3/OgGeOgoWPFqb5QpHNdXmLG4ghk/vWmYuux1pLsfdY4ZDr50NO5f5//1EpH3auqD+13PvD7+ZjwIo49Qu9UqL57tNe33a57SnqJzznlnI9vxSHr9wOGcd4edApSGOSDj1zyYD9eFNsO5js5fnov9CWt86HfX6tjyz05ST7zN/AKorzAfC4hwoti73mBlS1vXiHLM3ZspjEBHtnzWcdK/5ULfxc3j9UjOc9ef3zH1dR8LZ/zLff2MGnmGaRmz5GsoLISbJ+/eu27GwJUFgZAx0Hm72Ce1YDKm9fX+N1rDKoXzd3wS1g3C3LjBr96W5RLizMk7JPrSXb056fzj1YVOOtukLWPm6+X3NXWtKTec9AD2PNVmogWd4P1MrUMoLze/U+s9gwxyTLet5HFzZiv2AB6qpMidZALq6Sz/T+8Owi2HFq/DFAzD1ff+9n4i0X1Z1ybBLYN1HpmPsytfhiEtDuy45iAKndsjXBhEFpZVc/sJitueXAvDeil3BCZwswy8xe2xev8x8mH9unMnoBKqjXkMiok1pk7/Km7xld5jv9V/jTNamcDvYI0zp4rEzmg9o0vqZrFneOrP/pLE5Ug3xtCJvxd9v1mh34LTIfGgOJk/GqYVBT9ZoEzjtXOp7mWM483epXl2OSOg/yfwpL4Sf3zcdJrd9Y/4uty6Aj241Q6CHnAe9T/DPPitv7N0E6z81f7Z9Zxo11LX1G7OXMS7VP++XsxqqyyE6qbZLI5jf3R/fhM3zYfNX5u9ARKQpVsZp0BmmIc/ce03J75BzIDI2tGuTelSq1w71TnfPcvIicCqpqGbai0tYl7OflDizT+SbDXkUlAa5sUTXkfCrryDrKNMR7LULzZwk8H9HvXATmwIX/9fsHUk/DK6eCyfc7n0WyFOu94Fv79vSVuR1hapBRHVlbcasJRknaL+d9fxdqteYmCQYMRWmfQQ3rTLZ07T+UF0GP70Dr18MD/eE/5wJC580HRz9WQZcUw1bv4U5/wf/GAX/GAGf3W3O3DqrzVqO/i1c+bH75IALtn3rv/e3GkN0G1k/I57SozYQ/+IP2uQtIk0r3Gn2c9vs0ONoGH2d+fe7aBcseibUq5MDKOPUDlmznLbmleB0urDbG968XVFdw/WvLOOH7QUkxUby+nVjufH1H1i7ez9zVudwwZEB/uB1oIQMuOJD+PQOWDrLZF/A/x31wlHGQJixxmSbfN1sP/B006p84+dQVeb92amWtiKvy2qykLPa7E8LVonW3g3mw3F0YsszK1Znvbz1/s1EhJq138gfw2+9ldzdzGk77hZTvvbjm6aUr2CbO/My3wQ1yd2h30ToOwF6HeddNsrlMmW0ezdB/iZzuXcDbFkA5QW1j7NHmA8d/U81GbGOfWrv63W8Oc5bvzG/L/5g7W+yyvTqOu5WWP6yCa7WfwYDTvHPe4pI+7PFnW3qPLy23P6k/4N3fwULHoMRV7Sf/5/aAQVO7VC3lFgi7DbKqmrI2V9O56SDP0jXOF3c9PoKFmzIIy7KwYvTjmRApw5MGdqZtbv3M3tVdvADJ4CIKLOHqNNQ05LTWWWuHwp87Qxn6TzcnJ0q3GHapR82ufnnuFyQ6+7g05qMU4dOZiZVwTbYtRT6nNTy1/KFZ3/TwJZ3dYtPM/uy8jeb7nr9xvtvfaFSXWE6RULgM04NsdnM3rGuI+CUh2DvRtgw1+wz2vataSG/5HnzxxFtAp1+E033qJhkcyys4MhzucU08WhIbIp5fv9ToO/Jje/x63msec+t3/jve/V01Dvy4Ps6ZMJR18M3j5msU7+JgdmnKSJtn1Wm1+u42tsOvwC++yfkrIKvH4FTHgzN2uQgCpzaoUiHne6pcWzOK2FLbslBgZPL5eLu/63ik592E+Ww89zUURzRPQWA04Z24ZE56/l2Yx77SipD18581DTofhQU7jIbrqVxNpuZ6bToGdNdz5vAaf9uqCg0pQF1z8y3RNYYEzjtWBy8wGnPanPZ0jI9S7fR5sP6zsWBDZzyNphAdcCpgW19bmWbImLNHKdQstnce/D6wdjfQGWJKaPbMNf8Kdxu5pht/hI+u6u5FzOBYMfeJthN7WPKe7NGe/f32eNYc5nzk3+yi2X7TNYLzDoacvTvYMkL5j1X/6/+uAERETAnMa3GED2Pr73dbocJM+GVc2Dxv2DMdZDSMyRLlPoUOLVTvdLi2ZxXwua8Eo7um+a53eVy8eDHa3hj6Q7sNnji4iM4ps79vdLiGdwlkdW/FPHZ6t1cNNqPnbl8lTHQ/JHmDTzdBE7rPzHdvprLXln7m1J7t75DYNZoWPWmaRARLDmtbAxh6TYKfnw9cHu08jaYVvur3gZcJvNw7vO+dT/0Rd0yvXCbrxQVbwLHAaeaDwt56+tko9zNHJK6QWovExh17GMuU3ubDwyRMS1/74R0SB8IuWtM1mnQGa37XqwyvZReZrRCQ+JSTfD05R/NJu9BZ7Y8qyxSUw1bvjKt7jsPh5FXhHpF4g/7tppqEXuEOVlcV9+Tofc4c3Lpiz+a/zsk5BQ4tVONddZ7av4mnltgZu48fO5QThly8Gyg04Z2ZvUvRXy0Kju0gZN4r/tYk2Eo3WtKonqf2PTjWzP49kBWg4idS4M3TNbqqNfajJNnEO4yMxDYX+VUezfBV38xAaXLaW6zR5og4bmTTMv9QGRSPR31QlCm5wubzeytSx8AR0+HqnLAFdjuUT2P9V/g1FSZXl1HXW9OaORvhhWv6cOu+MblMgPOf3zLNFwp2WNut9lh8FmBOwEjwWOV6XUdCdEJB98/YSY8+yWsegvG3gBdjgju+uQgKrpup3qlHxw4vfz9Nv76mdnXcu+UQZw/quEPV6cd3hmA7zbtZW9xRYBXKn5hd8AAd4neGi9m1fijFbklYxBEJZhuiMEYJlteWBsgtGT4bV0Zg82Q4Yqi2qntrZG/Gd79NfzzSJPJcjlNs4LrvoJr5kJiN7Pv5/mTTdMAf/N01AtyW/3WiowJfMtda/+AP/Y5eQKnBhpD1BXdwTTMABNIV5W3/r2l/du7Ceb/Gf45ypxoWfS0CZpiU0z7e5fTZGml7bMaQ/Q8ruH7Ow+DoRea63PvU5fOMKDAqZ06MOP0/opd3Pf+TwD87qS+XH1sr0af26NjPId3TaLG6eKz1TmBX6z4h9UtbO1HJnvSFH80hrA4Imr3eQSjXG/PGnPZoYv5INEajgjoMsJcb025Xv4WeO8G0xZ75WvgqoF+k+DaL+GS16HLcHOm8Lr50P3o2pb7C/7m3/8IQ9FRr63ocYy53LMaSvJa/joul2mEAs0HTgCjroLErlC0E5b9u+XvK8HncsE718Kzx5tB5YFUvAe+f8YESv8YAfPdzVUiYmHIuXDxG3DLepNpgtoP3NJ21d3f1Ov4xh837h5wRJnHbpwXnLVJoxQ4tVO93S3Jt+eXMmf1bm55cyUuF1wxtgc3T2g+y3DaUJN1+mjVLwFdp/hRrxNM5mf/L6a8oymeGU6taEVel1Wut2SW2XwfSDnuxhCtzTZZstzlVi2Z51SwHT74rTkzvOIVEzD1nQDXfAGXvmm6y9WVkA5T34dRVwMumPcAvH2VaZzgD1YL/ySV2B4kPq22tLM185zyN5vmEI5oyDy8+cdHxpihuGC6Y1UUt/y9Jbg2zTPlttkrYdYpsO5T/76+y2Ua+rx8DvztMDOKY9cyU4rX52Q4+1m4bQOcN8u0tI+Iqv2AvfVr/65Fgm/vRtMF1RFVWzbekJQeZrYTmKyTsyY465MGKXBqpzITo4mNdFDjdPHrV5dT7XRx9hFduf/0wdi82DRulest3LSXPJXrtQ2RMab5AJj/jBtTkmf2QmHzT6kewPBLIDbVtE6ddYrphhgo/trfZPEMwl3a/GNrqmDvJmyb5jFs+7+JeHo0LP+PaWzQ5yS4+nO47G0zFLUxEVEw5VGY8rjZ97T6f/DCJNi3rfXfS1st1QuWnn4o17N+TjoPNcfSG8MvMU0uSvNM2ZWEP5cL5j9srsckQ2Ux/Pci0yLaH1ni8kJ45xp44zIToLlqTOb+lIfhlnVw+f9g2EWm3LMu62d490+BP0klgWVlm7qNbr5U+bhbzJ62PavhxzcCvzZplAKndspms3nK9WqcLsYPzOAv5w1tdBjugbJS4xjWLQmnCz75aXcglyr+NHCKuVzzYeP/uVtleslZEBXnn/dN7QVXfWrK5/LWmeBp7yb/vPaB/NVRz2Jt8M9dC2UFZhZS7npzdnnhU/DRreaM8N+Hwx8z4R8jiHj9Qnru/RKbs9o04rhqDlz+bm32yhujppmBz/HpJuB8blzrym+cTjNpHlSq15ie7rbkrfl73uVlY4i6HJGm3Abg23+YjJWEty1fmSx0RAz8+lsYeSXggjn3wOybzEmUltq+CJ45Fn56G2wO033xt8vh2i9MQ5GEjMaf2yET0gaYtbQmcyqh502ZniUutXa/5Bd/NMPuJSQUOLVjh3UyZ6rG9Erln5eMINLh2+H2lOv9qHK9NqPvBJP2z9/UeKMGT5meH/Y31ZU+AK7+zLSQLtwOsyZB9o/+fQ+Xy38znCwJ6bXzMf45ygRHTx4J/73QzBda8pw5I7xvizkrHBGLK30gu5JHUz11tim96z6mZe/dY6zZ99R5mMkC/udMWPSvlp3RLtkDNZWmzKdDl5atp72z9jnlroHi3Ja9xs4l5rKx+U2NGXyOaUZSUQjfPtGy95bg+eov5nLkNJPBnfI4THoQsMGyF818HV8D4Jpq0/Th36eYMt/kHnDVZzDxD77N07Manfh7n1N5EbxyLrw51QR3EjguV23mu1cjjSEONPpXpmNq0S5Y9Gzg1iZNUuDUjt12ygD+cNYQZl15JDGRvreInuwu11u0JZ89+9UNqk2ISTRzH6Dx7nqeVuR+2t9UV3J380Gg0+FQkgsvnubf7k9Fv5gSF5vDv+u32reX5AIuiOoAnYbCoLPg2Blwxj/hyo9hxlq4J5vq6xawtNd0XFlHNfGiXkrqZv7ODr/ABGaf3Gb2TVX7WCJrlel16GKaXsjB4jtC5hBzvSVn66vKapsE+JJxAtPq/uR7zfVFz8B+Nd4JW1u/MT8fjmg45kZzm81m2kFf/LrZS7rla3h+vPeZ9YLt5t/D+Q+ZrnhDL4Trv/EtS23xlJz6OXD6+X3Y+Lm5nDURnp9gqhe0p8b/9qwxpbsRsdDViyYzYMrxrcz1gkfbfqnm7lWw+t1Qr8JnCpzasc5JsVx+VA/io1v2IapbShzDs5JxueBTleu1HZ5yvQ8avj9QGSdLQjpc+VFt97iXz/Zf621rf1PHvq0f3FvXhAfgwldMyd2tG+GuHXD9ArjgJRh/P4y4HHoeA4mdAzNYNjIWzvkXTPiDyRj98DK8OMW3/xitFu0q02uaVa7Xkg+d2T+a/Wzx6eYkga/6n2ICrqpS+OYx358vwfGVe2/TiKnmd76uAaeYEx11Rws0t2du1dvw9LGw43tzUuac58zve0xiy9ZnBU57fm555rQh693NLzIGmcqFnYvNHqx/HglLXgj/8rDslUQ8P46svX4YORBoVple96O83ysJMPQC05SmotA0m2mrVr1tAvP/XVc7ULyNUOAkTZriLteb/WN2iFciXhsw2Xz43v1jww0HrD1OaQHIOFlikszm5v6nQHU5vH4J/Phm61/X3x31LDFJpp179zEm8AtEcNQcmw2O+R1c+pZZz87F8PJZ3pcDtZXht6HmCZxa8OHK2t/UdVTLfkZsNjjxLnP9h5dN9lTCy7aF5kOtPRKOvanhx3QaYvYjdR1pfj//cxb88MrBj6vYb+a6vXO1+aDb7UhzQmboBa1bY3xHU/YJ/ss6VVfApi/N9bOegpt+cjckSDal3x/NgMcGm1LDkr3+eU9/W/A3bDmrOGL7c9hWvxPq1TTNOm7elulZ7A4zFBdMGfm+rX5dVj27lsPyl32vfmiKswbm3Gt+J6rLzL/HKY2PxwlHCpykSae6y/WWbM0np0jlem1CfJrJ9oCZ6VRXeSHsdwfB6X7qqNeYyFiTxRl6oTlL/79rzf6d1vB01PNTY4hw1He8OaMdl2baIL98jncfsNVRzzs9jgFsJvPq69l6bwffNqXPSZA+0HRpa+jDdrhzuQKXechdb5qxvHJe7c9zsFnZpiMua/p3qUOmyawPPhucVfD+DTD3/toZejuXwTPHmbluNjscfztM+9Q00vGHXn4u19v6DVSVQIfO0Hm4+f5Ovg9uXm06/SV3N/sw5z9kAqiPbglcA6CWKM2HdZ8AYMOF44Mb/N8+3l+cNXX2N53g+/P7nmzKy2sqTaOIQCjeY/bcfjDdzDHzputsc0rzzR6679x7PI+5CS592zS+aEMUOEmTuibHMqK7Kdf7ZJWyTm1G3e56deW69zd16GKyGoHmiISznjGbWsHs35n/cMvb+Xo66vk54xRuMgaaphOxKWYm1yvnmbPXTVGpnnfiUmv3Ofn6odMfgZPNZjqngdng3db2j3z9CPypE7wwEZb+23SibA2nEzbMNScInjzSnEXfONc0KPDnmW5v7FgMm78EewQce3Pzj4+MhXNnmaAI4NvH4c3L4eu/mj1C+7aYDPCVH8FJ9/h376FVruevBhFWOXW/ifWzqdEJ5uf1tz+YeVKdh5tMwZLn4R8j4Y3LwyOAWv0/qKnElTGIHSlHm46nb10RnoOCd6+C8gJTttl5eMteY8ID5nLVW4EpdZs305TagznJ9MIE+OweqCxt2evt/sl0jt38JUTGmZ+lCTNNBq2NUeAkzTptqOnQ9ZECp7bjsNPM5faF9c+qe/Y3BTjbVJfdDqc+XFuiNP9B+PTO2jOz3qqpNq3OwX8d9cJZpyEmeIpJNmV7r57f9PDUwp3mUsNvm9eScr39Oe4BwzboMqLZhzfp8AtMUFywzXOWvE0o2QvfPGqu71hk2nL/bYAZ4rzxc9+CwIr9JgP95JHw6nmmcyU2U2ock2xOGHx6VwC+iSZYnfSGXWyGjnrDbjdB0TnPmX1Ba2ebLICz2mSjrv8Gehzt/7X2dGdO926Aolb+3+xywXr3z2H/Uxp+jCMChpxruoBeMRv6TQJcZi/taxeE/gTAiv8C4Bx6MT/0uBZn/1NNmfh/LzLZv3BinbDpMbblwXTnYebnFODDG83/j/6ya1ltNvySN2HoRaahycJ/wtNH+17m/NP/TOC1b6vpJHn1XPOz1EYpcJJmTT68EwBLtu5jd6HK9dqE5O7uM1kuWPdx7e2BbgzRGJsNTrwTTnV/MFn0DLz3a99moeRvMqUJkfHmH99DQedhMPU9iE4yQfB/L2r8jJ9K9bzXksDJ2t+UfljLN/VbouLcc4EwvwttxaJnTGOLToebM97pA82H05/eMSU4jw025WrWPsqG5G+BT++GRweZDPTejRCdCEfdAL/7AS7+L5z7PGCDpS/AyiAN+9y1zGS6bA44bobvzx96gZnLFpdm/o068yk4798Qm+z3pQIm8O50uLnemoHOYP5fKNhuugj2bqZ0zGYzZYKXvgm/+d6sY+/GxpsRBUPuevP7aXPgHHwuLpuDmrOfM2VwlcWmdbxVrRAOrCyYN/ObmjLhD+Ykw+5V/hus7XTCJ3eY60Mvgv6T4Jxn4ZK3ILGryaK+eBrMnmHa1zf5WjXm34O3p5l/N3qPM4F3pyH+WWuIKHCSZnVOimVUjxQAPlbWqe1oqFzP+kATiFbk3hjzKzj7X+bDyY+vw7MnwIbPvSvdsxpDZAw0Z3kPFV2OMI02ojqYM5X/vejgPSblhWbzOahUzxs9jgZsJoPpbVtwT5mej/ObGnPkteb3YOsC/887C4TyIljsnh1z/G2mTfdvFsK1X8Lo68wH6P3ZplztydHwr3Gw+Dmzr8Hlgs1fwX8vhieOgO+fNGVAHfvCqX+FGT/DKQ/W7v/pN8G8B5iz6cH40PvVX83l0AshtXfLXqP7UXDTj3DLWjji0sA3mbE+eG/9unWvY3XT63U8RMV7/7yMgbVl2N881vIS7NZa+Zq57DehdnhwRAxc9JppyFFeYBrthENJYU117YgOq9yypRLSYaJ7j9OXDzbcDMpXP75hZtVFJcD439fe3n+iCZRHTjNfL30Bnhpr/v9uSGm+qZL49nHz9dG/a5P7mRpyCH36kNbwDMNV4NR2DDzDXG75qvbMkFXqFuyMU13DLjT/ocUkm2G2r55r/lNr7sPjnkNkf1NDuo2Cy95xz4/5ynQprKqT/bXK9GJTffvgc6iKS60967nNy7P1VsbJ1/lNjUnqCoPONNfbwjDLpbNMgJ7WHw473dxms0HXETD5r3DLOrjgZVNqZ48wpXYf32pK+Z44Av5zhjv77YI+J5sPUTcsgTHXQXSHg9/vxDvNGerqMrNvqLmz262RvdKUqtnsppNca0TFtz4j6S0rcGrtPh5rf1P/Sb4/d8yvzJ6V7JWw6YvWraMlnDW1WUmrdM0SnWC6lGYOgeIc0/2wcFfQl1hP9gqo3G/2GFsZw9Y44jLocazJ6Hx0S+uC14r98Pn95vrxtx7cij8mEU5/3GRWU3pC0U7z//e7v64/OiNntdnPtGmemVN17gtmyHM7mS+owEm8cuqQzthssGzbPn4pCPNZDmKkD4CO/Ux524Y5UFliyjEgsK3IvTHgFFOWM3a62Reweb7p3PPu9bVBwIGss87tuaNeU7qPMR8CIuPMB5Q3L6/dPK8yPd95hoh6ETg5a0xrXvB+WKU3jvqNuVz1pn/n8fhbVRksfNJcP/bmhjO+EdEw6AxTajdjLUx6yHwwrKk05T2RcXDkNSZYuvx/JjvQVObY7jAfuKx5Se/fELiMhrW3ach5kNY3MO8RCN3Hmqzlvi2N/7vZnNJ8s18NWhY4xaXWlp2GYjbZlq9g/y/mRNyAUw++PzYFLn8XUvuYPYovnwUlecFeZS1rflPP4/zTGMFmM8GMI8qUmq7+X8tf6+u/mgAztXftv00N6XU8/Po792NsJuP31FGmumX1e2Y+076tZsvA1XPg8PNavqYwpMBJvNIpKYYje5gUq8r12pC65Xp57o56cWlmDkioxaXCpD/B9CXujaIuWPlf06np898f3IJ7T51SvUNVj6PNZt2IWBMMv3UlVFfW6ainxhBe86UrWe46s1ciMt6/P39ZR5pZQDWVsOzf/nnN/TmmbKfoF/+8HpiN4iV7TOORw89v/vEJ6TD2N6YxwvXfmL0+M9bAaX/zrTFNfEczhNoeafbQfP9Uy7+Hxuz+yTR0wGbOsrclMYnQZbi53tKs08bPzcb/zCEt//dj7A3mGG1d4J+21b5wN4VgyLmND0VPyDCNdhK7mf8HXz47dDPU6gZO/pLWD45z/+x+cqf3s//q2rsJFrp/vyY91PyA+ah4OOUhExil9TcB1xuXmU6GVSVmf9l1X0Hnob6vJcwpcBKvqVyvDRroLqnZMLe2FC6UZXoNSelpWpNe+4WZsVNdbs5cPnGEKWGqrjTd5KxBf5mHaMbJ0us4c1Y/IsaUPr1zldlwDxp+64seY/F0Jdu/u+nH7lxiLruO8H/73DG/NpdLnjc/663hdJpg+quH4c0r/NPprKYKvrXmrvzOjBjwRafDYcg5LW+S0G2U+YAGZnCmtT/EX752Z5sGnx26vZ+t4cmctjBwsvY3tSTbZEnqZvaGQXCzTuVFtXt4h1/a9GOTs0zwFJdmhsO/dmHLW2u3VHVlbXbP18G3zTn2JhPAlOwxDRl89eldZh5Z3wm+/SxkjYZfLTAlrjb3v41jp8Nl/2sX+5kaosBJvHbqkE7YbPDD9gJ27gvyPzjSMl1GmE44VSW1+yjC9cNB15Fm3slF/zX/AZTuhU9uh6fGwHf/MI+JzzADfg91fcbBRa+a8ow1H9Zu2ldjCO/50pXM2t/U1U+NIeoadKYZOlqcA6vfbd1rLX4WtrsDi52LTTDWWqveMiVO8RlmP0UoHHmNKaNz1cBb07xv6NGcnJ/h5/fNdasZRVtjfQDf8rXvpYw1VbWb+xtrQ+6tY24EbCZ7t2dt617LWz+/b/bApfU3JzWak9bXlO1ZXUrfuKz1Jyt8sWuZ2YsUl2Y6UvpTRDSc/ndzfflLvp1gWD8HNnxm9iae8pDvTU0iY8yw5BsWmVbjk/7UbvYzNUSBk3gtIzGG0T3NGYRPVjVzhlbCg81WO9PJKnUL18AJ3OudDL9eCFMeMx/W8jfDV3829x+KjSEa03c8XPiKKZFxumd4aI+TbzxdyZoJnKw5MP5qDFFXRBQcebW5vujplu/j2bsJPp9prvdyt5T+fGbtvsaWcNbAAvfcprE3mIGvoWCzmQ+F6YdB8W5452r/zK1Z8Ii5HHhG2/23Jeso84G3cEdtVt5b27833TjjOrb+pEB6/9rS8G//3rrX8tYKdze9YRd7/2G/89A6e0Xnwf+u8e8MpKZ4yvSODUxn2B5Hw4ip5vqHN3k3QLq6Ej5zz0s76tem7K+l0vqZDFQ7p8BJfDLFXa43W+V6bYdVrmcJ58DJ4oiAUVfB75bD8beb/+TAtOaWWv0nufeAuM/udWzFf3qHIs88pybKnCr213Z07ObHxhB1jZxmSi9/+aG2lMcXTie8P92cfe91vDmr3n2syTTPvrnlwdja2aaUMSbJ/D6GUnSC6doXlWCO1xd/aN3r5W0wgzkBTri99esLleiE2qDH13I9q0yv30T/lKAee7O5XPVmbcOaQMnf4s6u2mrLBL3VfYzp7OqIMlmrl8/yPehsCev4+LtMr64JD5gTjnnr4JvHm3/8omdM85X4DPN/rTRLgZP4ZNKQTthtsHJHATvyVa7XJnQ/2rSptoTbHqemRHeAk+6B3y6H05+AY24K9YrCz2GnwbRP4Oxn2+5Z81DpPta0oN67EYoaORn0yw+Ay+wf69ApMOuIT6ttuvB9CwZZLv6X+RAZlQBn/NN8CD7jH2ag6cbP4cc3fX9NlwsW/M1cH/2r4LXYbkp6fzjzn+b6t4/D2o9a/FKObx8FXHDYFP+0hQ4lXxqd1NWaNuQN6TrSZDud1bDwn/55zcasfN1c9j7RtPb3VZ9xcP5L5qTc1gXw1NGmtNXp9OsyParKYMdic93KCAdCbErtnsAFj5gTBI3Zn1PbUXL878Pjd7wNUOAkPsnoEMOYXqYjm7rrtRGOiNo2rdFJkJAZ2vW0RGJnGHlFyzeYt3dZo2HYRaFeRdsTmwyd3F2ftn3b8GM8jSECsL+prqPcTSLWfOjb2fq9m0wXSjBnm1N6mOtp/WozKZ/e4Xu7803zzGyeyPjatYWDwWfXtkp+99emlNdH8eW7sa1+x3zRVvc21dWrToMIb7OLezeZbKI9Avqc5L+1WFmnZS8Fru2302k6sAIMv6Tlr3PYZPj1t6YpUVWJmYP08pn+GSR7oB2LoaYCEjqZwc+BNORcU8pdU9l0xnneTDNTquvIg2dgSaMUOInP1F2vDbLOZmeNDvw0e5G2xCrXs/YfHMizvylAZXqWzMGmzM5VA0ue8+45B5bojZxW//5jboTMw0174k/v8G091t6mUdPCrzvWhAcga4zZn/PGVHM23wf9cz7E5nKahghWO++2LGuMKTvbn20CIm9Y2aYex5hSTH/pfaIpqa4uC9xg5+0LoWAbRHUwGcPWSO0NV8yGUx42Yx62fA1PH20GPvtzbljdMr1A/x9ss5nW/xGx5n1XvHrwY3Yurb391L8EZs9VO6W/KfHZKe5yvR93FrJ9r8r12oQ+4+CqOXBWC8qARNqzpgbhuly1HfUC0RjiQFZr8mUvmYHVzbFK9CLj3SV6B/yX7oiEM/9hyhF/egfWferdOrYtNBk4R5RpChFuHJFw/oumO1nOKnjvN6Yz2LbvzNiF/M0mw1ZVdvCH331b6Zbvzi62lz0dkbG1P59bGzkBcCBPG/JWdtM7kM1Wm3Va/KzZI+hvVlOIwWdBVFzrX89uh6OuN9mn7mPNzLbZN5u9T61prlKXVUZpNaQJtJSeMO5uc/2ze+pnnJ1O07EWYNglgT8p1M4ocBKfpSVEM7aPKddT1qkN6T7GDKYUkVo93Puc8jcdPDS2aKdpE26PgM7DAr+W/pPMB57ygto9HI2pW6I3sU6J3oG6HGHmqoD5MFhe1Pw6vnFnm4ZfAoldvFh4CCR2MfPfbHZY/T947Xz496nw7HFmBtwjfeFPneCBjvDn7vDoYHhyDBGvnIUdJ87eJ0O3AJdfBpP1gdybfU7lRbWlqf7a31TXYVNMOVp5ISx70b+vXVkCP79nrremTK8hHfvAlR+7B8DGwub5Zu/Tshdbl32qKK49AePPwbfNOeo3Zv9eeQF8dnft7Sv/a1qjR3WA8S2Y+XSIU+AkLXLa4eY/049W+XE6vYhIsMUk1QZFB2SdbLvcZXqZQ4LTitvugDHXm+uLnml8o7rTCR/8tk6JXjMd7068C1J6wf5f4PNmPihlr4QNc0xAcsyNvn8PwdT7BDj3BfNhtPMwSO1j9nBGxtc+xlVjPsAX7YTctdiKduLChvO4W0O37kComzlt7kP+pnmmgUPHfiZY8De7o7aRz8InvWuL7a01s01GKKWnyQ75m90OY38D139jSiAr98OHN8Ir50Dhzpa95o7vzd93UpZZd7A4Ikwbf5vddDrcOM8EzdYJlxNuC1zDm3ZMgZO0yClDOuGw2/hpVxFb87woKRERCVeNtCW3ecr0gljKMvxScyY4bz1s/qLhxyx5zmQMIuNN97zm9idExcEZT5jrS2fB1kYaYUDt3qYh55r9H+FuyDlw5Wz41ddmfMGt6+GeX+C+fLhzB8xYAzcsgWu/gKkfUH3ef1jQ/z5cwSi9DKZuo0xL+5I9kLuu6cf6u5teQ4ZeCB26mH1XzWVPfbGyBbObWiKtr+lWOvFP5u910xfw1FhY/h/fs091y/SCvce460jTFRNMxnneA+ZnpGPf2tJg8YkCJ2mR1PgoRvVIAWDxlvwQr0ZEpBV6NjwI1/bLcnOlaxADp5hEOOIyc/37Zw6+P3/zASV6Pb173V7Hw4grzPUPfttwQ4W8DWauDcCxM3xZdfixO8zfZWIX08a860jofQKuAZPZFx+ALEuoRUSbDAk0Pc/JWWMyiuD//U311hMFR7tLRL/9u3nf1ircCZu/MteD0UXU7jDfw/XfmD1kFUXmd+fFKbD7J+9fxzP4NohlenWddA8kdjUNNazGM5MeMsdIfKbASVpsUBfT8399TgA2f4qIBEv3o9z7nDZD4S4AbM5qbLt/NPcHOzsx5jrABhvn1p/DYnXRqyo1H8KaK9E70IQHTDvk/E3w1cMH3//N44ALBpymmWBtkdWWfMtXjT9m1zIo3WtKVLsfFdj1jLjCzBXK3wRrPmj96618HXBBj2ODW/KW1g+u+gwm/MHsfdr2jdlL9/HtpmNlU8oLIXuFuR7IwbdNie4Akx+p/brfJOg/MTRraQcUOEmLDcjsAMA6BU4i0pbFJELn4ea6O+uUVL4dW3U5xCQHZh9IU1J712YDFtXJOtUt0TuzgS56zYlNhinuUrxvnzD7mSwFO+BHd0nVcW0823Soqps5bWx/nNVNr+94050wkKITasvEvnmsdQ0WXK46s5tCMHPI7oBjfgfTF8OgM8HlNF0D/zHSlO819ve9baF5bGpvSOoW3DXXddhkGHklJHWvHZArLaLASVqsfycTOCnjJCJt3gH7nFJK3INVu40Kzewza+jsitfMWe26JXoTZrb8jPthp8Ggs0zThA9+CzXV5vbv/mE2sPc6Qe2J26quI0xQXbYP9qxu+DGe/U0BLNOra8yvIDLOBOmbGtmz542dS2HvRvNag8703/p8ldwdLvgPTH0f0gaY7N0Hv4XnT66d+VZXqMv06jr973DzquCfCGpnFDhJi/XLSAAgp6iCgtLKEK9GRKQVrHbOnsBpo/k6mPubDlxPxiBTlrfspfoleqOubt1rT/6ryaRlr4SF/zQzXpa/ZO477pZWL11CxBFZW37XUFvygh2Q85MpS+07Pjhriks1mQ4wWaeWsppCDDzdlJ6FWu8TzdyniX8yzVx+WQ7Pn2R+T+vOTLLmagVrfpMEnAInabEOMZF0TTYtetfnFId4NSIirZA1BmwO2LcVCneSUrrJ3B6q7ms2W21r8i/+2LoSvQMlZMCkB831+Q/Bp3dAdbkJEvUBr22z9tE01CDCKtPLGmMCmmAZewPYI82adi71/flV5WaAM5hueuHCEWmaR/x2We26fnjZlO99/4wJoKwmEuGQcRK/UOAkrTKgk/Y5iUg7EJMIXYYDYF83m4SKHHN71xGhW9PQCyA2FZxV5uvWlOgdaPgl0HucCZisD6XH3xqaskTxH88+p28P7mQXjDbkDUnqZtqTQ8uyTus/MU0WEruGZ2DfIRPOfgaummPmiVUUmpMRT48FXKakr0NmqFcpfqLASVqlv7tBxPrdCpxEpI1znxW2L3oaAFdq7+CemT9QZCwceY257o8SvbpsNrPnITLOfJ0x2HTbkrat8zBTOlZRCFZXSIDKktr9NsHa31TXMTcCNlg7G/as9e25K6zZTReZJg3hqvsYuPZLmPKY6SZY4i7ZC8dgT1pMgZO0yoBOZp+TMk4i0ua5AydbkWlJ7grV/qa6Trgdzn0BLnq19SV6B0rpYdoUx3U0M6H8/foSfI4I6HmMuV53n9Pmr6CmApJ7QPphwV9Xen8YOMVcf+l0eO8Gk+ksbWYO5P4c2DjPXA+nMr3G2B0w6ir47XJz0iN9oPla2o2IUC9A2jZPxilnPy6XC5vKPESkreru3ufkMiVOri4jQ7wgzD6Kw88L3Osfcan5I+1Hz+PMfqatC0wLbajd39T/lNCVY467x7TnLtkDK14xf7BBlyOg78nQ52TT0bFum/RVb5rfx25HmnlKbUVcKpz2t1CvQgJAgZO0Sp/0BOw2KCitInd/BRmJMaFekohIy0R3MHuadi4BwNl1JGFcGCTSMKtBxLbvoKYK7BGh299UV8ZAuHk1bP/OZJE2fQF7fjYd6X5ZDl//FaITTWlbn5NMMLXCPbupLWSb5JCgwElaJSbSQc+0eDbnlrAuZ78CJxFp23oeCzuXUGOLNPt+RNqazMNNu/nyAvhlhcngFO82XRmteWWhEhljgqI+J5mvi7JNALVpHmz6EsryzT6otbNrn+OIhiHnhGa9IgdQQbO02gB3ud46NYgQkbau/6kA5HYYVL9kSKStsNvrDHT+urZMr884iIgO3boaktjZlIqeNwtu2wjXfgEn/R90P9pkysAETbEpoV2niJsyTtJq/TM78MlPu1mvBhEi0tZ1H0PV1V+yfPEaJoR6LSIt1fM4k7XZssBkniA03fR8YXdA15Hmz/G3QXkR5Kw2nQJFwoQCJ2m12llOGoIrIu1Ap8OpitgR6lWItFy9fU4V5nq/iaFbT0vEJEKPsaFehUg9KtWTVrM6623I2Y/T6QrxakRERA5x6QNNm3kraOo6UkNYRfxAgZO0Ws+OcUQ57JRW1rCroCzUyxERETm01d3nBOFfpifSRihwklaLcNjpk+EehKsGESIiIqHnHugMhLYNuUg7osBJ/GJApjtwUoMIERGR0Os7HhxR0LEvdBoa6tWItAtqDiF+0d/dIEKd9UTC3+uLt7Mtv5TbJw3AZrOFejkiEgipveBXCyAmCfR7LuIXCpzELzTLSaRtqK5xct8Hq6msdnLm8C4c1ikx1EsSkUDJOCzUKxBpV1SqJ35hddbbnFtCVY0z6O/vcrn4zavLOPPJbymvqgn6+4u0FVv3llJZbX5HN+0pCfFqRERE2g4FTuIXXZNjiY9yUFnjZNve4H8YW7wln49X7WbljgKWbM0P+vuLtBV1y2k35Wr2moiIiLcUOIlf2O02+nnK9YL/Yezf3271XF+ydV/Q31+krahbTqvASURExHsKnMRvPPucgtwgYkd+KXN+3u35etk2ZZxEGlM347Q5V6V6IiIi3lLgJH7j6awX5AYRL3+/DacLuqfGAfDD9gKqQ7DPSqQtqB84FeNyuUK4GhERkbZDgZP4jZVxCmZL8pKKav67eDsA900ZRIeYCEora1iTre5+Igcqr6ph695Sz9cllTXkFFWEcEUiIiJthwIn8Zv+ncwQ3K17S4LW2e5/y3eyv7yaXmnxnHRYBiN7pACwVOV6IgfZnFtCjdNFYkwEvdPiAe1zEhER8VZYBE5PPvkkPXv2JCYmhjFjxrB48eJGH/vcc89x3HHHkZKSQkpKCuPHj2/y8RI86QnRpMRF4nTBxj2B/zDmdLr493dbAbhibA/sdhujrMBJDSJEDmJlgwd06kDvdHOiQ4GTiIiId0IeOL3xxhvMmDGD+++/n+XLlzNs2DAmTZrEnj17Gnz8/Pnzufjii/nyyy9ZuHAhWVlZTJw4kV27dgV55XIgm83mmecUjHK9rzfksjm3hA7REZw3KguAUT1TAZNx0t4Nkfqs38v+mR3ok2EyTmoQISIi4p2QB06PPvoo1157LdOmTWPQoEE888wzxMXFMWvWrAYf/+qrr/Kb3/yG4cOHc9hhh/H888/jdDqZN29ekFcuDRnQKXid9awW5OePyiIhOgKAYd2SibDbyCmqYOe+soCvQaQtqRc4pSnjJCIi4ouIUL55ZWUly5Yt46677vLcZrfbGT9+PAsXLvTqNUpLS6mqqiI1NbXB+ysqKqioqN38XFRUBEBVVRVVVVWtWL1/WGsIh7X4Q58009lubXZRQL+nTbklfLU+F5sNLh3d1fNeETYY1KUDP+4sYtGmXDp16BKwNTSnvR1bqdVWj+1ad8fLPmmxRDrMebNNe4rb3PcRaG31+ErzdGzbNx3f9iuQx9aX1wxp4JSXl0dNTQ2ZmZn1bs/MzGTt2rVevcYdd9xBly5dGD9+fIP3P/TQQ8ycOfOg2+fMmUNcXJzviw6QuXPnhnoJfrG3CCCCH7fm8vHHHwfsfd7abAfsDE528tP38/mpzn2pNea+d7/5kchfVgRsDd5qL8dWDtaWjm1FDezcZ/7J3/bj99gAiOCXwnLe/fBjoh2hXF14akvHV3yjY9u+6fi2X4E4tqWlpc0/yC2kgVNr/fnPf+b1119n/vz5xMTENPiYu+66ixkzZni+Lioq8uyLSkxMDNZSG1VVVcXcuXOZMGECkZGRoV5OqxWWVfHE6i/ZV2njuJMm0iHG/z9iRWVV3LXsa6CG2886krG9O9a737E6h/mvryTXlcjkyUf7/f291d6OrdRqi8f2x52FsHgRaQlRXHDmRAD++vOX7Cutov/IYxncJfT/HoaLtnh8xTs6tu2bjm/7Fchja1WjeSOkgVNaWhoOh4OcnJx6t+fk5NCpU6cmn/vII4/w5z//mc8//5yhQ4c2+rjo6Giio6MPuj0yMjKsfqnCbT0tlRYZSafEGHYXlbMlv9zTHtyf/rdwB6WVNQzI7MBx/TOx2Wz17h/TJx2ADbnFlFZDUmxo/17by7GVg7WlY7tpr9nz1z+zg2fNfTMSWLJ1H9sLKhjeo218H8HUlo6v+EbHtn3T8W2/AnFsfXm9kDaHiIqKYuTIkfUaO1iNHsaOHdvo8/7yl7/whz/8gU8//ZRRo0YFY6nig/6dAtdZr7rGyYvuFuTTjul5UNAEkN4hmp4d43C5YPl2tSVvCafTxfsrdpFTVB7qpYifrN9d2xjC0ttqEBGE8QEiIiJtXci76s2YMYPnnnuOl156iTVr1vDrX/+akpISpk2bBsDUqVPrNY94+OGHuffee5k1axY9e/Zk9+7d7N69m+Ji/ccfLgZkmg9j63b7P3D6fE0OuwrKSImL5Kwjujb6OE9b8q0ahNsSs1dlc+PrK7jqxSVq695OrHcHR1bnS6C2JXmeWpKLiIg0J+SB04UXXsgjjzzCfffdx/Dhw1mxYgWffvqpp2HE9u3byc7O9jz+6aefprKykvPOO4/OnTt7/jzyyCOh+hbkAIGc5TTL3YL84tHdiYlsfDe7BuG2zoL1uQCs/qWIeWsanqkmbYsyTiIiIq0TFs0hpk+fzvTp0xu8b/78+fW+3rp1a+AXJK0yIECleqt/KWTxlnwcdhuXj+3R5GNH9TSB04odBVRWO4mKCPk5gjbl+y17Pdf/Pm8DJw/MaLAsUtqGwtIqdrvLLvu5M8IAfTLM9c15xTidLux2HWMREZHG6NOk+F3fjARsNsgrriSvuKL5J3jJGnh76pBOdE6KbfKxfdITSImLpKLayepfCv22hkPBLwVl7Mgvw2G3ERvpYNWuQr5cp6xTW7Z+jzmJ0SUphsSY2k2wWSmxRDpslFc5ydZ+NhERkSYpcBK/i4uKoHuqmZHlr6xTXnEFH6z4BYCrju3V7ONtNpuno9+ybSrX88Uid7ZpSNckT2bv7/M2aq9TG2b9Hvavs78JIMJhp0dHs89J5XoiIiJNU+AkAeHZ5+SnBhGvLdpOZY2TYVnJjOjuXYtzq0HEEjWI8Mn3m8zf11G9Urn2uN7ERNpZuaOAr9z7nqTtsX4PB2R2OOi+PunuBhG5CpxERESaosBJAsL6gLYup/Ufxiqrnbz8/TYArjqmp9fPG1Un46RsifesjNNRvTuS3iGay8ZYWacN+ntso9a5M079Ggiceqe7G0TkqrOeiIhIUxQ4SUD4c5bTx6uyyd1fQUaHaE4d0tnr5w3pmkSUw05ecSVb95a2ag0ul4tH567nljdX8t4Pu9jrx71b4WR3YTlb95Zit9U22LjuhN5ER9j5YXsB32zMC/EKpSXWu09gNJxxsgInZZxERESaEhZd9aT9GVCnVM/lcrW4I5vL5WLWt1sAuPyoHj51x4uJdDC0WxJLt+1j6dZ8eqXFt2gNYLJWT8zbAMA7y3dis8GQLkmc0D+dEwakc0RWMhGOtn8ewso2De6SRAd3E4GMDjFcMqY7//52K3//fAPH9k1Th702JK+4gvySSmw207jlQLWleso4iYiINEWBkwREr7R4Iuw29ldUk11YTpfkprvgNWb59n38uLOQqAg7l4zp7vPzR/ZMYem2fSzbto/zR2W1aA0Ar7hLBYd0TcTphJ+zi1i1q5BVuwr555cb6RATwbF90zihfzrH909v9PutqnGSXVDOjn2lbM8vZUd+KTv2lbE9v5RfCsqYPKQTM88c0uJ1ttb3m937m3qn1rv9+hP68Oqi7Szdto+Fm/ZydN+0UCxPWsDa39QjNY7YqINnn1mleruLyimuqCYhWv8tiIiINET/Q0pAREXY6Z0ez/qcYtbl7G9x4GQNvD1zWBc6JkT7/Pwje6TyLJtb1SAiv6SSj1ftBuDBsw9naLdk9hSV8/WGPL5en8uCDbnsK63ik59288lP5nH9MhI4rm9Hcnba+Oa91ezcZ4Kl7MJyapyN7xN6+ftt3DJpQL2W0cG0aLPJOI3p1bHe7ZmJMVx8ZBYvLdzG4/M2KHBqQ5ra3wSQFBtJWkI0ecUVbM4tZmi35CCuTkREpO1Q4CQB0z+zA+tzilm/ez/jBmT4/PxfCsr41B2ITDum+RbkDbFakm/KLSG/pJLU+CifX+OtpTuorHEytFuS50NlRmIM543sxnkju1HjdLFqVyFfrcvlq/V7WLGjgA17itmwpxhwwI5d9V4vKsJOVkosWalxdE+NIysljqzUOP708c/syC9jyZZ8Th6Y2aLvtzX2FJWzOa8Emw2O7JV60P3Xn9iH/y7eweIt+SzctJexfTo28CoSbpra32TpnR7vDpxKFDiJiIg0QoGTBMyAzA7MJttzxttXL3+/jRqnizG9UhnUJbFFr5ESH0XfjAQ27ilm2bZ9TBjkW0DidLp4bfF2AC5tpFTQYbcxPCuZ4VnJ3Di+H4WlVXyzMY+v1+ewZdsOjjq8Hz3TEkyQlBpHekI0dvvBe4S+Wp/Lfxdv57tNe0MSOC3aYrJygzonkhR7cMarc1IsFxzZjVe+384T8zYocGojGpvhVFef9AQWb8lXgwgREZEmtP3d7BK2WtNZL3d/Ba8sNPuKWpptslhtyZdu871c75uNeWzbW0qHmAhOH9bFq+ckxUVy2tDO/PHMwVza18lvx/XhnBHdGNUzlczEmAaDJoCj3YHId5v2+rxOf/i+kTK9un59Yl8iHTYWbt7L4i2ajxXuXC6XZ49T/8yDG0NY1CBCRESkeQqcJGCs0qANOcVN7utpyF8+Xcv+imqGdE30OUt0IKtcb9nWfT4/12oKce6IbsRFBTZBe1RvE7CsyS4iv6QyoO/VECvjNKb3wWV6lq7JsZw30jTZ+Pu89UFZV0u4XC5KK6tDvYyQyy4sZ39FNRF2G73Tmgqc1JJcRESkOQqcJGCyUuOIibRTUe1ke773c5SWb9/HW8t2AjDzjCE4GsnQeOvIniYQ+HFnIeVVNV4/L7uwjM/X5ABw2VG+d/TzVXqHaE9WwGrSECx5xRVs3FOMzQZjGtjfVNdvTuxDhN3Gtxv3srQVTTcC6T8LtzHovs/4eFV2qJcSUla2t1dafJOt/K3AaXNeic8nOURERA4VCpwkYBx2G/0yTNZp3W7vyvVqnC7uf381AOeN7ObJFrVGj45xpCVEUVnj5KddhV4/7/XFO3C6TCDRN6Px/SH+dHQf060u2OV6i9xtyAdkdiA5rukGGlmpcZw7ohsAf3fPtgonLpeL57/ZDMCL7q6Mhypv9jcBdE2JJSrCTmW1k18KyoKxtKD6bmMeO3w4eSMiItIQBU4SUP0zfdvn9MaSHazaVUiHmAjuOOUwv6zBZrMxqofJoizxslyvqsbJ60tMU4jLjurhl3V4Y6xnn1Ne0N4TagffWuWCzblhXF8cdhsLNuSxfLvvJZCBtGzbPnbkmw//i7fmk13Y/gIBb63bbUrv+jcT+DvsNnp1NPucNrazcr1l2/K55PlFXPPS0lAvRURE2jgFThJQAzqZEiBvOuvtK6nkL5+tBWDGhP6kd/B9blNjRvV073PyskHEvDU55BRVkJYQxaTBnfy2juYc1asjNptpn76nqDxo77uokcG3jeneMY5zjugKwBNhlnV694f67d9nrzx0y/WsExbW72FT+mS0zwYR1gy2dTn7lXUSEZFWUeAkAeXJOHlRqvfInHUUlFYxILMDl/s5yzPS01lvH04v9nC8ushkmy4YldXk3hB/S4qLZLC79frCIO1zyi+p9AS2o5voqHcgK+s0f10uK3YUBGh1vqmsdjL7RxMoTRpsmop8+OMvoVxSyDidLjbssTrqNV9qajWPaE8NIlwuF3N/zvF8/fWG3BCuRkRE2joFThJQA9x7K7bklVBR3Xhjhp92FXrmJc08czARDv/+aA7ukkRMpJ2C0io25zX9wXBLXgkLNuRhs8HFowPfFOJAnn1OG4MTOC12l+kNyOzg04DgnmnxnDnctGj/R5hkneav20NhWRWZidH84cwh2G2mKcjWvPaVRfHGjn2llFc5iYqw08NdhtcUK+O0aU/7CZzW5xTXa0yzYH1wS2BFRKR9UeAkAdUpMYYOMRFUO11saeTDq9Pp4r73f8LlgjOGdfF6n40voiLsDOuWDMDSZvY5vbbItCAfNyCDrNQ4v6+lOZ59TpuD8yHv+83NtyFvzPRxfbHbYN7aPaza6X3jjUB5b4Up0ztzeFcyEmM4pq8JQj9ceehlnayGLH3TE7zqTGllnDa3oyBz7s+mTK9rciwA327Ko7rGGcoliYhIG6bASQLKZrN55jk11lnvfz/sYvn2AuKiHNw9eWDA1mK1JW+qQUR5VY2nFfqlY4KfbQKzzgi7jR35ZUHZk+HN4NvG9E5P4Az3YOBQd9grLKvi8zV7ADhruNl/ZQ0tPhTL9Wr3N3nXEbK3ewhu7v4KisqrArauYLLK9H59Yh+SYiPZX17NyjAI8EVEpG1S4CQBZ7VCbihwKiqv4s+frAHgdyf3o1NSTMDWMdKLBhEfr8qmoLSKrsmxnDggI2BraUpCdARDuyUBgd/nVFBau7+pJRkngOkn9cNmg8/X5PjU7t3fPv0pm8pqJwMyOzCws/mZmzS4E5EOG+tzir1uid9erM9xd9TzYn8TQIeYSDITTUOW9tAgIqeonJU7C7HZYOLgTI51Zx8XaJ+TiIi0kAInCbgBTbQkf3zuBvKKK+mdFs9Vx/QK6DpGdE/BZoOte0vJ3V/R4GNe+d6U6V0ypnurB++2hrXPaWGA5zkt2pKPywV9MxJIS2hZF8O+GQlMGWoyO7e//SOFpaHJVljd9M46ois2mzl2SbGRnNDfBMAfrNzV6HPbI1866lk8DSLawT4na3j18KxkMjrEcFw/K3DSPicREWkZBU4ScNYZ7wNbkq/bvZ+XFm4F4PdnDA5497qk2EhPENdQ1unnX4pYvr2ACLuN80d1C+hamnN0nXlOLlfzXQBbympDPqZXy7JNltsmDqBjfBQ/Zxdx+axFFJYFN3jaVVDm2atlNaywnOH++sOV2QH9uwwnVTVOT3e8fj4Mb/Y0iGgHnfWsMr3xA013xeP6pwOwYkdB0H8+RUSkfVDgJAFn7bHYkV9GSUU1YNoE3//BT9Q4XUwanMnx7g81geZpS97APqdX3U0hJg3pREaHwJUMemNEjxSiIuzkFFU02lTDH3wdfNuY7h3jePXaMaTERfLjzkKumLWY/UHcJ/PBCrOH6ajeqXRxNwKwjB+YQWykg+35pfx4iOxv2ba3hKoaF/FRDk9jBG94GkS08VK94opqT1fKiYNM4NQ1OZY+6fHUOF0Bz+SKiEj7pMBJAi41PsozzHaDuwRo9o/ZfL85n+gIO/932qCgrcXTIGJb/cCpuKKa99ylXpeN8e8MqZaIiXQwonsyAN8F6ENeYWkVP2cXAS3f31TXYZ0SeeWaMSTFRrJiRwFX/nsJxe5AOZBcLhfv/mAaepztHspbV1xUBCcPNOV6h0p3vXW73dmmzA7YfSg57ZPRPmY5fb0+l8oaJz07xtE3o7ZU8bh+5gSN9jmJiEhLKHCSoBhQZxBuSUU1f/rINIT4zYl9g9ry28o4rd5VSFll7Vypd3/YRUllDX3S4znKD0GEPwR6n9OSrWZ/U+/0eL9l2AZ3SeLVa8aQGBPBsm37uOrfSyitDGzwtCZ7P+tziomKsHPKkM4NPsbq/Df7x2yvBiC3dVZZbP9M7/c3AfRxd9bbtre0Tbft/txdpjdhUKZnvxvA8f21z0lERFpOgZMERd19Tv/8ciO7i8rJSo3lVyf0Duo6uqXE0ikxhmqnixU7CgCTsXjV3RTi0jE96n3QCiVrn9PCzXsD8mHfKtNrSRvypgzpmsTLV4+hQ3QEi7fmc9WLS+oFqf5mzW4aPzCDpNjIBh9zwoB0OsREsLuonCVbG++q2F6s320FTt7vbwLokhRLTKSdyhonO/eVBWJpAVdd4+SLdaYt/YRBnerdN6ZXRyIdNrbnlx6SQ5FFRKR1FDhJUFidveav28PzCzYDcN+UwcREOoK6DpvNdlBb8v9v776jorq2OAD/7nR6772KoKCACjaiomjUaCwxxthiL4nGPJOYWNI18aWZ2JIYk2iiPjXWWGLFiggoiCBFKaL03ply3x/DjKIgbWAY3N9arKUzd2bOcAa4+56z945KL8SdrFKI+ByM91VvUYjHedsaQlvARUF5DRJzVF9KW1FMoS1W2HzsDPH7rN7QFfIQdq8As/+4jiqx6oMnqYzFodrASdG7qT5CHhchXvKT6Oehp5Pi89LUHk4KHA4DJ1PN3q53PbUQRRViGGnzldtdFXSEPOWqM23XI4QQ0lwUOJF2objyfTdXnrQ+qIsZgruqp0+Sv6JARG2e086wdADAaG9rGGjXv2KhDgIeB/61OVmKRHdVKakS4/ZDeaEEVa84KfjaG+G3mb2gLeDicnI+5u6IVHnwFHYvH9kl1TDU5jfad0uxXe/YrSyINXgbWmOqxFLlakqXZq44AY8a4WpqgQhFNb3BHhbgcZ/+E6fIc7pA2/UIIYQ0EwVOpF24PXYCJ+BysHq0l9q2xCkKRESmFSKvrBr/3MoEALweoP6iEE96VJZctYFTRGoBZCzgaKLdpk2H/R2NsX1GL2jxubiQmIsFOyNRLVFd8KTo3TSyu1Wj5ez7upjAWEeAgvKaNiu40RHczS2DjJWX31cUZWkOFzPNXXFiWRan4rMAyPOb6jOwNnC6eje/UwfQhBBCVI8CJ9IudIU82BnLyyLPGegEJ1MdtY3Fw1IP2gIuSqsk+OJYPGokMnS3MYCPnaHaxtQQReB0LSUfUhXmOT3q39Q2q02P6+Nsgm0z/CHic3AuIReL/ryBGknrT1gra6Q4ESs/Sa6vmt6TeFwOXuxeu12vE1fXUza+tdBr0cUJRYEITQycErPLcL+gEkIeR1kI4kle1vow0uajrFqizHMkhBBCmoICJ9Ju1ozywuz+Tlg8yE2t4+BxOfC1l2/X+ztKvmIxpY+9OofUIC9rA+iJeCitkii31qlCWEptfpNL+1QQ7Otiil+m9YKQx8Hp+Gy8uSuq1Vf7T8Vno6xaAlsjLWXeSmNe8pEHWCdjs9ok5+pZ2mt1IzFbHvC4Wzavop6CYsWpvbbqyWQsvjpxB9supbT6uU7FyQPp/q6m0Bbw6j2Gw2HQX1GWPJHynAghhDQdBU6k3QR7WmDlKE9oCdq3IER9Hj/R1hPx8FIPazWOpmFcDqNcFVLV9rKyagliH7RtflN9+ruZ4qdp/hBwOTh5OxtLd99sVclrRd+tl3vaNHllxd/BCJb6IpRWSxDaTifNpVVizNweDt9PTuFyctvn1Sgq6rUkvwmAcjU4v7wGRRU1KhtXQ/6Ny8am83fx6dE4RLSy4qEivym4gW16CgPc5KtR6shzSsouxdRt15Ql0wkhhGgOCpzIc8nf8VHgNN7XtsGr0x2BqvOcIlILIJWxsDPWgrWhlkqes6mC3M2wdaof+FwG/9zKxNv/i27RFsT8smpl4DPmGdX0nsThMBjlLe/11B7b9XJKqzBpaxjOJeSitFqCxX9F4X5BRZu+pqKHk1sLAycdIQ9WtXlvd9t41YllWWwOvav8/6dH41pcej+7pArRGcVgGCgbHjdEETjFZBS1S3CoUFYtwbwdkbiYlIcvjsWDZTt/TzFCCOlMKHAiz6We9kbKYgKvddBtegp9XeWB0/WUApXkBl1TbNNrx9Wmxw3yMMemKX7gcRgciX6I5fuim32yfDQmE1IZC29bA7iaN29LmmJ18XR8Nsqr2645773cMozffAVxmSUw1RXAw1IPhRVizNsR2WZ9rcqrJcr+S83t4fS49ioQcfVePqLvF0HI40BHwEV0RjEORT9o0XOdjpev4PSwM2y0obOVgRbczHUhY1VfeKUhLMvi/f0xuFdb8fBeXjluUI4VIYRoFAqcyHNJV8jDtun++GmqX6tOMNuDu7keTHQEqBRLEZNR1OrnC7tX2/jWWT2BEyCvePbD5J7gchj8HfUAHxy41azgSVFN71m9mxrS3cYADibaqBLLlCfbqnbzfhEmbLmK+wWVcDDRxv4FffHrjF4w0REgLrMEK/6OaZPVhqQceaBjpieEsY6gxc/TXgUiNp+Xrza94m+HhYNcAQBfnUhoUWCp2KbXUDW9JynKkrdXP6edYWk4GpMJHodBj9pCNPsiM9rltQkhhKgGBU7kuTXAzQzDapuidmQcDoMAZ9Vs16uokeBWhiK/qX0KQzRkRHcrfDupBzgMsPv6faw5fLtJwURKXjlu3i8Cl8NgtE/zc9MYhsFob/njjkRnNvvxjTl3JweTfwpDQXkNutsYYP+CvnAw0YG1oRZ+fM0XXA6DgzcfYvvlVJW/dmvzmxSc26FAROyDYlxMygOXw2DuQGfM6u8EG0MtZBZX4efaJtlNVVYtUfY6G9bEwElRde9CYl6bb5mLySjCp0fjAQDvj/DAuyFdAMi3i7Z3kRJCCCEtR4ETIRogUJnn1Lpk9si0QkhkLGwMtWBnrK2KobXKSz7WWD/BBwwD7AhLwydH4xo9iVUUhRjgZtqiPkXAo+16oYk5KK4Qt+g56rM34j5m/xGBSrEUA9xMsXtuAEx1H40x0MUEH77YFQDw+bF4XFXxNrFH+U0tq6in0B5b9bbU5jaN8raCnbE2RHwu3h/hAUC+EpVdUtXk57qQmIsaqQyOJtrKsTemj5MJBFwOHhRVIiWv7QLE4goxFv4ZhRqpDMM8LTCrvxMCnE1gY6iF0ioJ/qUiEYQQojEocCJEAygKRESlFbXqCvWjbXrqXW163Hg/W6wb1x0AsP1yKtaduNNg8MSyLA7efFRNr6XcLfTQxUIPYimLk7ezWvw8j49r47lkLN8XA6mMxcs9bbBtei/oCJ8uOjKznyNe7mkDqYzF4r+i8KCostWvr/B4D6fWcK7dqpeeX9EmZdRT88pxrLbx9PwgF+Xto7yt4GtviEqxFOtPJjT5+U4/tk2vqRUWtQRc9HKSF4m50EYVFlmWxTt7o5FRWAl7Y22sn+gDhmHA4TAY7yv//O6n7XqEEKIxKHAiRAM4merAUl+EGqkMUWmFLX4eRePbADXmN9VnUi97fDa2GwBga+g9fHsqsd7jbtwvQlp+BbQF3CbnsjRktE9tdb2Y1lXXk8pYfHT4tvJEf16QM76e6KMsPvIkhmHwxcvd4WWtj/zyGszfEamy7VqKwMndsnWBk6W+CNoCLiQyFultUAXwp4v3IGOBQV3M0NVKX3k7wzBYNcoTALA/KkNZNv9ZJFIZzibkAACGejZv6+2jPKe2KUv+88V7OB2fDQGXg01TfGGgxVfeN97Ptva1c5FV3PTVNUIIIepDgRMhGoBhmMe267Vse1dljRTRtcUl1FVR71leD3DAmtHyk+YNZ5Ox4UzSU8cotukN97JsdQl5RX7U5eQ85JVVt+g5qsVSvLkrCr9fTQMArBrliRUjuoLDefaqh5aAiy2v+8FIm49bD4rx4YHYVufZFFXUILtE/j7cmllp8EkcDqNcdbqbo9rtejklVdgXIV9lWfCC61P397Q3wpge1mBZNGnr5vXUQhRViGGsI2hyI2QFRVnyq/fyVVKx8nERqQX48oQ8mF492hPdbAzq3O9gooNejkaQsY+KnRBCSFNJZWyL/3aRlqPAiRAN0do8p6j0QoilLKwMRLAzbt/+TU01s58TPnhRnufyzalEZR4MAIilMmXvpbGt2Kan4GCiAx9bA8hYKLeNNUeFBHjjjygcu5UFPpfBhsk9Mau/U5Mfb2esjR9f8wWHka+u7AhLa/YYHpeYLQ9wbAy1oCfiN3J045xNawtEqDj/59fLqaiRyuDnYIRejvUHOu8O94CQx0F4SgFO3n52DpCimt5gD3NwGwlYn9TVUh+mugJU1EgRld7yldwn5ZdVY/FfNyCVsRjTwxpTGmh5MKF21Wl/VAb1dCKENFlxpRgTtlyB/2ensf7knRb1QyQtQ4ETIRpCkecUk1GMshb0H7pWm98U4GzS5DwQdZg70AXLa6uOrTt+B9supQCQ56EUVohhpidUfi9aS7Hq1NxmuEk5Zdhwm4vw1ELoCnn4fWZvvNSCCn/9XE2xYoS8WMQnR+IQXttjqyWU2/RaWRhCQVkgQoUrTiVVYvxZGyAuCHJp8HNoY6iFuQOdAQBrj8ejWlL/VkaWZXEqXp6jFty1+Vs3ORwG/V3lq06qKksulbFYuucmskqq4GKmgy9e7t7g+3yxuxVEfA6Sc8oQndH4tkRCCCmuEGPqtmu4kV4EANh47i5mbA9HQXn7NfN+nlHgRIiGsDXShr2xNiQyFtdTm3+CHVab36TuMuRNsWiQK94a4gYA+PRoHP64mqrczvSSjzV4XNX86hrlbQ2GkW/3eviMIg0syyL2QTG+/jcBwd+E4sUfriCzgoGZrgB75gWgb+3Jd0vMHuCE0T7WkMhYLPwzEpnFLSsWoar8JgXFVj1VrjjtDEtDabUEbua6GOxh/sxj5we5wExPiLT8Cvxxpf7VuMTsMtwvqISQx1GWF28uVec5bTyXjItJeRDxOdg0xa/eAiEKeiI+RnST59rti7yvktcnhHReRRU1mLItDDEZxTDS5uP9ER7Q4nNxMSkPozZcxE1qqt3mKHAiRIME1hZ1aG4Z6yqxVPkLVZ2Nb5vj7WA3LHhBXnFt9aHbOBErX1loTTW9J1kaiNDLUR5IHn2iSIRMxiIyrQCf/xOHgevPYdQPl/DD2WQk55SBz2XgaSjDnrm94WVtUN9TNxnDMPhyfHd4WOohr6wG83dGNbjC8iwJtT2c3M1VEzgpVpySc8pUso2sSizFr5dSAciDosbywHSEPCwfJl953HA2Cfn17OU/FSf/TPR3NW1xzpsiz+nWg+JWX7G9nJyHb0/LC5t8NrY7ujQhiB3vK9+ud/gm9XQihDSssLwGr/18DbEPSmCiI8CuuQGYH+SCg4v6wdlUBw+Lq/DKlqv481oabf1tQxQ4EaJB+ro2P8+puFKMDw7cQo1UBgt9IRxN1N+/qSkYhsG7IV0wuzZvSCJj4WquCy9r/UYe2TyPtutlQiKV4XJyHlYdjEXA2jMYv/kqfr6YgvsFlRDxOQjxssC3k3wQ9t4LmNdVBjsj1XwvtQU8/DTVHwZafETfL8Lqg01rBqzAsuyjUuQqWnFyMtUBw8g/P6rYArI/KgN5ZdWwNhAp+2g1ZryfLTyt9FFaJcF3p58uFnLqsTLkLWWuL4KHpR5YVh74tFR2SRWW7L4BlgUm+dsp85caE+hiAmsDEUqqJDgTn9Pi1yeEdF4F5TV47ZdriMssgamuPGjysJT/LexiqYdDi/shxMsCNVIZPjwQi+X7YuhCTBuhwIkQDaJYcbr9sKRJjVtP3s7C0G9C8XeUfJvbwhdcO3R+05MYhsGHI7tiZj9HAMC0QAeVj//FbpbgchjcelAM/89PY8ov17AjLA05pdXQE/Iwpoc1Nk/xRdSqodg61R8v97SFvlbriy88yd5EGz9M7gkOA+yJuI+/wtOb/Ni8shoUVojBMIBrKyvqKWgJuLA2kBcRae12PYlUhq2h9wAAcwY6g9/ErZZczqPy5H+FpyOpNjgE5IFKdEYxGAYY0oL8pscpVp1amuckkcrw5q4byCurgYelHj4e49Xkx3I5DMbVrjrRdr22l19eg4xy0BV5ojHyy6rx2s9hiM8sgamuELvmBMD9iV59eiI+trzuh/dHeIDDAPsiMzBu0xWk56u+ncTzjgInQjSIub4Irua6YFkgLKXh7Xq5pdVY9GcU5u2IRE5pNZzNdLB3fiCm93Vsv8GqCMMwWDPaC1GrhmJqgIPKn99EV6gsEFBUIYaRNh+T/O2wfUYvRKwKxvev9sSI7latLn/eFAPdzbA8RF5VcOXBWLz04yX892QCwlMKntmIVrHa5GiiAxGfq7LxuJirpkDE8dgspBdUyL+3veya9dhAFxMM87SAVMbi82PxytsVq0097Axhpids1fgez3NqyQn116cSEZ5SAF0hD5um+DZ7DhQ9nUITc5FTQj2d2srVu/kYseEy1sfwMPLHK/jtcgqKKxu/AEWIuuSVVeO1n6/hTlYpzPSE2D03AG4NNDhnGAbzg1ywc1YfmOgIEJdZglE/XMS5O7SSrUoUOBGiYZ6V58SyLPZHZiD4m1D8cysTXA6DhS+44NhbA5S5PJrKWEfQZqtln7/cDctDuuCvOX1w/cNgfDnBG4M8zCHkqS4Iaar5Qc6Y3NsOLCuvoPjjuWS8svUqfD85hXk7IvDntTTcf6IprSK/qbX9m57kbNr6AhEsy2LzeXlZ+Rl9nVoUgK54sSv4XAbnE3IRmihfFTod3/ptegq9nYwh5HGQWVyFu7lNDxJZlsWW0LvK9/fleG84mzV/DpxMdeDnQD2dACD2QTE2nktWaYUwlmWx42oqpm67hsLalfqknHJ8dCQOfb44jeV7o3EjvZBWocgz1UhkSFVxe4ZnyS2txuSfwpCQXQrz2qCpKTsK+rqa4uhb/dHDzhAlVRLM/O06vjmVSCXLVaTtL6ESQlSqr4sJdoSlPZXn9KCoEh/8fUt5YulppY+vJng/1XiTPM3WSBuLBj3djFUdGIbB2nHeeDvYHReS8nAhMRcXk+Sl2E/ezlb2NXI21cFAdzMMdDdFTG1jY1XlNymoYsXpQlIe4jJLoC3gYlpgy1YMnUx1MC3QEdsupeCzo3HosaAvriTLLxwMU0HgJOJz0dvJGBeT8hCamIdpfRrPTyqtEmP53hicuC0vUDF3oDNGelu1eAwT/GwRmVaI/VEZmDvQWaO21KpKcYUYM7aHI6+sBtsvp+KLl7thmJdlq56zRiLDmsO3sat26+tob0v04mdAYtkNuyMykJhdhr2RGdgbmQFPK3281sceY3vaQPcZ1RBJx5SWX47PjsZBVsyBWWohejubtroCa7VEiktJefjnViZOxWWjtEqClSO7YvYAZxWNun45JVWY/HMY7uaWw1JfhF1zA+BUeyGrKawMtLBnXgA+OxqPHWFp2HAmCdH3i/DdpB4w0hG04cg7P/rNQIiGCahdcUrMLkNuaTVMdATYeS0NXx6/g/IaKQQ8DpYMccPcZuSSkI7HXF+ECX62mOBnC5mMRezDYoQm5OJCUi6i0otwL68c9/LK8duVVOVjntz33loutSXJm7MK86TN55MBAJN727fqD/Zbg93wd1QGknLK8OauG6iRyuBkqqOs/tdaA93McDEpDxeTchsNnBKzSzF/RyTu5ZWDz5VvJW2oyW1TjfS2wkeHbyMxuwy3HhTD29awVc+nib48eQd5ZfKVpryyaszdEYlxPW2wZrQXDLSbn1eYV1aNhTujEJ5aAIYB3hvugTcC7XD8eAZeDLDHzP7OiEwrxF/X0nH0VibiMkuw8mAs1h6Lx0s9bDCljz1deNIQLMvivf0xtW03ODiz7Tr0RTwMdDfDYA9zBLmbwUS3aVt6q8RSXEjMxfHYLJyOy0bpE30TvzudhDE9bFq9Rbgh2bVB073cclgZiLBrTgAcmxE0KQh5XHw6tht62hvigwPyi6qjf7yEffP7wtJA1AYjfz5Q4ESIhjHSEcDTSh9xmSXYHZ6OC0m5uJ5aCADwdzDCuvHeKisQQDoGDoeBt60hvG0N8eYQN5RUiXElOR8XknJxITEXGYWVEHA56GlvqNLXVQQl9wsrUS2RNnvrYlR6IcLuFYDHYTCrtjpiSxlo87E02B1rDt/GhdpV1aGeFipbmRngbgocA8Lu5aNa0nA+2aGbD/D+/luoFEthZSDCpim+6Glv1OrX1xfxEeJlicPRD7EvMuO5C5wUAQwA7JjVG5eS8/DzhXv4+8YDXL6bh3XjvTGoy7N7fz3u9sNizP0jEg+KKqEn5GHD5J4Y5GEOsfhRThPDMPB3NIa/ozFWjfLE/qgM/BWejnu55dgVno5d4enwtjXAgiAXjOje8tVE0vZOxGYh7F4BhDwOvAwkuFchRFGlGEdjMnE0JhMMA/jYGmJQF3MM9jCHl7V+nZYIVWIpzifk4titTJyJz0Z5zaOKdBb6QozoZoUR3SzxxbF4RGcU49vTifji5e4qfx9ZxfKgKSWvHDaGWtg1JwD2rayEO87XFh6W+pi/MxLpBRV4Z+9N7HijT6MtIUj9KHAiRAMFupggLrMEX5+S94zREXDx3ggPvN7HgX4ZPgf0RXwM72aJ4d0swbIsUvLKweUwsFVReXQFcz0hdIU8lFVLkJ5f0WBSckO21Ob+jO1pA2tDrVaP57U+9vjjairu5srzDIJbWU3vcV0s9GCmJ0RuaTWi0gufur9GIsMXx+KVK3z9XU3x/as9mnwVuykm+NnicPRDHI5+iA9HdlVLjp06iKUyfHjgFgBgop8tBriZYYCbGYZ5WuI/e6ORkleOmduvY5K/HVaO6go90bNXn/6JycQ7e2+iSixflfx5mn+jF5OMdASYPcAZs/o7IexeAf4KT8eJ2EzEZBRjwZ9R2Dc/EP4anifaWVWJpcrCMXP6O8KtOhEhw1/A7awynL2Tg3N3chGXWYKb94tw834Rvj2dCDM9IV5wN4OPnSHC7uXj7J0cVDwWLFkZiDCimxVGeluip52R8u/qhyM98crWq9gdno4ZfR1VusqfWVyJyT+FITW/AjaGWtg9NwB2xqr5ne5prY/tM3th1IZLuJycj22XUjBnYNtuN+ysaB8PIRqon+ujJrYD3c1w8u2BmBboSEHTc4hhGDib6cLBpPlbOZr23C3brpecU4p/ayvfzQ9SzR9oPpeDlSPl5cnN9ITwc2j9So8CwzDKsuSXkusWXlFcBVYETYsGueD3N3qrNGgCgH6uprDUF6GoQoyzz1FPp+2XU3AnqxRG2nyseLGr8nY/ByMce2uAsh3Bnoj7GP7dxQb7bclkLL7+NwGL/opClViGge5mOLiwX7NW4BmGQaCLCX6Y3BNhK4ZgRDd5jpWisXFnxrIsLifnIbO4Ut1DaZZtl1KQUVgJS30R5gxwBCAv8+/nYIzlIR44tmQAwlYMwdpx3THM0wLaAi5yS6uxNzIDKw/G4mhMJipqpLAx1MKcAU74e2FfXH5vMFaP9oSfg3Gdv6u9nYwxopslZCzw+T/xDYyo+cRSGebtiERqfgXsjOX5SaoKmhRczHSV7R3Wn0zA7YfFKn3+5wWtOBGigYLczfF2sDuczHQw2tvquUwkJ+3DxUwXMRnFylWeplL0bRrmaQFXc9VdlR3kYY7tM3vBykAEroovFAx0M8PfUQ9wKTkfXo7y267czcNbtT2a9EQ8fPNKD5VU8quPvKeTDTadv4t9kRnPxfawjMIKfHtK3tx4xYtdYfxEHpyWgIs1o70Q4mWJ5fuicb+gElN+uYapAQ54f4QHdGqLOJRVS/D2npvKMvVzBjjh/RFdW/UZMdEVYuUoT5yOz8bl5HyE3ctX5piqQpVYiklbryKjsBK9HI3Rx9kYfZxM4GGp1+4XwSpqJHhv/y0ciX4IS30RzrwTpPzedmTZJVXYeE6eR/n+CI8Gq3ZaGogwubc9Jve2R7VEiusphTh7JwexD4vR084QI7pbwcfWoEl/S98f4YHT8dkITczF+YQcvNCMLaQN2XTuLmIyimGgxceuOQEq3z2gMLm3Hc4l5OBUXDaW7L6JI4v7Q0vwfKxsq0rH/6kghDyFy2GwJNhN3cMgz4GWFIh4WFSJgzflZbXnv+Ci8jE1J9elOfrV9vOKyyxFiTXw08UUfH0qCTIW8LDUw5bX/VqUpN0c4/1ssen8XZxPzEVuaXWbJaB3FB8djkOlWIreTsaY6NdwUY4AZxOcWDIQa4/HY2dYOnaEpSE0MRf/negDC30h5vwRgcTsMgh4HKx9ubuyN1Zr2Rhq4dVe9tgRloZvTiViz9wAlV2o+uXiPURnyK/6n7idpazQaKDFRy9HYwTUBlKe1voqv0jwuPT8CszdEYE7tW0Nskqq8MPZZLw/wkPlr5WYXQoHE22VbUP98sQdVNRI4WtviDE9rCGRSBp9jJDHRX83U/SvXWFuLgcTHczo64ifL6bgi2Px6O/auup9tzKK8cNZ+cWDT8Z4tVnQBMhXVL8c742b9y8gOacMa4/H45Mx3drs9Toj2qpHCCGkQYq+RPcaWXGqlkiRV1aNlLxy/HA2CWIpiwBnY/iqoHBCezHTE8LTSh8A8MNtLtb/Kw+axvW0wYGF/do8aALkK3w97Q0hlbE4dLNz93Q6eTsLp+Ozwecy+Hxst0YDEh0hD5+N7Y6ds/rA2kCE9IIKTPrpKkZuuITE7DKY6wmxZ26AyoImhYWDXCDgcRCeUoAr9fTPa4nskipsqs0BXB7SBctDumCguxl0BFwUV4pxOj4bn/0Tj9E/XkKPj//FzO3h2Hz+LqLSCyF5RjPs5rqYJK+0dierFKa6AiwZIr8gt+3SvVZV06zPrvB0DPv2AsZuvILy6sYDnMbcvF+Ev6PkPyNrRnu1686LxYPcYKjNR2J2GfZE3G/x81SJpXj7fzchkbEY6W2Fl3ysVTjK+hnrCPDfiT4AgD+upuHsnew2f83OhFacCCGENEhRWS8hqxT/2RuNsioJSqvFKK2S1H6JUVIlQU09legWvNAxemM1xwB3U8RlliCnigGfy2D1aC+83se+XU/KJvjZ4kZ6EfZGZGBWf6dOuRW3vFqCjw7fBiDvgdWcwiP93Uxx4u2B+OxoHP4XkYGyagl87Azx01Q/WOirvsyylYEWXuttj9+upOKbU4no62LS6jn578kEVNRI0dPeEAtfcAHDMFg0CJBIZYh9WIJr9/IRnlKA8NQClFZJcC4hF+cS5NUkrQ1EeHOIGyb42ba45QTLsth64R6+OnEHMhbwsTXAlql+sDLQQkxGEc4l5OLjI3H4fWYvlXz+Mgor8NnROABAfGYJlu65ia2v+7V4SyLLsvj4iPzzM97XFj52hq0eY3MYaPOxdIgbPjoSh29PJeIlH+tGi5bU578nE5CcUwYzPSE+G9P4xQNVCXI3wxv9nPDr5RS8uy8Gx5cM7PSr26pCK06EEEIa5GCiDQGPg0qxFPsiM3DidhYuJ+cjJqMYKXnlyCurqRM06Qp5sDKQ96Aa2MKtMOo0vLbhqqGAxV+zemFqgEO7By6jvK0h4HGQkF2K2w9LmvXYiNQC/PdkAv69nVVvMNtRfHsqEZnFVbAz1sLiQc3fdqwv4uOrCT7YOasPVo7sij1zA9okaFJY+IILhDwOItMKcSGp/uIUTRX7oBj7ojIAAKtGedb5fPG4HPSwM8S8IBdsm9ELN1cPw9E3+2PVKE8M87SAgRYfD4ursOLvWxj6TSgO3XwAmYxt1utX1Ejw5q4bWHdcHjRN9LPFnnmBsDKQV75cPdoLAi4HFxJzlTljrcGyLFb8fQvlNVJ0sdCDgMfBqbhsrP83ocXPeejmQ9xIL4K2gIt3h3dp9RhbYkqAA5xNdZBXVoPNtauHzRF2Lx/bLqcAAL4c373dG9O+O7wLPCz1kFdWg3f3RYNlm/c5el7RihMhhJAGifhcbH3dD+GpBdAT8aAn4kNfxFP+W1dY999tmYvRHnraG+HY4r64FX4BPdr5KraCgRYfwzwtcDQmE/siMxptwsqyLC4k5WHjuWSEpxQobzfWEeAlH2uM97VFNxv9DrNydfthMbbXVij8dEy3ViWntyZXpTnM9UWYGuCAXy6l4JtTiRjoZtqi7yfLsvj0aBxYFnjJx7rRraxcDoNuNgboZmOAWf2dUCWW4s9r6dh0Lhmp+RVYsvsmNp27i2XD3DGsCX3NHs9n4nEYrBntidefuDjgZKqD2QOcsOn8XXz6TxwGuptBxG/5HO25fh8Xk/Ig5HGw+XVfxGQUY+mem9h8/i5czXSbvbWyokaCdcfvAAAWDXJt04D5WfhcDj54sStm/xGBXy6l4LU+9k3OTyqtEuM/e6PBssCrveww2KNtCs48i4jPxXev9sBLP17GuYRc7AhLw7RAx3Yfh6ahFSdCCCHPNMjDHO8N98DCF1wxNcABY3rYYLCHBXo5GqOrlT5sjbRhoMXX+KBJwc1CFyI1F5qaUHsyeejmgwZXjmQyFidiM/HSj5cx/ddwhKcUgM9lMMzTAmZ6QhSU1+C3K6kY/eMlhHx3AVtC7yKruKo938ZTpDIWHx6IhVTGYmR3K5VUJGsv84JcoMXnIvp+Ec4ltKxc/Mnb2biWIm/U+l4Lii+I+FzM6u+EC+8OwvKQLtAX8ZCQXYp5OyIxduNlXEjMbXDl4ELi4/lMQuyaG4CpgY71BluLB7vCykCE+wWVygqZLZFZXKks2/3OMHc4m+libE8bLB4k38a74u9biEwreNZTPGXL+bvIKqmCrZFWqxtrt9aQruYIdDZBjUSGr040fQXts6PxyCishK2RFlbWlghXBw9Lfayo/Rx+/k88krJLW/xc5dUSFJbXqGpoHRYFToQQQkgHM8DNDBb6QhRWiHH2Tt2TdLFUhr+jMjDsuwuYvzMKtx4UQ8Tn4I1+8hPqn6b54+r7g7F9Zi+M9rGGkMdBYnYZ1h2/g77rzmDqtms4eOMBKh9r+NledoWn4+b9IugKeVg9Wn0njC1hpifEtL4OAIBvTiU2e2tTtUSKtcdrG7UOcIZNK5pC6wh5WDTIFRffHYxFg1ygLeAiOqMY034Nx6s/hSEi9VEwwrIstoTexYzt4SiuFMPHzhBH3uyHXs9o6Kst4OHDkfKeWpvOJ+N+QUWzx6jYoldaLUEPO0PM6v+on9uyoe4I8bJAjVSGuX9EIqOwac+fUViBrRfkgdyHL3Zt1UqYKjAMgw9HdgXDAIejH9bbPPtJZ+KzsSfiPhgG+HqiD3TVXPZ9Rl9HBLmboVoiw1u7b6Ja0rzfCyVVYnx7KhEBX5xB33Vn63z2OiMKnAghhJAOhsth8HJP+arTvkh5PkyVWIqdYWkY9N/zWPa/aCTnlEFPxMPiQa7Khp2KPBUel4NBXczxw+SeuL4yGOvGdUdvR2PIWOBiUh6W7rkJ/89OYfneaFxKykNidilS8sqRUViBnNIqFFXUoKJGArFUprLch5zSKnx5Qr7F6j/D3NW2xao15g10gY6Ai9gHJc3O//njShrS8itgpifEAhWV6TfQ5mN5iAcuvDsIb/RzgoDLwbWUAkzYchUztocjIrUAix/LZ5rkb4f/zQtQfk6eZWR3KwQ6m6BaImtRs9f9UQ9wPiEXAi4H6yd411mR5nAYfDupBzyt9JFfXoPZv0egrAmV9tYdv4NqiQx9nIwxvLY5sbp1szHABF/5z+pnR+Oe+fNSUF6D9/bfAgDM7u+EPirsC9ZSDMNg/URvGOsIEJ9Zgv+ebNrKWUWNBJvOJ2PAl+fw/ZkklFZLUCmWYvYfEUjOUW1Fxo6EcpwIIYSQDmiCnw22hN7F+YQc/HAmCTvC0pBTWg0AMNER4I3+Tpga6AD9Rqp56Yv4eLW3PV7tbY+0/HIcuPEAf0c9QHpBBfZGZmBvbWDWEIaR53MIuBzwuQz0RPIcrEm97JpVDe/zf+JRWiVBdxsDTNXQXApjHQFm9HPExnN38e3pJAR3tWhSZbj8smpsqO3Vszyki8qby5rqCrF6tCdmD3DCD2eT8L+IDJxPyMX52kp8fC6DNaO9MKUZFSIZhsFHL3nhxQ0XceJ2Fi4m5WKAm1mTHptdUoVPaqveLR3qVu/nRFvAwy/T/TFm42XcySrF0t03sHWqf4NbfsNTCnA0JhMcBlg92rPD5OwBwH9CuuBoTCai0otw7FYWRno/3byaZVmsPHgLeWXVcDPXxTvD1FPUoj7meiJ8Od4bc/6IwM8XUxDkbt5g7qDiAs6W0LvIK5NvzXM118VbQ9yw/XIKbqQXYfqv4TiwsC/MNfDiSGNoxYkQQgjpgFzN9eBjZwiJjMXXpxKRU1oNKwMR1oz2xKX3BmPRINdGg6YnOZjoYGmwO0KXv4C98wPxai872BhqwVhHAD0hD0IeB0+ej7IsUCORoaxagsIKMdILKvDLpRQM/fYCXt50GbvC01FaJX7m615MysWhmw/BYYAvXu6u0flwcwY4Q1fIQ3xmCU7WNq1tzLenE1FaJYGXtb5ydaItWBtqYe04b5xZFoSxPazBMPKgatecgKeKQDRFF0s9TAuUb0/86PDtJlVqZFl5HltJlQTetgaYO8C5wWOtDbXw8zR/CHkcnI7PwVcn79R7nFT2qPz4pF728LJ+dsGU9mahL8L8IPkq4roT8agSP73d7XD0Qxy7lQUeh8E3r/RQ+zbDJw31tMCUPvYAgHf23nwqX6lGIsOOsDQErT+Hz/6JR15ZDRxMtPHdpB44uXQgXvKxxrbpveBkqoMHRZWYsf16o78XNBGtOBFCCCEd1Kz+Tnhr1w04mmhjwQsueLmnLQS81l/zZBgGvRyN681zYVkWUhkLsZRFjUSGGqn8SyyRQSyVISWvHHsjM3D2Tg5upBfhRnoRPjkShxe7W+EVf1v0djKuc4JeJZZi1cFYAMC0QEd0t+1YJ73NZagtX+3bcCYJ355OxDAvy2cGgonZpfjrWjoAefnxlvYuag5HUx1892pPvDvcA/pa/Fbl0SwNdseR6Ie4m1uO366kYO7AZ28zPBz9UNnYeP0EH/Aa6TXVw84QX03wxpLdN7E19B5czXQx0d+uzjH7Iu/j9sMS6Al5eGeYe4vfS1uaM9AJf4Wn4X5BJX6/kop5QY++T1nFVcqfgTcHu3XYn4GVIz1x9V4+7uWW4/2/Y7DldT9IZSz+jnqA788k4UFRJQDAxlALbw1xxTjfur3EjHUE+H1mb4zbfBlxmSVY+GcUtk3vpZLfWR1F53knhBBCSCfzko81wj8cgjPvvIBJvezb5QSEYRjwuBxoCbgw0ObDTE8IG0MtOJrqwM1CD8O8LPHzNH9cXTEYK0Z4wMVMB5ViKfZHZWDST2EY/HUoNp1PRnaJvILfpvN3kZpfAQt9YYc96W2uWf2doCfiITG7DP/cynzmsZ/9Ew8ZC4R4WSCgnXNarA21Wl18wECLj3eHyyuvfX86STmv9ckprcKa2sbGbw52QxfLpm3lHNPDBm8Nllfa++DALVx/rMBAaZUY62vzbpYEu8FUt2M2atUW8LA8RP59+vFsMvLL5NtqWZbF8n3RKKmSwMfWAAsHqSa/rS1oCbjY8GpP8LkMTt7OxqpDsRj67QW8uz8GD4oqYa4nxCdjvHD2P0GY1Mu+3gbM9iba2D6jN7QFXFxMysP7+2M6VY8oCpwIIYSQDsxcT9Qht7aZ64kwL8gFp5cFYf+CQEzyt4OOgIuUvHJ8dSIBgWvPYMb2cGypbQ66ZrQX9Jq5tbCjMtDiY07tFrTvTidC2kAT2nMJObiQmAs+l8GKEV3bc4gqNcHXFj3sDFFeI1X2UHoSy7JYffA2iirE8LTSb3YBjKXB7nixuyXEUhbzdkQqK/n9eC4ZeWU1cDbV6fB9hsb1tEE3G32UVkvw3Wl5TtvOa+nKPlZfv9Kj3mCjI+lmY6DMv9oZlo6UvHIY6wiwcmRXXHh3EKYFOkLIe/Y2w+62Btg0xRdcDoO/bzxQBr6dQceePUIIIYR0aAzDwM/BGF9O8Eb4h8H4aoI3ejkaQcYC5xNyUSOV4YUuZhjRQaqgqcrMfo4w0OLjXm45Dkc/eOp+sfRRNboZfR3haKrT3kNUGQ6HwSdjvMAwwIEbD+qsCCn8cysTJ27Lc3jWT/RudoDA4TD4emIPdLcxQEFtpb3YB8X49VIKAGDlqK4dfssXh8PgwxflZfb/Ck/H6bhsfFH7GXhvuAdczXXVObwmmzPAGSFeFjDVFWB5SBdcfHcQZg9wblZe1gtdzLFuXHcA8lXnHVdT22i07atjfwIJIYQQojF0hDy84m+HvfP74sw7QZgXJD8BWzuue4eqgqYKeiI+5g6Urzp9fzoJEmndwgm7wtORnFMGYx0BFg92U8cQVcrb1hCv9pLnHq0+dLvOKlt+WTVWH5Jv0Vs4yLXFxRu0BFz8PM0f5npCJGSXYtzmKxBLWQx0N8MgDWmWHOhigqGeFpDKWMzZEYFKsRSBziaY0ddR3UNrMi6HwZbX/RCxcigWDXJtcRXIif52eGeofHvu6sO3cSK2acVUOjIKnAghhBCici5mulgxoiu2TvVvUt8gTTS9ryOMdQRIza/AgRuPVp2KK+RNQQHg7aHuMNDqHFsU/zOsC/RF8oqCf11LU96+5vBtFJTXwMNSD4sHubbqNSwNRMpKezUSGbgcBqtGdtWowHvFCA/wOAxYFtAV8rB+one7FAVRJVV9vxcPdsXk3vZgWWDJ7huITNPsBrkUOBFCCCGEtICukId5tatOG84mQVy76rThbBIKK8Rwt9DF5F52z3oKjWKiK8R/QuT5L//9NxEF5TU4EZuFozGZ4HLkVfRUsZ3Ox84Q307qAQGPgwVBLs3qF9YROJvpYn6QCzgM8NnYbrA10lb3kNSGYRh8OsYLwV3NUS2RYdbvmt0glwInQgghhJAWmhroAFNdAe4XVGJ/ZAZS8srxR20+x4cjPRstx61pXuttj65W+iiuFGP1oVisrC2zPW+gs0rLbL/Y3QpxH4coAzVN884wd8R8FIKxPW3UPRS143E5+GGyL3rYGaKoQozpv4Yj5xnVGTuyzvXTTAghhBDSjrQFPGXz0x/OJuPTo3EQS1m80MUMQe5mah6d6vG4HHz8khcA4GhMJvLKquFqrou3hqg+j0uTg06GYVpdCr4z0RJwsW26v8Y3yNXcTyQhhBBCSAfweoADzPSEeFBUibN3csDlMFg5UnPLjzemt5MxxvawBgBwGGD9BO9mVVwjzycTXSF+n9kbproCZYPcGoms8Qd2IBQ4EUIIIYS0gojPxaLH+hZN6WMPV3PNystprg9GdsUAN1OsGuWJnvZG6h4O0RD2Jtr4dUYvaAu4uHI3H5FpheoeUrPQGiIhhBBCSCu92tsef15LR1m1BEuD3dU9nDZnrifCjll91D0MooG8bQ2xaYovZCyLQBcTdQ+nWShwIoQQQghpJRGfi3/eGgAZy9K2NUIa8YKG9OV6EgVOhBBCCCEqoIpS3ISQjot+wgkhhBBCCCGkERQ4EUIIIYQQQkgjKHAihBBCCCGEkEZ0iMBp48aNcHR0hEgkQp8+fRAeHv7M4/fu3QsPDw+IRCJ0794dx44da6eREkIIIYQQQp5Hag+c9uzZg2XLlmHNmjWIioqCj48PQkJCkJOTU+/xV65cweTJkzFr1izcuHEDY8eOxdixYxEbG9vOIyeEEEIIIYQ8L9QeOH3zzTeYM2cOZs6cCU9PT2zZsgXa2tr49ddf6z3++++/x/Dhw7F8+XJ07doVn376KXx9ffHjjz+288gJIYQQQgghzwu1liOvqalBZGQkVqxYobyNw+EgODgYV69erfcxV69exbJly+rcFhISgoMHD9Z7fHV1Naqrq5X/Ly4uBgAUFBRALBa38h20nlgsRkVFBfLz88Hn89U9HKJCNLedF81t50bz23nR3HZuNL+dV1vObWlpKQCAZdlGj1Vr4JSXlwepVAoLC4s6t1tYWODOnTv1PiYrK6ve47Oysuo9fu3atfj444+fut3JyamFoyaEEEIIIYR0JqWlpTAwMHjmMZ2+Ae6KFSvqrFDJZDIUFBTAxMQEDMOocWRyJSUlsLOzw/3796Gvr6/u4RAVorntvGhuOzea386L5rZzo/ntvNpyblmWRWlpKaytrRs9Vq2Bk6mpKbhcLrKzs+vcnp2dDUtLy3ofY2lp2azjhUIhhEJhndsMDQ1bPug2oq+vTz/knRTNbedFc9u50fx2XjS3nRvNb+fVVnPb2EqTglqLQwgEAvj5+eHMmTPK22QyGc6cOYPAwMB6HxMYGFjneAA4depUg8cTQgghhBBCSGupfavesmXLMH36dPj7+6N379747rvvUF5ejpkzZwIApk2bBhsbG6xduxYAsGTJEgQFBeHrr7/GyJEjsXv3bkREROCnn35S59sghBBCCCGEdGJqD5wmTZqE3NxcrF69GllZWejRowdOnDihLACRnp4ODufRwljfvn3x119/YeXKlfjggw/g5uaGgwcPolu3bup6C60iFAqxZs2ap7YTEs1Hc9t50dx2bjS/nRfNbedG89t5dZS5Zdim1N4jhBBCCCGEkOeY2hvgEkIIIYQQQkhHR4ETIYQQQgghhDSCAidCCCGEEEIIaQQFToQQQgghhBDSCAqc1Gjjxo1wdHSESCRCnz59EB4eru4hkRa4cOECRo8eDWtrazAMg4MHD9a5n2VZrF69GlZWVtDS0kJwcDCSkpLUM1jSLGvXrkWvXr2gp6cHc3NzjB07FgkJCXWOqaqqwqJFi2BiYgJdXV2MHz/+qSbdpOPZvHkzvL29lc0UAwMDcfz4ceX9NK+dx7p168AwDJYuXaq8jeZXc3300UdgGKbOl4eHh/J+mlvN9uDBA7z++uswMTGBlpYWunfvjoiICOX96j6nosBJTfbs2YNly5ZhzZo1iIqKgo+PD0JCQpCTk6PuoZFmKi8vh4+PDzZu3Fjv/V999RU2bNiALVu24Nq1a9DR0UFISAiqqqraeaSkuUJDQ7Fo0SKEhYXh1KlTEIvFGDZsGMrLy5XHvP322zhy5Aj27t2L0NBQPHz4EOPGjVPjqElT2NraYt26dYiMjERERAQGDx6MMWPG4Pbt2wBoXjuL69evY+vWrfD29q5zO82vZvPy8kJmZqby69KlS8r7aG41V2FhIfr16wc+n4/jx48jLi4OX3/9NYyMjJTHqP2ciiVq0bt3b3bRokXK/0ulUtba2ppdu3atGkdFWgsAe+DAAeX/ZTIZa2lpya5fv155W1FRESsUCtldu3apYYSkNXJyclgAbGhoKMuy8rnk8/ns3r17lcfEx8ezANirV6+qa5ikhYyMjNhffvmF5rWTKC0tZd3c3NhTp06xQUFB7JIlS1iWpZ9bTbdmzRrWx8en3vtobjXbe++9x/bv37/B+zvCORWtOKlBTU0NIiMjERwcrLyNw+EgODgYV69eVePIiKqlpKQgKyurzlwbGBigT58+NNcaqLi4GABgbGwMAIiMjIRYLK4zvx4eHrC3t6f51SBSqRS7d+9GeXk5AgMDaV47iUWLFmHkyJF15hGgn9vOICkpCdbW1nB2dsaUKVOQnp4OgOZW0x0+fBj+/v6YOHEizM3N0bNnT/z888/K+zvCORUFTmqQl5cHqVQKCwuLOrdbWFggKytLTaMibUExnzTXmk8mk2Hp0qXo168funXrBkA+vwKBAIaGhnWOpfnVDLdu3YKuri6EQiHmz5+PAwcOwNPTk+a1E9i9ezeioqKwdu3ap+6j+dVsffr0wW+//YYTJ05g8+bNSElJwYABA1BaWkpzq+Hu3buHzZs3w83NDSdPnsSCBQvw1ltv4ffffwfQMc6peO3yKoQQouEWLVqE2NjYOnvpiWbr0qULbt68ieLiYuzbtw/Tp09HaGiouodFWun+/ftYsmQJTp06BZFIpO7hEBUbMWKE8t/e3t7o06cPHBwc8L///Q9aWlpqHBlpLZlMBn9/f3zxxRcAgJ49eyI2NhZbtmzB9OnT1Tw6OVpxUgNTU1NwudynqrxkZ2fD0tJSTaMibUExnzTXmm3x4sU4evQozp07B1tbW+XtlpaWqKmpQVFRUZ3jaX41g0AggKurK/z8/LB27Vr4+Pjg+++/p3nVcJGRkcjJyYGvry94PB54PB5CQ0OxYcMG8Hg8WFhY0Px2IoaGhnB3d0dycjL97Go4KysreHp61rmta9euyq2YHeGcigInNRAIBPDz88OZM2eUt8lkMpw5cwaBgYFqHBlRNScnJ1haWtaZ65KSEly7do3mWgOwLIvFixfjwIEDOHv2LJycnOrc7+fnBz6fX2d+ExISkJ6eTvOrgWQyGaqrq2leNdyQIUNw69Yt3Lx5U/nl7++PKVOmKP9N89t5lJWV4e7du7CysqKfXQ3Xr1+/p1p+JCYmwsHBAUAHOadqlxIU5Cm7d+9mhUIh+9tvv7FxcXHs3LlzWUNDQzYrK0vdQyPNVFpayt64cYO9ceMGC4D95ptv2Bs3brBpaWksy7LsunXrWENDQ/bQoUNsTEwMO2bMGNbJyYmtrKxU88hJYxYsWMAaGBiw58+fZzMzM5VfFRUVymPmz5/P2tvbs2fPnmUjIiLYwMBANjAwUI2jJk3x/vvvs6GhoWxKSgobExPDvv/++yzDMOy///7LsizNa2fzeFU9lqX51WTvvPMOe/78eTYlJYW9fPkyGxwczJqamrI5OTksy9LcarLw8HCWx+Oxn3/+OZuUlMT++eefrLa2Nrtz507lMeo+p6LASY1++OEH1t7enhUIBGzv3r3ZsLAwdQ+JtMC5c+dYAE99TZ8+nWVZefnMVatWsRYWFqxQKGSHDBnCJiQkqHfQpEnqm1cA7Pbt25XHVFZWsgsXLmSNjIxYbW1t9uWXX2YzMzPVN2jSJG+88Qbr4ODACgQC1szMjB0yZIgyaGJZmtfO5snAieZXc02aNIm1srJiBQIBa2Njw06aNIlNTk5W3k9zq9mOHDnCduvWjRUKhayHhwf7008/1blf3edUDMuybPusbRFCCCGEEEKIZqIcJ0IIIYQQQghpBAVOhBBCCCGEENIICpwIIYQQQgghpBEUOBFCCCGEEEJIIyhwIoQQQgghhJBGUOBECCGEEEIIIY2gwIkQQgghhBBCGkGBEyGEEEIIIYQ0ggInQgghhBBCCGkEBU6EEEI0Xm5uLhYsWAB7e3sIhUJYWloiJCQEly9fBgAwDIODBw+qd5CEEEI0Gk/dAyCEEEJaa/z48aipqcHvv/8OZ2dnZGdn48yZM8jPz1f30AghhHQSDMuyrLoHQQghhLRUUVERjIyMcP78eQQFBT11v6OjI9LS0pT/d3BwQGpqKgDg0KFD+PjjjxEXFwdra2tMnz4dH374IXg8+XVFhmGwadMmHD58GOfPn4eVlRW++uorTJgwoV3eGyGEkI6DtuoRQgjRaLq6utDV1cXBgwdRXV391P3Xr18HAGzfvh2ZmZnK/1+8eBHTpk3DkiVLEBcXh61bt+K3337D559/Xufxq1atwvjx4xEdHY0pU6bg1VdfRXx8fNu/MUIIIR0KrTgRQgjRePv378ecOXNQWVkJX19fBAUF4dVXX4W3tzcA+crRgQMHMHbsWOVjgoODMWTIEKxYsUJ5286dO/Huu+/i4cOHysfNnz8fmzdvVh4TEBAAX19fbNq0qX3eHCGEkA6BVpwIIYRovPHjx+Phw4c4fPgwhg8fjvPnz8PX1xe//fZbg4+Jjo7GJ598olyx0tXVxZw5c5CZmYmKigrlcYGBgXUeFxgYSCtOhBDyHKLiEIQQQjoFkUiEoUOHYujQoVi1ahVmz56NNWvWYMaMGfUeX1ZWho8//hjjxo2r97kIIYSQx9GKEyGEkE7J09MT5eXlAAA+nw+pVFrnfl9fXyQkJMDV1fWpLw7n0Z/HsLCwOo8LCwtD165d2/4NEEII6VBoxYkQQohGy8/Px8SJE/HGG2/A29sbenp6iIiIwFdffYUxY8YAkFfWO3PmDPr16wehUAgjIyOsXr0ao0aNgr29PSZMmAAOh4Po6GjExsbis88+Uz7/3r174e/vj/79++PPP/9EeHg4tm3bpq63SwghRE2oOAQhhBCNVl1djY8++gj//vsv7t69C7FYDDs7O0ycOBEffPABtLS0cOTIESxbtgypqamwsbFRliM/efIkPvnkE9y4cQN8Ph8eHh6YPXs25syZA0BeHGLjxo04ePAgLly4ACsrK3z55Zd45ZVX1PiOCSGEqAMFToQQQkgD6qvGRwgh5PlEOU6EEEIIIYQQ0ggKnAghhBBCCCGkEVQcghBCCGkA7WYnhBCiQCtOhBBCCCGEENIICpwIIYQQQgghpBEUOBFCCCGEEEJIIyhwIoQQQgghhJBGUOBECCGEEEIIIY2gwIkQQgghhBBCGkGBEyGEEEIIIYQ0ggInQgghhBBCCGnE/wEBro377PoI5gAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}